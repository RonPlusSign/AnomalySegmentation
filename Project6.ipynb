{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/RonPlusSign/AnomalySegmentation/blob/chris-1/Project6.ipynb)"
      ],
      "metadata": {
        "id": "ypo8OBRZ-1p3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Anomaly Segmentation Project 6**\n",
        "##*Andrea Delli, Christian Dellisanti, Giorgia Modi*"
      ],
      "metadata": {
        "id": "AUjRrYEW8-uz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Dataset Preparation**"
      ],
      "metadata": {
        "id": "4x3MajLNeXhX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip  install -q numpy matplotlib Pillow torchvision visdom ood_metrics\n",
        "\n",
        "import sys, os\n",
        "if not os.path.isfile('/content/Validation_Dataset.zip'):\n",
        "  !gdown 12YJq48XkCxQHjN3CmLc-zM5dThSak4Ta\n",
        "if not os.path.isdir('/content/Validation_Dataset'):\n",
        "  !unzip Validation_Dataset.zip\n",
        "if not os.path.isdir('/content/AnomalySegmentation'):\n",
        "  #!git clone https://github.com/shyam671/AnomalySegmentation_CourseProjectBaseCode.git\n",
        "  #token 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\n",
        "  !git clone -b chris-1 https://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@github.com/RonPlusSign/AnomalySegmentation.git\n",
        "!cd /content/AnomalySegmentation && git pull"
      ],
      "metadata": {
        "id": "B_tj8W3BeVPo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70edb515-104d-444d-c0bf-af249d44fc20",
        "collapsed": true
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects:  14% (1/7)\u001b[K\rremote: Counting objects:  28% (2/7)\u001b[K\rremote: Counting objects:  42% (3/7)\u001b[K\rremote: Counting objects:  57% (4/7)\u001b[K\rremote: Counting objects:  71% (5/7)\u001b[K\rremote: Counting objects:  85% (6/7)\u001b[K\rremote: Counting objects: 100% (7/7)\u001b[K\rremote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1)\u001b[K\rremote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 4 (delta 3), reused 4 (delta 3), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects:  25% (1/4)\rUnpacking objects:  50% (2/4)\rUnpacking objects:  75% (3/4)\rUnpacking objects: 100% (4/4)\rUnpacking objects: 100% (4/4), 375 bytes | 187.00 KiB/s, done.\n",
            "From https://github.com/RonPlusSign/AnomalySegmentation\n",
            "   7a99815..8d310ea  chris-1    -> origin/chris-1\n",
            "Updating 7a99815..8d310ea\n",
            "Fast-forward\n",
            " eval/evalAnomaly.py | 2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Anomaly Inference**"
      ],
      "metadata": {
        "id": "4RZTrDS4Mysu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# se vado alla linea 87 di evalAnomaly.py quello dovrebbe essere l'utilizzo di MSP\n",
        "\n",
        "for dataset_dir in ['RoadAnomaly', 'FS_LostFound_full', 'RoadObsticle21', 'RoadAnomaly21', 'fs_static']:\n",
        "  if torch.cuda.is_available():\n",
        "    for method in [\"MSP\", \"MaxLogit\", \"MaxEntropy\"]: #MaxEntropy in the future\n",
        "\n",
        "      format_file = os.listdir(f'/content/Validation_Dataset/{dataset_dir}/images')[0].split(\".\")[1]\n",
        "      input =f'/content/Validation_Dataset/{dataset_dir}/images/*.{format_file}'\n",
        "      print(f\"\\nDataset: {dataset_dir} method : {method}\")\n",
        "      !python -W ignore /content/AnomalySegmentation/eval/evalAnomaly.py --input {input} --loadDir '/content/AnomalySegmentation/trained_models/' --method {method}| tail -n 2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9afwM8zdM7_l",
        "outputId": "5e9e7cd0-9e08-4ca5-d5b5-5b638bd6b7ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset: RoadAnomaly method : MSP\n",
            "AUPRC score: 6.738430123274028\n",
            "FPR@TPR95: 94.89165173912563\n",
            "\n",
            "Dataset: RoadAnomaly method : MaxLogit\n",
            "AUPRC score: 6.261041864915782\n",
            "FPR@TPR95: 87.40798550331887\n",
            "\n",
            "Dataset: RoadAnomaly method : MaxEntropy\n",
            "AUPRC score: 11.621901396244672\n",
            "FPR@TPR95: 61.66823489182735\n",
            "\n",
            "Dataset: FS_LostFound_full method : MSP\n",
            "AUPRC score: 0.043171156215075765\n",
            "FPR@TPR95: 97.16297775768996\n",
            "\n",
            "Dataset: FS_LostFound_full method : MaxLogit\n",
            "AUPRC score: 0.03342295883844134\n",
            "FPR@TPR95: 97.51261950474581\n",
            "\n",
            "Dataset: FS_LostFound_full method : MaxEntropy\n",
            "AUPRC score: 0.08640125288914538\n",
            "FPR@TPR95: 42.92264292693945\n",
            "\n",
            "Dataset: RoadObsticle21 method : MSP\n",
            "AUPRC score: 0.018794117004305163\n",
            "FPR@TPR95: 95.399020190716\n",
            "\n",
            "Dataset: RoadObsticle21 method : MaxLogit\n",
            "AUPRC score: 0.020923770584216864\n",
            "FPR@TPR95: 65.61880697582242\n",
            "\n",
            "Dataset: RoadObsticle21 method : MaxEntropy\n",
            "AUPRC score: 0.016374445292533832\n",
            "FPR@TPR95: 70.49424704483458\n",
            "\n",
            "Dataset: RoadAnomaly21 method : MSP\n",
            "AUPRC score: 1.6319066971638478\n",
            "FPR@TPR95: 95.25864514332903\n",
            "\n",
            "Dataset: RoadAnomaly21 method : MaxLogit\n",
            "AUPRC score: 1.2451039820863412\n",
            "FPR@TPR95: 89.16379685795232\n",
            "\n",
            "Dataset: RoadAnomaly21 method : MaxEntropy\n",
            "AUPRC score: 2.1463284220047196\n",
            "FPR@TPR95: 78.27562286448068\n",
            "\n",
            "Dataset: fs_static method : MSP\n",
            "AUPRC score: 2.644619504332807\n",
            "FPR@TPR95: 96.04300806593338\n",
            "\n",
            "Dataset: fs_static method : MaxLogit\n",
            "AUPRC score: 1.9850762867805603\n",
            "FPR@TPR95: 99.33830433781615\n",
            "\n",
            "Dataset: fs_static method : MaxEntropy\n",
            "AUPRC score: 2.2646916674618653\n",
            "FPR@TPR95: 99.19317607890927\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Temperature Scaling**"
      ],
      "metadata": {
        "id": "NhQWIx8rklfO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Anomaly Inference with temperature**"
      ],
      "metadata": {
        "id": "q7DsE7oO1n9G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "\n",
        "for t in [0.5, 0.75, 1.1]:\n",
        "  for dataset_dir in ['RoadAnomaly', 'FS_LostFound_full', 'RoadObsticle21', 'RoadAnomaly21', 'fs_static']:\n",
        "\n",
        "    format_file = os.listdir(f'/content/Validation_Dataset/{dataset_dir}/images')[0].split(\".\")[1]\n",
        "    input =f'/content/Validation_Dataset/{dataset_dir}/images/*.{format_file}'\n",
        "    print(f\"\\nDataset: {dataset_dir} method : MSP Temperature: {t}\")\n",
        "\n",
        "    !python -W ignore /content/AnomalySegmentation/eval/evalAnomaly.py --input {input} --loadDir '/content/AnomalySegmentation/trained_models/'  --method 'MSP'  --cpu  --temperature {t} | tail -n 2\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "uOPe7qbN14Qz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dff9229-fe92-4b09-a7fd-7b5f2820ef5b"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset: RoadAnomaly method : MSP Temperature: 0.5\n",
            "AUPRC score: 6.711344253191805\n",
            "FPR@TPR95: 94.9778651262153\n",
            "\n",
            "Dataset: RoadAnomaly method : MSP Temperature: 0.75\n",
            "AUPRC score: 6.723575093120552\n",
            "FPR@TPR95: 94.93579185596369\n",
            "\n",
            "Dataset: RoadAnomaly method : MSP Temperature: 1.1\n",
            "AUPRC score: 6.744795309567523\n",
            "FPR@TPR95: 94.86656357972738\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DATASET MANAGEMENT** **TUTTO INUTILE GIÃ€ TUTTO SCRITTO**"
      ],
      "metadata": {
        "id": "zXztTueNBgkk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "import os\n",
        "\n",
        "from PIL import Image\n",
        "import sys\n",
        "\n",
        "\n",
        "def pil_loader(path):\n",
        "    # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n",
        "    with open(f\"/content/Validation_Dataset/{path}\", 'rb') as f:\n",
        "        img = Image.open(f)\n",
        "        return img.convert('RGB')\n",
        "\n",
        "\n",
        "# Define the Dataset class\n",
        "class PACSDataset(Dataset):\n",
        "    def __init__(self, root= \"/content/Validation_Dataset\", source_domain=\"FS_LostFound_full\" , dataset_transform=None):\n",
        "      super(PACSDataset, self).__init__( )\n",
        "\n",
        "      self.dataset_transform = dataset_transform\n",
        "\n",
        "      self.root=f\"{root}/{source_domain}\"\n",
        "      self.data   = os.listdir(f\"{root}/{source_domain}/images\")\n",
        "      #self.labels = os.listdir(f\"{root}/{source_domain}/labels_masks\")\n",
        "\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "      image, label = pil_loader(f\"images/{self.data[index]}\"), pil_loader(f\"labels_masks/{self.data[index]}\")\n",
        "\n",
        "      # Applies preprocessing when accessing the image\n",
        "      if self.dataset_transform is not None:\n",
        "          image = self.dataset_transform(image)\n",
        "\n",
        "      return image, label\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mNB5VstJIcYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ARCHITECTURE SETUP**"
      ],
      "metadata": {
        "id": "AWeVJrW2NiFM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# Define AlexNet architecture class\n",
        "class ErfNet(nn.Module):\n",
        "    def __init__(self, num_classes=1000):\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "        )\n",
        "        # Category classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, num_classes)\n",
        "        )\n",
        "        # Domain classifier\n",
        "        self.domain_classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.features(x)\n",
        "        features = features.view(features.size(0), -1)\n",
        "        class_outputs = self.classifier(features)\n",
        "        domain_outputs = self.domain_classifier(features)\n",
        "        return class_outputs, domain_outputs"
      ],
      "metadata": {
        "id": "GB1UGpoSJL4w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}