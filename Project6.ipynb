{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/RonPlusSign/AnomalySegmentation/blob/chris-1/Project6.ipynb)"
      ],
      "metadata": {
        "id": "ypo8OBRZ-1p3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Anomaly Segmentation Project 6**\n",
        "##*Andrea Delli, Christian Dellisanti, Giorgia Modi*"
      ],
      "metadata": {
        "id": "AUjRrYEW8-uz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Dataset Preparation**"
      ],
      "metadata": {
        "id": "4x3MajLNeXhX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip  install -q numpy matplotlib Pillow torchvision visdom ood_metrics icecream cityscapesscripts\n",
        "\n",
        "import sys, os\n",
        "if not os.path.isfile('/content/Validation_Dataset.zip'):\n",
        "  !gdown 12YJq48XkCxQHjN3CmLc-zM5dThSak4Ta\n",
        "if not os.path.isdir('/content/Validation_Dataset'):\n",
        "  !unzip -q Validation_Dataset.zip\n",
        "if not os.path.isdir('/content/AnomalySegmentation'):\n",
        "  #!git clone https://github.com/shyam671/AnomalySegmentation_CourseProjectBaseCode.git\n",
        "  #token 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\n",
        "  !git clone -b chris-1 https://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@github.com/RonPlusSign/AnomalySegmentation.git\n",
        "!cd /content/AnomalySegmentation && git pull"
      ],
      "metadata": {
        "id": "B_tj8W3BeVPo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0eea7bf4-c18b-404a-b0f3-ae6d2eb96019"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 17, done.\u001b[K\n",
            "remote: Counting objects:   6% (1/15)\u001b[K\rremote: Counting objects:  13% (2/15)\u001b[K\rremote: Counting objects:  20% (3/15)\u001b[K\rremote: Counting objects:  26% (4/15)\u001b[K\rremote: Counting objects:  33% (5/15)\u001b[K\rremote: Counting objects:  40% (6/15)\u001b[K\rremote: Counting objects:  46% (7/15)\u001b[K\rremote: Counting objects:  53% (8/15)\u001b[K\rremote: Counting objects:  60% (9/15)\u001b[K\rremote: Counting objects:  66% (10/15)\u001b[K\rremote: Counting objects:  73% (11/15)\u001b[K\rremote: Counting objects:  80% (12/15)\u001b[K\rremote: Counting objects:  86% (13/15)\u001b[K\rremote: Counting objects:  93% (14/15)\u001b[K\rremote: Counting objects: 100% (15/15)\u001b[K\rremote: Counting objects: 100% (15/15), done.\u001b[K\n",
            "remote: Compressing objects:  20% (1/5)\u001b[K\rremote: Compressing objects:  40% (2/5)\u001b[K\rremote: Compressing objects:  60% (3/5)\u001b[K\rremote: Compressing objects:  80% (4/5)\u001b[K\rremote: Compressing objects: 100% (5/5)\u001b[K\rremote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 9 (delta 6), reused 6 (delta 4), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects:  11% (1/9)\rUnpacking objects:  22% (2/9)\rUnpacking objects:  33% (3/9)\rUnpacking objects:  44% (4/9)\rUnpacking objects:  55% (5/9)\rUnpacking objects:  66% (6/9)\rUnpacking objects:  77% (7/9)\rUnpacking objects:  88% (8/9)\rUnpacking objects: 100% (9/9)\rUnpacking objects: 100% (9/9), 1.67 KiB | 570.00 KiB/s, done.\n",
            "From https://github.com/RonPlusSign/AnomalySegmentation\n",
            "   3c46671..fd136f6  chris-1    -> origin/chris-1\n",
            "Updating 3c46671..fd136f6\n",
            "Fast-forward\n",
            " Project6.ipynb   | 57 \u001b[32m++++++++++++++++++++++++++++++++++++\u001b[m\u001b[31m---------------------\u001b[m\n",
            " eval/eval_iou.py | 12 \u001b[32m++++++\u001b[m\u001b[31m------\u001b[m\n",
            " 2 files changed, 42 insertions(+), 27 deletions(-)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**mIoU**"
      ],
      "metadata": {
        "id": "JAmA1igJhHhR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import  os\n",
        "# s306027@studenti.polito.it\n",
        "# %mR+g$L\\~5U03O9)IZ-_\n",
        "# Per Eseguire tutto ci mette 23 min sia CPU che GPU\n",
        "createLabel = False\n",
        "if not os.path.isdir('/content/cityscapes'):\n",
        "  !mkdir /content/cityscapes\n",
        "\n",
        "if not os.path.isfile('/content/cityscapes/gtFine_trainvaltest.zip'):\n",
        "  !csDownload gtFine_trainvaltest.zip -d /content/cityscapes/\n",
        "  !rm /content/cityscapes/README\n",
        "  !rm /content/cityscapes/license.txt\n",
        "\n",
        "if not os.path.isfile('/content/cityscapes/leftImg8bit_trainvaltest.zip'):\n",
        "  !csDownload leftImg8bit_trainvaltest.zip -d /content/cityscapes/\n",
        "  !rm /content/cityscapes/README\n",
        "  !rm /content/cityscapes/license.txt\n",
        "\n",
        "if not os.path.isdir('/content/cityscapes/gtFine'):\n",
        "  !unzip -q /content/cityscapes/gtFine_trainvaltest.zip -d /content/cityscapes/\n",
        "  createLabel = True\n",
        "\n",
        "\n",
        "if not os.path.isdir('/content/cityscapes/leftImg8bit'):\n",
        "  !unzip -q /content/cityscapes/leftImg8bit_trainvaltest.zip  -d /content/cityscapes/\n",
        "  createLabel = True\n",
        "\n",
        "if createLabel:\n",
        "  os.environ['CITYSCAPES_DATASET'] = '/content/cityscapes/'\n",
        "  !csCreateTrainIdLabelImgs\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3w0jewGkphY",
        "outputId": "786f4237-cac0-415b-d5de-b12937061eb4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cityscapes username or email address: s306027@studenti.polito.it\n",
            "Cityscapes password: \n",
            "Store credentials unencrypted in '/root/.local/share/cityscapesscripts/credentials.json' [y/N]: y\n",
            "Downloading cityscapes package 'gtFine_trainvaltest.zip' to '/content/cityscapes/gtFine_trainvaltest.zip'\n",
            "Download progress: 100% 241M/241M [00:04<00:00, 58.7MB/s]\n",
            "Downloading cityscapes package 'leftImg8bit_trainvaltest.zip' to '/content/cityscapes/leftImg8bit_trainvaltest.zip'\n",
            "Download progress:  98% 10.8G/11.0G [16:18<00:18, 11.8MB/s]\n",
            "replace /content/cityscapes/README? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "Processing 5000 annotation files\n",
            "Progress: 100.0 % "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# ci mette 7 min con la GPU\n",
        "\n",
        "no_execute = False\n",
        "just_once = True\n",
        "\n",
        "\n",
        "for method in [\"MSP\", \"MaxLogit\", \"MaxEntropy\"]:\n",
        "\n",
        "  if no_execute:\n",
        "    break\n",
        "\n",
        "\n",
        "  if torch.cuda.is_available():\n",
        "    !python -W ignore /content/AnomalySegmentation/eval/eval_iou.py --loadDir /content/AnomalySegmentation/trained_models/ --datadir /content/cityscapes/ --method {method} | tail -n 28\n",
        "  else:\n",
        "    !python -W ignore /content/AnomalySegmentation/eval/eval_iou.py  --loadDir  /content/AnomalySegmentation/trained_models/ --datadir /content/cityscapes/ --method {method} --cpu | tail -n 28\n",
        "\n",
        "  if just_once:\n",
        "    no_execute = True\n",
        "    just_once = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAeuewkbhM3p",
        "outputId": "42a5b4a8-5b22-44dd-cf8a-7ee6b08cd4ed"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "498 val/munster/munster_000172_000019_leftImg8bit.png\n",
            "499 val/munster/munster_000173_000019_leftImg8bit.png\n",
            "-------------MSP-------------------\n",
            "---------------------------------------\n",
            "Took  415.04830741882324 seconds\n",
            "=======================================\n",
            "Per-Class IoU:\n",
            "\u001b[0m37.68\u001b[0m Road\n",
            "\u001b[0m0.00\u001b[0m sidewalk\n",
            "\u001b[0m0.00\u001b[0m building\n",
            "\u001b[0m0.00\u001b[0m wall\n",
            "\u001b[0m0.00\u001b[0m fence\n",
            "\u001b[0m0.00\u001b[0m pole\n",
            "\u001b[0m0.00\u001b[0m traffic light\n",
            "\u001b[0m0.00\u001b[0m traffic sign\n",
            "\u001b[0m0.00\u001b[0m vegetation\n",
            "\u001b[0m0.00\u001b[0m terrain\n",
            "\u001b[0m0.00\u001b[0m sky\n",
            "\u001b[0m0.00\u001b[0m person\n",
            "\u001b[0m0.00\u001b[0m rider\n",
            "\u001b[0m0.00\u001b[0m car\n",
            "\u001b[0m0.00\u001b[0m truck\n",
            "\u001b[0m0.00\u001b[0m bus\n",
            "\u001b[0m0.00\u001b[0m train\n",
            "\u001b[0m0.00\u001b[0m motorcycle\n",
            "\u001b[0m0.00\u001b[0m bicycle\n",
            "=======================================\n",
            "MEAN IoU:  \u001b[0m1.98\u001b[0m %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Anomaly Inference**"
      ],
      "metadata": {
        "id": "4RZTrDS4Mysu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# se vado alla linea 87 di evalAnomaly.py quello dovrebbe essere l'utilizzo di MSP\n",
        "\n",
        "no_execute = False\n",
        "just_once = True\n",
        "\n",
        "for dataset_dir in ['RoadAnomaly', 'FS_LostFound_full', 'RoadObsticle21', 'RoadAnomaly21', 'fs_static']:\n",
        "    for method in [\"MSP\", \"MaxLogit\", \"MaxEntropy\"]:\n",
        "\n",
        "      if no_execute:\n",
        "        break\n",
        "\n",
        "      format_file = os.listdir(f'/content/Validation_Dataset/{dataset_dir}/images')[0].split(\".\")[1]\n",
        "      input =f'/content/Validation_Dataset/{dataset_dir}/images/*.{format_file}'\n",
        "      print(f\"\\nDataset: {dataset_dir} method : {method}\")\n",
        "      if torch.cuda.is_available():\n",
        "        !python -W ignore /content/AnomalySegmentation/eval/evalAnomaly.py --input {input} --loadDir '/content/AnomalySegmentation/trained_models/' --method {method} | tail -n 2\n",
        "      else:\n",
        "        !python -W ignore /content/AnomalySegmentation/eval/evalAnomaly.py --input {input} --loadDir '/content/AnomalySegmentation/trained_models/' --method {method}  --cpu | tail -n 2\n",
        "\n",
        "      if just_once:\n",
        "        no_execute = True\n",
        "        just_once = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9afwM8zdM7_l",
        "outputId": "5b16d27f-fcfe-45f3-9147-b5a8df671119"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset: RoadAnomaly method : MSP\n",
            "AUPRC score: 11.621902667890218\n",
            "FPR@TPR95: 61.66823489182735\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Temperature Scaling**"
      ],
      "metadata": {
        "id": "NhQWIx8rklfO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Anomaly Inference with temperature**"
      ],
      "metadata": {
        "id": "q7DsE7oO1n9G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "no_execute = False\n",
        "just_once = True\n",
        "for t in [0.5, 0.75, 1.1]:\n",
        "  for dataset_dir in ['RoadAnomaly', 'FS_LostFound_full', 'RoadObsticle21', 'RoadAnomaly21', 'fs_static']:\n",
        "\n",
        "    if no_execute:\n",
        "        break\n",
        "\n",
        "    format_file = os.listdir(f'/content/Validation_Dataset/{dataset_dir}/images')[0].split(\".\")[1]\n",
        "    input =f'/content/Validation_Dataset/{dataset_dir}/images/*.{format_file}'\n",
        "    print(f\"\\nDataset: {dataset_dir} method : MSP Temperature: {t}\")\n",
        "    if torch.cuda.is_available():\n",
        "      !python -W ignore /content/AnomalySegmentation/eval/evalAnomaly.py --input {input} --loadDir '/content/AnomalySegmentation/trained_models/'  --method 'MSP'   --temperature {t} | tail -n 2\n",
        "    else:\n",
        "      !python -W ignore /content/AnomalySegmentation/eval/evalAnomaly.py --input {input} --loadDir '/content/AnomalySegmentation/trained_models/'  --method 'MSP'  --cpu  --temperature {t} | tail -n 2\n",
        "\n",
        "    if just_once:\n",
        "      no_execute = True\n",
        "      just_once = False\n"
      ],
      "metadata": {
        "id": "uOPe7qbN14Qz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c090fe5e-d3b0-445d-fa8b-ed786883db05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset: RoadAnomaly method : MSP Temperature: 0.5\n",
            "AUPRC score: 6.711347578959494\n",
            "FPR@TPR95: 94.9778651262153\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DATASET MANAGEMENT** **TUTTO INUTILE GIÃ€ TUTTO SCRITTO**"
      ],
      "metadata": {
        "id": "zXztTueNBgkk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "import os\n",
        "\n",
        "from PIL import Image\n",
        "import sys\n",
        "\n",
        "\n",
        "def pil_loader(path):\n",
        "    # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n",
        "    with open(f\"/content/Validation_Dataset/{path}\", 'rb') as f:\n",
        "        img = Image.open(f)\n",
        "        return img.convert('RGB')\n",
        "\n",
        "\n",
        "# Define the Dataset class\n",
        "class PACSDataset(Dataset):\n",
        "    def __init__(self, root= \"/content/Validation_Dataset\", source_domain=\"FS_LostFound_full\" , dataset_transform=None):\n",
        "      super(PACSDataset, self).__init__( )\n",
        "\n",
        "      self.dataset_transform = dataset_transform\n",
        "\n",
        "      self.root=f\"{root}/{source_domain}\"\n",
        "      self.data   = os.listdir(f\"{root}/{source_domain}/images\")\n",
        "      #self.labels = os.listdir(f\"{root}/{source_domain}/labels_masks\")\n",
        "\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "      image, label = pil_loader(f\"images/{self.data[index]}\"), pil_loader(f\"labels_masks/{self.data[index]}\")\n",
        "\n",
        "      # Applies preprocessing when accessing the image\n",
        "      if self.dataset_transform is not None:\n",
        "          image = self.dataset_transform(image)\n",
        "\n",
        "      return image, label\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mNB5VstJIcYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ARCHITECTURE SETUP**"
      ],
      "metadata": {
        "id": "AWeVJrW2NiFM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# Define AlexNet architecture class\n",
        "class ErfNet(nn.Module):\n",
        "    def __init__(self, num_classes=1000):\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "        )\n",
        "        # Category classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, num_classes)\n",
        "        )\n",
        "        # Domain classifier\n",
        "        self.domain_classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.features(x)\n",
        "        features = features.view(features.size(0), -1)\n",
        "        class_outputs = self.classifier(features)\n",
        "        domain_outputs = self.domain_classifier(features)\n",
        "        return class_outputs, domain_outputs"
      ],
      "metadata": {
        "id": "GB1UGpoSJL4w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}