{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypo8OBRZ-1p3"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/RonPlusSign/AnomalySegmentation/blob/main/Project6.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUjRrYEW8-uz"
      },
      "source": [
        "# **Anomaly Segmentation Project 6**\n",
        "##*Andrea Delli, Christian Dellisanti, Giorgia Modi*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4x3MajLNeXhX"
      },
      "source": [
        "##**Dataset Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "yorO9_xVX2bJ"
      },
      "outputs": [],
      "source": [
        "!rm -rf /content/AnomalySegmentation\n",
        "!rm -rf AnomalySegmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_tj8W3BeVPo",
        "outputId": "c43dca09-e702-4b39-a515-c16d15c8e75f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects:  14% (1/7)\u001b[K\rremote: Counting objects:  28% (2/7)\u001b[K\rremote: Counting objects:  42% (3/7)\u001b[K\rremote: Counting objects:  57% (4/7)\u001b[K\rremote: Counting objects:  71% (5/7)\u001b[K\rremote: Counting objects:  85% (6/7)\u001b[K\rremote: Counting objects: 100% (7/7)\u001b[K\rremote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1)\u001b[K\rremote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 4 (delta 3), reused 4 (delta 3), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects:  25% (1/4)\rUnpacking objects:  50% (2/4)\rUnpacking objects:  75% (3/4)\rUnpacking objects: 100% (4/4)\rUnpacking objects: 100% (4/4), 389 bytes | 389.00 KiB/s, done.\n",
            "From https://github.com/RonPlusSign/AnomalySegmentation\n",
            "   dae9062..e5e47b7  main       -> origin/main\n",
            "Updating dae9062..e5e47b7\n",
            "Fast-forward\n",
            " eval/mahalanobis.py | 4 \u001b[32m+++\u001b[m\u001b[31m-\u001b[m\n",
            " 1 file changed, 3 insertions(+), 1 deletion(-)\n"
          ]
        }
      ],
      "source": [
        "!pip  install -q numpy matplotlib Pillow torchvision visdom ood_metrics icecream cityscapesscripts tqdm #triton\n",
        "\n",
        "import sys, os\n",
        "if not os.path.isfile('/content/Validation_Dataset.zip'):\n",
        "  !gdown 12YJq48XkCxQHjN3CmLc-zM5dThSak4Ta\n",
        "if not os.path.isdir('/content/Validation_Dataset'):\n",
        "  !unzip -q Validation_Dataset.zip\n",
        "if not os.path.isdir('/content/AnomalySegmentation'):\n",
        "  #!git clone https://github.com/shyam671/AnomalySegmentation_CourseProjectBaseCode.git\n",
        "  #token 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\n",
        "  !git clone -b main https://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@github.com/RonPlusSign/AnomalySegmentation.git\n",
        "!cd /content/AnomalySegmentation && git pull\n",
        "#!cd /content/AnomalySegmentation && git checkout main"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAmA1igJhHhR"
      },
      "source": [
        "##**mIoU**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3w0jewGkphY",
        "outputId": "4a765fe1-a353-42dc-9ffc-850f92cc8692"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1-fjLAk4_-GkixW1-GP_cYDBUmhnVbApL\n",
            "From (redirected): https://drive.google.com/uc?id=1-fjLAk4_-GkixW1-GP_cYDBUmhnVbApL&confirm=t&uuid=1a828b36-54af-4521-8d68-d299054b03dc\n",
            "To: /content/cityscapes.zip\n",
            "100% 11.9G/11.9G [02:24<00:00, 82.6MB/s]\n"
          ]
        }
      ],
      "source": [
        "import  os\n",
        "# s306027@studenti.polito.it\n",
        "# %mR+g$L\\~5U03O9)IZ-_\n",
        "# Per Eseguire tutto ci mette 23 min sia CPU che GPU\n",
        "createLabel = True\n",
        "fast_download = True\n",
        "super_fast_download = True\n",
        "if super_fast_download:\n",
        "  !gdown 1-fjLAk4_-GkixW1-GP_cYDBUmhnVbApL\n",
        "  !unzip -q cityscapes.zip\n",
        "  !mv  ./content/cityscapes /content/cityscapes\n",
        "  !rm -rf ./content\n",
        "else:\n",
        "  if not os.path.isdir('/content/cityscapes'):\n",
        "    !mkdir /content/cityscapes\n",
        "\n",
        "  if not os.path.isfile('/content/cityscapes/gtFine_trainvaltest.zip'):\n",
        "    if fast_download:\n",
        "      !gdown 1J31rnVd33GBt-IYGYqC9mv73q7vc55pw -O /content/cityscapes/\n",
        "    else:\n",
        "      !csDownload gtFine_trainvaltest.zip -d /content/cityscapes/\n",
        "\n",
        "  if not os.path.isdir('/content/cityscapes/gtFine'):\n",
        "    !unzip -q /content/cityscapes/gtFine_trainvaltest.zip -d /content/cityscapes/\n",
        "    createLabel = True\n",
        "    !rm /content/cityscapes/README\n",
        "    !rm /content/cityscapes/license.txt\n",
        "\n",
        "\n",
        "  if not os.path.isfile('/content/cityscapes/leftImg8bit_trainvaltest.zip'):\n",
        "    if fast_download:\n",
        "      #https://drive.google.com/file/d/1m8Y3Zc6vG11Q9SxW7Be5EGXTDq4s4RlJ/view?usp=sharing\n",
        "      !gdown 1m8Y3Zc6vG11Q9SxW7Be5EGXTDq4s4RlJ -O /content/cityscapes/\n",
        "    else:\n",
        "      !csDownload leftImg8bit_trainvaltest.zip -d /content/cityscapes/\n",
        "\n",
        "\n",
        "  if not os.path.isdir('/content/cityscapes/leftImg8bit'):\n",
        "    !unzip -q /content/cityscapes/leftImg8bit_trainvaltest.zip -d /content/cityscapes/\n",
        "    createLabel = True\n",
        "    !rm /content/cityscapes/README\n",
        "    !rm /content/cityscapes/license.txt\n",
        "\n",
        "  if createLabel:\n",
        "    os.environ['CITYSCAPES_DATASET'] = '/content/cityscapes/'\n",
        "    !csCreateTrainIdLabelImgs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAeuewkbhM3p",
        "outputId": "91464ffe-a919-48c1-cf3e-c3a79a673dcb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "498 val/munster/munster_000172_000019_leftImg8bit.png\n",
            "499 val/munster/munster_000173_000019_leftImg8bit.png\n",
            "-------------MSP-------------------\n",
            "---------------------------------------\n",
            "Took  80.77754092216492 seconds\n",
            "=======================================\n",
            "Per-Class IoU:\n",
            "\u001b[0m97.62\u001b[0m Road\n",
            "\u001b[0m81.37\u001b[0m sidewalk\n",
            "\u001b[0m90.77\u001b[0m building\n",
            "\u001b[0m49.43\u001b[0m wall\n",
            "\u001b[0m54.93\u001b[0m fence\n",
            "\u001b[0m60.81\u001b[0m pole\n",
            "\u001b[0m62.60\u001b[0m traffic light\n",
            "\u001b[0m72.32\u001b[0m traffic sign\n",
            "\u001b[0m91.35\u001b[0m vegetation\n",
            "\u001b[0m60.97\u001b[0m terrain\n",
            "\u001b[0m93.38\u001b[0m sky\n",
            "\u001b[0m76.11\u001b[0m person\n",
            "\u001b[0m53.45\u001b[0m rider\n",
            "\u001b[0m92.91\u001b[0m car\n",
            "\u001b[0m72.78\u001b[0m truck\n",
            "\u001b[0m78.87\u001b[0m bus\n",
            "\u001b[0m63.86\u001b[0m train\n",
            "\u001b[0m46.41\u001b[0m motorcycle\n",
            "\u001b[0m71.89\u001b[0m bicycle\n",
            "=======================================\n",
            "MEAN IoU:  \u001b[0m72.20\u001b[0m %\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "# ci mette 7 min con la GPU\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  !python -W ignore /content/AnomalySegmentation/eval/eval_iou.py --loadDir /content/AnomalySegmentation/trained_models/ --datadir /content/cityscapes/  | tail -n 28\n",
        "else:\n",
        "  !python -W ignore /content/AnomalySegmentation/eval/eval_iou.py  --loadDir  /content/AnomalySegmentation/trained_models/ --datadir /content/cityscapes/  --cpu | tail -n 28"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RZTrDS4Mysu"
      },
      "source": [
        "##**Anomaly Inference**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9afwM8zdM7_l",
        "outputId": "80d0aaaa-35f3-4bb8-a9fb-b46181f31866"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------\n",
            "\n",
            "Dataset: RoadAnomaly21 method: MSP\n",
            "AUPRC score: 29.100168300581203\n",
            "FPR@TPR95: 62.51075321069286\n",
            "\n",
            "Dataset: RoadAnomaly21 method: MaxLogit\n",
            "AUPRC score: 38.31957797222208\n",
            "FPR@TPR95: 59.3370558914899\n",
            "\n",
            "Dataset: RoadAnomaly21 method: MaxEntropy\n",
            "AUPRC score: 31.005102648344756\n",
            "FPR@TPR95: 62.593151130093226\n",
            "----------------------------\n",
            "\n",
            "Dataset: RoadObsticle21 method: MSP\n",
            "AUPRC score: 2.7116243119338366\n",
            "FPR@TPR95: 64.9739786894368\n",
            "\n",
            "Dataset: RoadObsticle21 method: MaxLogit\n",
            "AUPRC score: 4.626567617520253\n",
            "FPR@TPR95: 48.443439151949555\n",
            "\n",
            "Dataset: RoadObsticle21 method: MaxEntropy\n",
            "AUPRC score: 3.051560023478638\n",
            "FPR@TPR95: 65.59968252759046\n",
            "----------------------------\n",
            "\n",
            "Dataset: FS_LostFound_full method: MSP\n",
            "AUPRC score: 1.747872547607269\n",
            "FPR@TPR95: 50.76348570192957\n",
            "\n",
            "Dataset: FS_LostFound_full method: MaxLogit\n",
            "AUPRC score: 3.3014401015087245\n",
            "FPR@TPR95: 45.494876929038305\n",
            "\n",
            "Dataset: FS_LostFound_full method: MaxEntropy\n",
            "AUPRC score: 2.581709137723009\n",
            "FPR@TPR95: 50.368099783135676\n",
            "----------------------------\n",
            "\n",
            "Dataset: fs_static method: MSP\n",
            "AUPRC score: 7.4700433549050915\n",
            "FPR@TPR95: 41.82346831776172\n",
            "\n",
            "Dataset: fs_static method: MaxLogit\n",
            "AUPRC score: 9.498677970785756\n",
            "FPR@TPR95: 40.3000747567442\n",
            "\n",
            "Dataset: fs_static method: MaxEntropy\n",
            "AUPRC score: 8.82636607633996\n",
            "FPR@TPR95: 41.52332673090571\n",
            "----------------------------\n",
            "\n",
            "Dataset: RoadAnomaly method: MSP\n",
            "AUPRC score: 12.426265849563665\n",
            "FPR@TPR95: 82.49244029880458\n",
            "\n",
            "Dataset: RoadAnomaly method: MaxLogit\n",
            "AUPRC score: 15.581983301641019\n",
            "FPR@TPR95: 73.24766535735604\n",
            "\n",
            "Dataset: RoadAnomaly method: MaxEntropy\n",
            "AUPRC score: 12.678035094227063\n",
            "FPR@TPR95: 82.63192451735861\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "no_execute = False\n",
        "just_once = False\n",
        "\n",
        "for dataset_dir in ['RoadAnomaly21', 'RoadObsticle21', 'FS_LostFound_full', 'fs_static', 'RoadAnomaly']:\n",
        "  print(\"----------------------------\")\n",
        "  for method in [\"MSP\", \"MaxLogit\", \"MaxEntropy\"]:\n",
        "\n",
        "    if no_execute:\n",
        "      break\n",
        "\n",
        "    format_file = os.listdir(f'/content/Validation_Dataset/{dataset_dir}/images')[0].split(\".\")[1]\n",
        "    input =f'/content/Validation_Dataset/{dataset_dir}/images/\\*.{format_file}'\n",
        "    print(f\"\\nDataset: {dataset_dir} method: {method}\")\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "      !python -W ignore /content/AnomalySegmentation/eval/evalAnomaly.py --input {input} --method  {method}  | tail -n 2\n",
        "    else:\n",
        "      !python -W ignore /content/AnomalySegmentation/eval/evalAnomaly.py --input {input} --method {method}  --cpu | tail -n 2\n",
        "\n",
        "    if just_once:\n",
        "      no_execute = True\n",
        "      just_once = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhQWIx8rklfO"
      },
      "source": [
        "##**Temperature Scaling**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7DsE7oO1n9G"
      },
      "source": [
        "**Anomaly Inference with temperature**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Zu-dIEeqFLq3",
        "outputId": "47825080-3d12-479f-c2c2-51ca15ecab1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------\n",
            "\n",
            "Dataset: RoadAnomaly21 method : MSP Temperature: 0.5\n",
            "AUPRC score: 27.060833635879618\n",
            "FPR@TPR95: 62.730810427606734\n",
            "\n",
            "Dataset: RoadAnomaly21 method : MSP Temperature: 0.75\n",
            "AUPRC score: 28.156063054348103\n",
            "FPR@TPR95: 62.478737323984326\n",
            "\n",
            "Dataset: RoadAnomaly21 method : MSP Temperature: 1.1\n",
            "AUPRC score: 29.40955379121979\n",
            "FPR@TPR95: 62.58986549662704\n",
            "----------------------------\n",
            "\n",
            "Dataset: RoadObsticle21 method : MSP Temperature: 0.5\n",
            "AUPRC score: 2.4195519558429823\n",
            "FPR@TPR95: 63.22544524787239\n",
            "\n",
            "Dataset: RoadObsticle21 method : MSP Temperature: 0.75\n",
            "AUPRC score: 2.5668802249367677\n",
            "FPR@TPR95: 64.05285534718263\n",
            "\n",
            "Dataset: RoadObsticle21 method : MSP Temperature: 1.1\n",
            "AUPRC score: 2.7658075767433776\n",
            "FPR@TPR95: 65.52358106228223\n",
            "----------------------------\n",
            "\n",
            "Dataset: FS_LostFound_full method : MSP Temperature: 0.5\n",
            "AUPRC score: 1.2802500246431052\n",
            "FPR@TPR95: 66.73710676943257\n",
            "\n",
            "Dataset: FS_LostFound_full method : MSP Temperature: 0.75\n",
            "AUPRC score: 1.4927065686510383\n",
            "FPR@TPR95: 51.848262648332636\n",
            "\n",
            "Dataset: FS_LostFound_full method : MSP Temperature: 1.1\n",
            "AUPRC score: 1.8596703140506141\n",
            "FPR@TPR95: 50.38650128754133\n",
            "----------------------------\n",
            "\n",
            "Dataset: fs_static method : MSP Temperature: 0.5\n",
            "AUPRC score: 6.6011970066164665\n",
            "FPR@TPR95: 43.47565874225287\n",
            "\n",
            "Dataset: fs_static method : MSP Temperature: 0.75\n",
            "AUPRC score: 6.99079114995491\n",
            "FPR@TPR95: 42.49329123307483\n",
            "\n",
            "Dataset: fs_static method : MSP Temperature: 1.1\n",
            "AUPRC score: 7.686696846804934\n",
            "FPR@TPR95: 41.586844199987\n",
            "----------------------------\n",
            "\n",
            "Dataset: RoadAnomaly method : MSP Temperature: 0.5\n",
            "AUPRC score: 12.187681345765725\n",
            "FPR@TPR95: 82.02224728951396\n",
            "\n",
            "Dataset: RoadAnomaly method : MSP Temperature: 0.75\n",
            "AUPRC score: 12.319186617225913\n",
            "FPR@TPR95: 82.28451947325927\n",
            "\n",
            "Dataset: RoadAnomaly method : MSP Temperature: 1.1\n",
            "AUPRC score: 12.465779148190585\n",
            "FPR@TPR95: 82.62125003163526\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "no_execute = False\n",
        "just_once = False\n",
        "for dataset_dir in ['RoadAnomaly21', 'RoadObsticle21', 'FS_LostFound_full', 'fs_static', 'RoadAnomaly']:\n",
        "  print(\"----------------------------\")\n",
        "  for t in [0.5, 0.75, 1.1]:\n",
        "    if no_execute:\n",
        "        break\n",
        "\n",
        "    format_file = os.listdir(f'/content/Validation_Dataset/{dataset_dir}/images')[0].split(\".\")[1]\n",
        "    input =f'/content/Validation_Dataset/{dataset_dir}/images/\\*.{format_file}'\n",
        "    print(f\"\\nDataset: {dataset_dir}, method: MSP, Temperature: {t}\")\n",
        "    if torch.cuda.is_available():\n",
        "      !python -W ignore /content/AnomalySegmentation/eval/evalAnomaly.py --input {input} --method 'MSP' --temperature {t} | tail -n 2\n",
        "    else:\n",
        "      !python -W ignore /content/AnomalySegmentation/eval/evalAnomaly.py --input {input} --method 'MSP' --cpu --temperature {t} | tail -n 2\n",
        "\n",
        "    if just_once:\n",
        "      no_execute = True\n",
        "      just_once = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nY-OAYlIjGaG"
      },
      "source": [
        "## **Void Classifier**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-E1hYJkZf_bU"
      },
      "source": [
        "**Cella per eseguire fine tuning di tutti e tre:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3bSxCH-7WT7"
      },
      "outputs": [],
      "source": [
        "# Fine-tune ERFNet, ENet and BiSeNetv1 for VOID classification using CrossEntropy\n",
        "\n",
        "models = [\"erfnet\", \"enet\", \"bisenet\"]\n",
        "savedirs = [\"erfnet_training_void\", \"enet_training_void\", \"bisenet_training_void\"]\n",
        "pretrained_weights = [\"erfnet_pretrained.pth\", \"enet_pretrained.pth\", \"bisenetv1_pretrained.pth\"]\n",
        "epochs = 20\n",
        "\n",
        "# Base directory of the project\n",
        "base_dir = \"/content/AnomalySegmentation/train\"\n",
        "# Dataset directory\n",
        "data_dir = \"/content/cityscapes\"\n",
        "\n",
        "# Loop to execute fine-tuning\n",
        "for model, savedir, pretrained_weight  in zip(models, savedirs, pretrained_weights):\n",
        "    print(f\"\\n\\n----- Fine-tuning {model} for VOID classification -----\")\n",
        "    !cd {base_dir} && python -W ignore main.py --savedir {savedir} --datadir {data_dir} --model {model} --cuda --num-epochs=20 --epochs-save=1 --FineTune --decoder --loadWeights={pretrained_weight}\n",
        "    print(f\"Model saved in /content/AnomalySegmentation/save/{savedir}\")\n",
        "    # zip folder\n",
        "    !zip -r save_{savedir}.zip /content/AnomalySegmentation/save/{savedir}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jel6EnIygGvW"
      },
      "source": [
        "**Celle per eseguire fine tuning uno alla volta:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wQ3eGuwVkP_",
        "outputId": "865f1cfc-e058-4401-c6e5-f1eb2275f7b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----- Fine-tuning erfnet for VOID classification -----\n",
            "odict_keys(['module.encoder.initial_block.conv.weight', 'module.encoder.initial_block.conv.bias', 'module.encoder.initial_block.bn.weight', 'module.encoder.initial_block.bn.bias', 'module.encoder.initial_block.bn.running_mean', 'module.encoder.initial_block.bn.running_var', 'module.encoder.layers.0.conv.weight', 'module.encoder.layers.0.conv.bias', 'module.encoder.layers.0.bn.weight', 'module.encoder.layers.0.bn.bias', 'module.encoder.layers.0.bn.running_mean', 'module.encoder.layers.0.bn.running_var', 'module.encoder.layers.1.conv3x1_1.weight', 'module.encoder.layers.1.conv3x1_1.bias', 'module.encoder.layers.1.conv1x3_1.weight', 'module.encoder.layers.1.conv1x3_1.bias', 'module.encoder.layers.1.conv3x1_2.weight', 'module.encoder.layers.1.conv3x1_2.bias', 'module.encoder.layers.1.conv1x3_2.weight', 'module.encoder.layers.1.conv1x3_2.bias', 'module.encoder.layers.1.bn1.weight', 'module.encoder.layers.1.bn1.bias', 'module.encoder.layers.1.bn1.running_mean', 'module.encoder.layers.1.bn1.running_var', 'module.encoder.layers.1.bn2.weight', 'module.encoder.layers.1.bn2.bias', 'module.encoder.layers.1.bn2.running_mean', 'module.encoder.layers.1.bn2.running_var', 'module.encoder.layers.2.conv3x1_1.weight', 'module.encoder.layers.2.conv3x1_1.bias', 'module.encoder.layers.2.conv1x3_1.weight', 'module.encoder.layers.2.conv1x3_1.bias', 'module.encoder.layers.2.conv3x1_2.weight', 'module.encoder.layers.2.conv3x1_2.bias', 'module.encoder.layers.2.conv1x3_2.weight', 'module.encoder.layers.2.conv1x3_2.bias', 'module.encoder.layers.2.bn1.weight', 'module.encoder.layers.2.bn1.bias', 'module.encoder.layers.2.bn1.running_mean', 'module.encoder.layers.2.bn1.running_var', 'module.encoder.layers.2.bn2.weight', 'module.encoder.layers.2.bn2.bias', 'module.encoder.layers.2.bn2.running_mean', 'module.encoder.layers.2.bn2.running_var', 'module.encoder.layers.3.conv3x1_1.weight', 'module.encoder.layers.3.conv3x1_1.bias', 'module.encoder.layers.3.conv1x3_1.weight', 'module.encoder.layers.3.conv1x3_1.bias', 'module.encoder.layers.3.conv3x1_2.weight', 'module.encoder.layers.3.conv3x1_2.bias', 'module.encoder.layers.3.conv1x3_2.weight', 'module.encoder.layers.3.conv1x3_2.bias', 'module.encoder.layers.3.bn1.weight', 'module.encoder.layers.3.bn1.bias', 'module.encoder.layers.3.bn1.running_mean', 'module.encoder.layers.3.bn1.running_var', 'module.encoder.layers.3.bn2.weight', 'module.encoder.layers.3.bn2.bias', 'module.encoder.layers.3.bn2.running_mean', 'module.encoder.layers.3.bn2.running_var', 'module.encoder.layers.4.conv3x1_1.weight', 'module.encoder.layers.4.conv3x1_1.bias', 'module.encoder.layers.4.conv1x3_1.weight', 'module.encoder.layers.4.conv1x3_1.bias', 'module.encoder.layers.4.conv3x1_2.weight', 'module.encoder.layers.4.conv3x1_2.bias', 'module.encoder.layers.4.conv1x3_2.weight', 'module.encoder.layers.4.conv1x3_2.bias', 'module.encoder.layers.4.bn1.weight', 'module.encoder.layers.4.bn1.bias', 'module.encoder.layers.4.bn1.running_mean', 'module.encoder.layers.4.bn1.running_var', 'module.encoder.layers.4.bn2.weight', 'module.encoder.layers.4.bn2.bias', 'module.encoder.layers.4.bn2.running_mean', 'module.encoder.layers.4.bn2.running_var', 'module.encoder.layers.5.conv3x1_1.weight', 'module.encoder.layers.5.conv3x1_1.bias', 'module.encoder.layers.5.conv1x3_1.weight', 'module.encoder.layers.5.conv1x3_1.bias', 'module.encoder.layers.5.conv3x1_2.weight', 'module.encoder.layers.5.conv3x1_2.bias', 'module.encoder.layers.5.conv1x3_2.weight', 'module.encoder.layers.5.conv1x3_2.bias', 'module.encoder.layers.5.bn1.weight', 'module.encoder.layers.5.bn1.bias', 'module.encoder.layers.5.bn1.running_mean', 'module.encoder.layers.5.bn1.running_var', 'module.encoder.layers.5.bn2.weight', 'module.encoder.layers.5.bn2.bias', 'module.encoder.layers.5.bn2.running_mean', 'module.encoder.layers.5.bn2.running_var', 'module.encoder.layers.6.conv.weight', 'module.encoder.layers.6.conv.bias', 'module.encoder.layers.6.bn.weight', 'module.encoder.layers.6.bn.bias', 'module.encoder.layers.6.bn.running_mean', 'module.encoder.layers.6.bn.running_var', 'module.encoder.layers.7.conv3x1_1.weight', 'module.encoder.layers.7.conv3x1_1.bias', 'module.encoder.layers.7.conv1x3_1.weight', 'module.encoder.layers.7.conv1x3_1.bias', 'module.encoder.layers.7.conv3x1_2.weight', 'module.encoder.layers.7.conv3x1_2.bias', 'module.encoder.layers.7.conv1x3_2.weight', 'module.encoder.layers.7.conv1x3_2.bias', 'module.encoder.layers.7.bn1.weight', 'module.encoder.layers.7.bn1.bias', 'module.encoder.layers.7.bn1.running_mean', 'module.encoder.layers.7.bn1.running_var', 'module.encoder.layers.7.bn2.weight', 'module.encoder.layers.7.bn2.bias', 'module.encoder.layers.7.bn2.running_mean', 'module.encoder.layers.7.bn2.running_var', 'module.encoder.layers.8.conv3x1_1.weight', 'module.encoder.layers.8.conv3x1_1.bias', 'module.encoder.layers.8.conv1x3_1.weight', 'module.encoder.layers.8.conv1x3_1.bias', 'module.encoder.layers.8.conv3x1_2.weight', 'module.encoder.layers.8.conv3x1_2.bias', 'module.encoder.layers.8.conv1x3_2.weight', 'module.encoder.layers.8.conv1x3_2.bias', 'module.encoder.layers.8.bn1.weight', 'module.encoder.layers.8.bn1.bias', 'module.encoder.layers.8.bn1.running_mean', 'module.encoder.layers.8.bn1.running_var', 'module.encoder.layers.8.bn2.weight', 'module.encoder.layers.8.bn2.bias', 'module.encoder.layers.8.bn2.running_mean', 'module.encoder.layers.8.bn2.running_var', 'module.encoder.layers.9.conv3x1_1.weight', 'module.encoder.layers.9.conv3x1_1.bias', 'module.encoder.layers.9.conv1x3_1.weight', 'module.encoder.layers.9.conv1x3_1.bias', 'module.encoder.layers.9.conv3x1_2.weight', 'module.encoder.layers.9.conv3x1_2.bias', 'module.encoder.layers.9.conv1x3_2.weight', 'module.encoder.layers.9.conv1x3_2.bias', 'module.encoder.layers.9.bn1.weight', 'module.encoder.layers.9.bn1.bias', 'module.encoder.layers.9.bn1.running_mean', 'module.encoder.layers.9.bn1.running_var', 'module.encoder.layers.9.bn2.weight', 'module.encoder.layers.9.bn2.bias', 'module.encoder.layers.9.bn2.running_mean', 'module.encoder.layers.9.bn2.running_var', 'module.encoder.layers.10.conv3x1_1.weight', 'module.encoder.layers.10.conv3x1_1.bias', 'module.encoder.layers.10.conv1x3_1.weight', 'module.encoder.layers.10.conv1x3_1.bias', 'module.encoder.layers.10.conv3x1_2.weight', 'module.encoder.layers.10.conv3x1_2.bias', 'module.encoder.layers.10.conv1x3_2.weight', 'module.encoder.layers.10.conv1x3_2.bias', 'module.encoder.layers.10.bn1.weight', 'module.encoder.layers.10.bn1.bias', 'module.encoder.layers.10.bn1.running_mean', 'module.encoder.layers.10.bn1.running_var', 'module.encoder.layers.10.bn2.weight', 'module.encoder.layers.10.bn2.bias', 'module.encoder.layers.10.bn2.running_mean', 'module.encoder.layers.10.bn2.running_var', 'module.encoder.layers.11.conv3x1_1.weight', 'module.encoder.layers.11.conv3x1_1.bias', 'module.encoder.layers.11.conv1x3_1.weight', 'module.encoder.layers.11.conv1x3_1.bias', 'module.encoder.layers.11.conv3x1_2.weight', 'module.encoder.layers.11.conv3x1_2.bias', 'module.encoder.layers.11.conv1x3_2.weight', 'module.encoder.layers.11.conv1x3_2.bias', 'module.encoder.layers.11.bn1.weight', 'module.encoder.layers.11.bn1.bias', 'module.encoder.layers.11.bn1.running_mean', 'module.encoder.layers.11.bn1.running_var', 'module.encoder.layers.11.bn2.weight', 'module.encoder.layers.11.bn2.bias', 'module.encoder.layers.11.bn2.running_mean', 'module.encoder.layers.11.bn2.running_var', 'module.encoder.layers.12.conv3x1_1.weight', 'module.encoder.layers.12.conv3x1_1.bias', 'module.encoder.layers.12.conv1x3_1.weight', 'module.encoder.layers.12.conv1x3_1.bias', 'module.encoder.layers.12.conv3x1_2.weight', 'module.encoder.layers.12.conv3x1_2.bias', 'module.encoder.layers.12.conv1x3_2.weight', 'module.encoder.layers.12.conv1x3_2.bias', 'module.encoder.layers.12.bn1.weight', 'module.encoder.layers.12.bn1.bias', 'module.encoder.layers.12.bn1.running_mean', 'module.encoder.layers.12.bn1.running_var', 'module.encoder.layers.12.bn2.weight', 'module.encoder.layers.12.bn2.bias', 'module.encoder.layers.12.bn2.running_mean', 'module.encoder.layers.12.bn2.running_var', 'module.encoder.layers.13.conv3x1_1.weight', 'module.encoder.layers.13.conv3x1_1.bias', 'module.encoder.layers.13.conv1x3_1.weight', 'module.encoder.layers.13.conv1x3_1.bias', 'module.encoder.layers.13.conv3x1_2.weight', 'module.encoder.layers.13.conv3x1_2.bias', 'module.encoder.layers.13.conv1x3_2.weight', 'module.encoder.layers.13.conv1x3_2.bias', 'module.encoder.layers.13.bn1.weight', 'module.encoder.layers.13.bn1.bias', 'module.encoder.layers.13.bn1.running_mean', 'module.encoder.layers.13.bn1.running_var', 'module.encoder.layers.13.bn2.weight', 'module.encoder.layers.13.bn2.bias', 'module.encoder.layers.13.bn2.running_mean', 'module.encoder.layers.13.bn2.running_var', 'module.encoder.layers.14.conv3x1_1.weight', 'module.encoder.layers.14.conv3x1_1.bias', 'module.encoder.layers.14.conv1x3_1.weight', 'module.encoder.layers.14.conv1x3_1.bias', 'module.encoder.layers.14.conv3x1_2.weight', 'module.encoder.layers.14.conv3x1_2.bias', 'module.encoder.layers.14.conv1x3_2.weight', 'module.encoder.layers.14.conv1x3_2.bias', 'module.encoder.layers.14.bn1.weight', 'module.encoder.layers.14.bn1.bias', 'module.encoder.layers.14.bn1.running_mean', 'module.encoder.layers.14.bn1.running_var', 'module.encoder.layers.14.bn2.weight', 'module.encoder.layers.14.bn2.bias', 'module.encoder.layers.14.bn2.running_mean', 'module.encoder.layers.14.bn2.running_var', 'module.decoder.layers.0.conv.weight', 'module.decoder.layers.0.conv.bias', 'module.decoder.layers.0.bn.weight', 'module.decoder.layers.0.bn.bias', 'module.decoder.layers.0.bn.running_mean', 'module.decoder.layers.0.bn.running_var', 'module.decoder.layers.1.conv3x1_1.weight', 'module.decoder.layers.1.conv3x1_1.bias', 'module.decoder.layers.1.conv1x3_1.weight', 'module.decoder.layers.1.conv1x3_1.bias', 'module.decoder.layers.1.bn1.weight', 'module.decoder.layers.1.bn1.bias', 'module.decoder.layers.1.bn1.running_mean', 'module.decoder.layers.1.bn1.running_var', 'module.decoder.layers.1.conv3x1_2.weight', 'module.decoder.layers.1.conv3x1_2.bias', 'module.decoder.layers.1.conv1x3_2.weight', 'module.decoder.layers.1.conv1x3_2.bias', 'module.decoder.layers.1.bn2.weight', 'module.decoder.layers.1.bn2.bias', 'module.decoder.layers.1.bn2.running_mean', 'module.decoder.layers.1.bn2.running_var', 'module.decoder.layers.2.conv3x1_1.weight', 'module.decoder.layers.2.conv3x1_1.bias', 'module.decoder.layers.2.conv1x3_1.weight', 'module.decoder.layers.2.conv1x3_1.bias', 'module.decoder.layers.2.bn1.weight', 'module.decoder.layers.2.bn1.bias', 'module.decoder.layers.2.bn1.running_mean', 'module.decoder.layers.2.bn1.running_var', 'module.decoder.layers.2.conv3x1_2.weight', 'module.decoder.layers.2.conv3x1_2.bias', 'module.decoder.layers.2.conv1x3_2.weight', 'module.decoder.layers.2.conv1x3_2.bias', 'module.decoder.layers.2.bn2.weight', 'module.decoder.layers.2.bn2.bias', 'module.decoder.layers.2.bn2.running_mean', 'module.decoder.layers.2.bn2.running_var', 'module.decoder.layers.3.conv.weight', 'module.decoder.layers.3.conv.bias', 'module.decoder.layers.3.bn.weight', 'module.decoder.layers.3.bn.bias', 'module.decoder.layers.3.bn.running_mean', 'module.decoder.layers.3.bn.running_var', 'module.decoder.layers.4.conv3x1_1.weight', 'module.decoder.layers.4.conv3x1_1.bias', 'module.decoder.layers.4.conv1x3_1.weight', 'module.decoder.layers.4.conv1x3_1.bias', 'module.decoder.layers.4.bn1.weight', 'module.decoder.layers.4.bn1.bias', 'module.decoder.layers.4.bn1.running_mean', 'module.decoder.layers.4.bn1.running_var', 'module.decoder.layers.4.conv3x1_2.weight', 'module.decoder.layers.4.conv3x1_2.bias', 'module.decoder.layers.4.conv1x3_2.weight', 'module.decoder.layers.4.conv1x3_2.bias', 'module.decoder.layers.4.bn2.weight', 'module.decoder.layers.4.bn2.bias', 'module.decoder.layers.4.bn2.running_mean', 'module.decoder.layers.4.bn2.running_var', 'module.decoder.layers.5.conv3x1_1.weight', 'module.decoder.layers.5.conv3x1_1.bias', 'module.decoder.layers.5.conv1x3_1.weight', 'module.decoder.layers.5.conv1x3_1.bias', 'module.decoder.layers.5.bn1.weight', 'module.decoder.layers.5.bn1.bias', 'module.decoder.layers.5.bn1.running_mean', 'module.decoder.layers.5.bn1.running_var', 'module.decoder.layers.5.conv3x1_2.weight', 'module.decoder.layers.5.conv3x1_2.bias', 'module.decoder.layers.5.conv1x3_2.weight', 'module.decoder.layers.5.conv1x3_2.bias', 'module.decoder.layers.5.bn2.weight', 'module.decoder.layers.5.bn2.bias', 'module.decoder.layers.5.bn2.running_mean', 'module.decoder.layers.5.bn2.running_var', 'module.decoder.output_conv.weight', 'module.decoder.output_conv.bias'])\n",
            "odict_keys(['encoder.initial_block.conv.weight', 'encoder.initial_block.conv.bias', 'encoder.initial_block.bn.weight', 'encoder.initial_block.bn.bias', 'encoder.initial_block.bn.running_mean', 'encoder.initial_block.bn.running_var', 'encoder.initial_block.bn.num_batches_tracked', 'encoder.layers.0.conv.weight', 'encoder.layers.0.conv.bias', 'encoder.layers.0.bn.weight', 'encoder.layers.0.bn.bias', 'encoder.layers.0.bn.running_mean', 'encoder.layers.0.bn.running_var', 'encoder.layers.0.bn.num_batches_tracked', 'encoder.layers.1.conv3x1_1.weight', 'encoder.layers.1.conv3x1_1.bias', 'encoder.layers.1.conv1x3_1.weight', 'encoder.layers.1.conv1x3_1.bias', 'encoder.layers.1.bn1.weight', 'encoder.layers.1.bn1.bias', 'encoder.layers.1.bn1.running_mean', 'encoder.layers.1.bn1.running_var', 'encoder.layers.1.bn1.num_batches_tracked', 'encoder.layers.1.conv3x1_2.weight', 'encoder.layers.1.conv3x1_2.bias', 'encoder.layers.1.conv1x3_2.weight', 'encoder.layers.1.conv1x3_2.bias', 'encoder.layers.1.bn2.weight', 'encoder.layers.1.bn2.bias', 'encoder.layers.1.bn2.running_mean', 'encoder.layers.1.bn2.running_var', 'encoder.layers.1.bn2.num_batches_tracked', 'encoder.layers.2.conv3x1_1.weight', 'encoder.layers.2.conv3x1_1.bias', 'encoder.layers.2.conv1x3_1.weight', 'encoder.layers.2.conv1x3_1.bias', 'encoder.layers.2.bn1.weight', 'encoder.layers.2.bn1.bias', 'encoder.layers.2.bn1.running_mean', 'encoder.layers.2.bn1.running_var', 'encoder.layers.2.bn1.num_batches_tracked', 'encoder.layers.2.conv3x1_2.weight', 'encoder.layers.2.conv3x1_2.bias', 'encoder.layers.2.conv1x3_2.weight', 'encoder.layers.2.conv1x3_2.bias', 'encoder.layers.2.bn2.weight', 'encoder.layers.2.bn2.bias', 'encoder.layers.2.bn2.running_mean', 'encoder.layers.2.bn2.running_var', 'encoder.layers.2.bn2.num_batches_tracked', 'encoder.layers.3.conv3x1_1.weight', 'encoder.layers.3.conv3x1_1.bias', 'encoder.layers.3.conv1x3_1.weight', 'encoder.layers.3.conv1x3_1.bias', 'encoder.layers.3.bn1.weight', 'encoder.layers.3.bn1.bias', 'encoder.layers.3.bn1.running_mean', 'encoder.layers.3.bn1.running_var', 'encoder.layers.3.bn1.num_batches_tracked', 'encoder.layers.3.conv3x1_2.weight', 'encoder.layers.3.conv3x1_2.bias', 'encoder.layers.3.conv1x3_2.weight', 'encoder.layers.3.conv1x3_2.bias', 'encoder.layers.3.bn2.weight', 'encoder.layers.3.bn2.bias', 'encoder.layers.3.bn2.running_mean', 'encoder.layers.3.bn2.running_var', 'encoder.layers.3.bn2.num_batches_tracked', 'encoder.layers.4.conv3x1_1.weight', 'encoder.layers.4.conv3x1_1.bias', 'encoder.layers.4.conv1x3_1.weight', 'encoder.layers.4.conv1x3_1.bias', 'encoder.layers.4.bn1.weight', 'encoder.layers.4.bn1.bias', 'encoder.layers.4.bn1.running_mean', 'encoder.layers.4.bn1.running_var', 'encoder.layers.4.bn1.num_batches_tracked', 'encoder.layers.4.conv3x1_2.weight', 'encoder.layers.4.conv3x1_2.bias', 'encoder.layers.4.conv1x3_2.weight', 'encoder.layers.4.conv1x3_2.bias', 'encoder.layers.4.bn2.weight', 'encoder.layers.4.bn2.bias', 'encoder.layers.4.bn2.running_mean', 'encoder.layers.4.bn2.running_var', 'encoder.layers.4.bn2.num_batches_tracked', 'encoder.layers.5.conv3x1_1.weight', 'encoder.layers.5.conv3x1_1.bias', 'encoder.layers.5.conv1x3_1.weight', 'encoder.layers.5.conv1x3_1.bias', 'encoder.layers.5.bn1.weight', 'encoder.layers.5.bn1.bias', 'encoder.layers.5.bn1.running_mean', 'encoder.layers.5.bn1.running_var', 'encoder.layers.5.bn1.num_batches_tracked', 'encoder.layers.5.conv3x1_2.weight', 'encoder.layers.5.conv3x1_2.bias', 'encoder.layers.5.conv1x3_2.weight', 'encoder.layers.5.conv1x3_2.bias', 'encoder.layers.5.bn2.weight', 'encoder.layers.5.bn2.bias', 'encoder.layers.5.bn2.running_mean', 'encoder.layers.5.bn2.running_var', 'encoder.layers.5.bn2.num_batches_tracked', 'encoder.layers.6.conv.weight', 'encoder.layers.6.conv.bias', 'encoder.layers.6.bn.weight', 'encoder.layers.6.bn.bias', 'encoder.layers.6.bn.running_mean', 'encoder.layers.6.bn.running_var', 'encoder.layers.6.bn.num_batches_tracked', 'encoder.layers.7.conv3x1_1.weight', 'encoder.layers.7.conv3x1_1.bias', 'encoder.layers.7.conv1x3_1.weight', 'encoder.layers.7.conv1x3_1.bias', 'encoder.layers.7.bn1.weight', 'encoder.layers.7.bn1.bias', 'encoder.layers.7.bn1.running_mean', 'encoder.layers.7.bn1.running_var', 'encoder.layers.7.bn1.num_batches_tracked', 'encoder.layers.7.conv3x1_2.weight', 'encoder.layers.7.conv3x1_2.bias', 'encoder.layers.7.conv1x3_2.weight', 'encoder.layers.7.conv1x3_2.bias', 'encoder.layers.7.bn2.weight', 'encoder.layers.7.bn2.bias', 'encoder.layers.7.bn2.running_mean', 'encoder.layers.7.bn2.running_var', 'encoder.layers.7.bn2.num_batches_tracked', 'encoder.layers.8.conv3x1_1.weight', 'encoder.layers.8.conv3x1_1.bias', 'encoder.layers.8.conv1x3_1.weight', 'encoder.layers.8.conv1x3_1.bias', 'encoder.layers.8.bn1.weight', 'encoder.layers.8.bn1.bias', 'encoder.layers.8.bn1.running_mean', 'encoder.layers.8.bn1.running_var', 'encoder.layers.8.bn1.num_batches_tracked', 'encoder.layers.8.conv3x1_2.weight', 'encoder.layers.8.conv3x1_2.bias', 'encoder.layers.8.conv1x3_2.weight', 'encoder.layers.8.conv1x3_2.bias', 'encoder.layers.8.bn2.weight', 'encoder.layers.8.bn2.bias', 'encoder.layers.8.bn2.running_mean', 'encoder.layers.8.bn2.running_var', 'encoder.layers.8.bn2.num_batches_tracked', 'encoder.layers.9.conv3x1_1.weight', 'encoder.layers.9.conv3x1_1.bias', 'encoder.layers.9.conv1x3_1.weight', 'encoder.layers.9.conv1x3_1.bias', 'encoder.layers.9.bn1.weight', 'encoder.layers.9.bn1.bias', 'encoder.layers.9.bn1.running_mean', 'encoder.layers.9.bn1.running_var', 'encoder.layers.9.bn1.num_batches_tracked', 'encoder.layers.9.conv3x1_2.weight', 'encoder.layers.9.conv3x1_2.bias', 'encoder.layers.9.conv1x3_2.weight', 'encoder.layers.9.conv1x3_2.bias', 'encoder.layers.9.bn2.weight', 'encoder.layers.9.bn2.bias', 'encoder.layers.9.bn2.running_mean', 'encoder.layers.9.bn2.running_var', 'encoder.layers.9.bn2.num_batches_tracked', 'encoder.layers.10.conv3x1_1.weight', 'encoder.layers.10.conv3x1_1.bias', 'encoder.layers.10.conv1x3_1.weight', 'encoder.layers.10.conv1x3_1.bias', 'encoder.layers.10.bn1.weight', 'encoder.layers.10.bn1.bias', 'encoder.layers.10.bn1.running_mean', 'encoder.layers.10.bn1.running_var', 'encoder.layers.10.bn1.num_batches_tracked', 'encoder.layers.10.conv3x1_2.weight', 'encoder.layers.10.conv3x1_2.bias', 'encoder.layers.10.conv1x3_2.weight', 'encoder.layers.10.conv1x3_2.bias', 'encoder.layers.10.bn2.weight', 'encoder.layers.10.bn2.bias', 'encoder.layers.10.bn2.running_mean', 'encoder.layers.10.bn2.running_var', 'encoder.layers.10.bn2.num_batches_tracked', 'encoder.layers.11.conv3x1_1.weight', 'encoder.layers.11.conv3x1_1.bias', 'encoder.layers.11.conv1x3_1.weight', 'encoder.layers.11.conv1x3_1.bias', 'encoder.layers.11.bn1.weight', 'encoder.layers.11.bn1.bias', 'encoder.layers.11.bn1.running_mean', 'encoder.layers.11.bn1.running_var', 'encoder.layers.11.bn1.num_batches_tracked', 'encoder.layers.11.conv3x1_2.weight', 'encoder.layers.11.conv3x1_2.bias', 'encoder.layers.11.conv1x3_2.weight', 'encoder.layers.11.conv1x3_2.bias', 'encoder.layers.11.bn2.weight', 'encoder.layers.11.bn2.bias', 'encoder.layers.11.bn2.running_mean', 'encoder.layers.11.bn2.running_var', 'encoder.layers.11.bn2.num_batches_tracked', 'encoder.layers.12.conv3x1_1.weight', 'encoder.layers.12.conv3x1_1.bias', 'encoder.layers.12.conv1x3_1.weight', 'encoder.layers.12.conv1x3_1.bias', 'encoder.layers.12.bn1.weight', 'encoder.layers.12.bn1.bias', 'encoder.layers.12.bn1.running_mean', 'encoder.layers.12.bn1.running_var', 'encoder.layers.12.bn1.num_batches_tracked', 'encoder.layers.12.conv3x1_2.weight', 'encoder.layers.12.conv3x1_2.bias', 'encoder.layers.12.conv1x3_2.weight', 'encoder.layers.12.conv1x3_2.bias', 'encoder.layers.12.bn2.weight', 'encoder.layers.12.bn2.bias', 'encoder.layers.12.bn2.running_mean', 'encoder.layers.12.bn2.running_var', 'encoder.layers.12.bn2.num_batches_tracked', 'encoder.layers.13.conv3x1_1.weight', 'encoder.layers.13.conv3x1_1.bias', 'encoder.layers.13.conv1x3_1.weight', 'encoder.layers.13.conv1x3_1.bias', 'encoder.layers.13.bn1.weight', 'encoder.layers.13.bn1.bias', 'encoder.layers.13.bn1.running_mean', 'encoder.layers.13.bn1.running_var', 'encoder.layers.13.bn1.num_batches_tracked', 'encoder.layers.13.conv3x1_2.weight', 'encoder.layers.13.conv3x1_2.bias', 'encoder.layers.13.conv1x3_2.weight', 'encoder.layers.13.conv1x3_2.bias', 'encoder.layers.13.bn2.weight', 'encoder.layers.13.bn2.bias', 'encoder.layers.13.bn2.running_mean', 'encoder.layers.13.bn2.running_var', 'encoder.layers.13.bn2.num_batches_tracked', 'encoder.layers.14.conv3x1_1.weight', 'encoder.layers.14.conv3x1_1.bias', 'encoder.layers.14.conv1x3_1.weight', 'encoder.layers.14.conv1x3_1.bias', 'encoder.layers.14.bn1.weight', 'encoder.layers.14.bn1.bias', 'encoder.layers.14.bn1.running_mean', 'encoder.layers.14.bn1.running_var', 'encoder.layers.14.bn1.num_batches_tracked', 'encoder.layers.14.conv3x1_2.weight', 'encoder.layers.14.conv3x1_2.bias', 'encoder.layers.14.conv1x3_2.weight', 'encoder.layers.14.conv1x3_2.bias', 'encoder.layers.14.bn2.weight', 'encoder.layers.14.bn2.bias', 'encoder.layers.14.bn2.running_mean', 'encoder.layers.14.bn2.running_var', 'encoder.layers.14.bn2.num_batches_tracked', 'encoder.output_conv.weight', 'encoder.output_conv.bias', 'decoder.layers.0.conv.weight', 'decoder.layers.0.conv.bias', 'decoder.layers.0.bn.weight', 'decoder.layers.0.bn.bias', 'decoder.layers.0.bn.running_mean', 'decoder.layers.0.bn.running_var', 'decoder.layers.0.bn.num_batches_tracked', 'decoder.layers.1.conv3x1_1.weight', 'decoder.layers.1.conv3x1_1.bias', 'decoder.layers.1.conv1x3_1.weight', 'decoder.layers.1.conv1x3_1.bias', 'decoder.layers.1.bn1.weight', 'decoder.layers.1.bn1.bias', 'decoder.layers.1.bn1.running_mean', 'decoder.layers.1.bn1.running_var', 'decoder.layers.1.bn1.num_batches_tracked', 'decoder.layers.1.conv3x1_2.weight', 'decoder.layers.1.conv3x1_2.bias', 'decoder.layers.1.conv1x3_2.weight', 'decoder.layers.1.conv1x3_2.bias', 'decoder.layers.1.bn2.weight', 'decoder.layers.1.bn2.bias', 'decoder.layers.1.bn2.running_mean', 'decoder.layers.1.bn2.running_var', 'decoder.layers.1.bn2.num_batches_tracked', 'decoder.layers.2.conv3x1_1.weight', 'decoder.layers.2.conv3x1_1.bias', 'decoder.layers.2.conv1x3_1.weight', 'decoder.layers.2.conv1x3_1.bias', 'decoder.layers.2.bn1.weight', 'decoder.layers.2.bn1.bias', 'decoder.layers.2.bn1.running_mean', 'decoder.layers.2.bn1.running_var', 'decoder.layers.2.bn1.num_batches_tracked', 'decoder.layers.2.conv3x1_2.weight', 'decoder.layers.2.conv3x1_2.bias', 'decoder.layers.2.conv1x3_2.weight', 'decoder.layers.2.conv1x3_2.bias', 'decoder.layers.2.bn2.weight', 'decoder.layers.2.bn2.bias', 'decoder.layers.2.bn2.running_mean', 'decoder.layers.2.bn2.running_var', 'decoder.layers.2.bn2.num_batches_tracked', 'decoder.layers.3.conv.weight', 'decoder.layers.3.conv.bias', 'decoder.layers.3.bn.weight', 'decoder.layers.3.bn.bias', 'decoder.layers.3.bn.running_mean', 'decoder.layers.3.bn.running_var', 'decoder.layers.3.bn.num_batches_tracked', 'decoder.layers.4.conv3x1_1.weight', 'decoder.layers.4.conv3x1_1.bias', 'decoder.layers.4.conv1x3_1.weight', 'decoder.layers.4.conv1x3_1.bias', 'decoder.layers.4.bn1.weight', 'decoder.layers.4.bn1.bias', 'decoder.layers.4.bn1.running_mean', 'decoder.layers.4.bn1.running_var', 'decoder.layers.4.bn1.num_batches_tracked', 'decoder.layers.4.conv3x1_2.weight', 'decoder.layers.4.conv3x1_2.bias', 'decoder.layers.4.conv1x3_2.weight', 'decoder.layers.4.conv1x3_2.bias', 'decoder.layers.4.bn2.weight', 'decoder.layers.4.bn2.bias', 'decoder.layers.4.bn2.running_mean', 'decoder.layers.4.bn2.running_var', 'decoder.layers.4.bn2.num_batches_tracked', 'decoder.layers.5.conv3x1_1.weight', 'decoder.layers.5.conv3x1_1.bias', 'decoder.layers.5.conv1x3_1.weight', 'decoder.layers.5.conv1x3_1.bias', 'decoder.layers.5.bn1.weight', 'decoder.layers.5.bn1.bias', 'decoder.layers.5.bn1.running_mean', 'decoder.layers.5.bn1.running_var', 'decoder.layers.5.bn1.num_batches_tracked', 'decoder.layers.5.conv3x1_2.weight', 'decoder.layers.5.conv3x1_2.bias', 'decoder.layers.5.conv1x3_2.weight', 'decoder.layers.5.conv1x3_2.bias', 'decoder.layers.5.bn2.weight', 'decoder.layers.5.bn2.bias', 'decoder.layers.5.bn2.running_mean', 'decoder.layers.5.bn2.running_var', 'decoder.layers.5.bn2.num_batches_tracked', 'decoder.output_conv.weight', 'decoder.output_conv.bias'])\n",
            "Import Model erfnet with weights erfnet_pretrained.pth to FineTune\n",
            "========== TRAINING ===========\n",
            "/content/cityscapes/leftImg8bit/train\n",
            "/content/cityscapes/leftImg8bit/val\n",
            "----- TRAINING - EPOCH 1 -----\n",
            "LEARNING RATE:  5e-05\n",
            "loss: 0.6448 (epoch: 1, step: 0) // Avg time/img: 0.2650 s\n",
            "\n",
            "Model saved in /content/AnomalySegmentation/save/erfnet_training\n",
            "updating: content/AnomalySegmentation/save/erfnet_training/ (stored 0%)\n",
            "updating: content/AnomalySegmentation/save/erfnet_training/opts.txt (deflated 37%)\n",
            "updating: content/AnomalySegmentation/save/erfnet_training/model.txt (deflated 92%)\n",
            "updating: content/AnomalySegmentation/save/erfnet_training/automated_log.txt (deflated 27%)\n"
          ]
        }
      ],
      "source": [
        "# Fine-tune ERFNet for VOID classification using CrossEntropy\n",
        "\n",
        "model = \"erfnet\"\n",
        "savedir = \"erfnet_training\"\n",
        "pretrained_weights = \"erfnet_pretrained.pth\"\n",
        "epochs = 20\n",
        "\n",
        "# Base directory of the project\n",
        "base_dir = \"/content/AnomalySegmentation/train\"\n",
        "# Dataset directory\n",
        "data_dir = \"/content/cityscapes\"\n",
        "\n",
        "print(f\"----- Fine-tuning {model} for VOID classification -----\")\n",
        "!cd {base_dir} && python -W ignore main.py --savedir {savedir} --datadir {data_dir} --model {model} --cuda --num-epochs=20 --epochs-save=1 --FineTune --decoder --loadWeights={pretrained_weights}\n",
        "print(f\"Model saved in /content/AnomalySegmentation/save/{savedir}\")\n",
        "# zip folder\n",
        "!zip -r save_{savedir}.zip /content/AnomalySegmentation/save/{savedir}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOFE1m7pVyfZ",
        "outputId": "0026000f-99e6-4261-9e72-e22610569144"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----- Fine-tuning enet for VOID classification -----\n",
            "odict_keys(['initial_block.main_branch.weight', 'initial_block.batch_norm.weight', 'initial_block.batch_norm.bias', 'initial_block.batch_norm.running_mean', 'initial_block.batch_norm.running_var', 'initial_block.batch_norm.num_batches_tracked', 'initial_block.out_activation.weight', 'downsample1_0.ext_conv1.0.weight', 'downsample1_0.ext_conv1.1.weight', 'downsample1_0.ext_conv1.1.bias', 'downsample1_0.ext_conv1.1.running_mean', 'downsample1_0.ext_conv1.1.running_var', 'downsample1_0.ext_conv1.1.num_batches_tracked', 'downsample1_0.ext_conv1.2.weight', 'downsample1_0.ext_conv2.0.weight', 'downsample1_0.ext_conv2.1.weight', 'downsample1_0.ext_conv2.1.bias', 'downsample1_0.ext_conv2.1.running_mean', 'downsample1_0.ext_conv2.1.running_var', 'downsample1_0.ext_conv2.1.num_batches_tracked', 'downsample1_0.ext_conv2.2.weight', 'downsample1_0.ext_conv3.0.weight', 'downsample1_0.ext_conv3.1.weight', 'downsample1_0.ext_conv3.1.bias', 'downsample1_0.ext_conv3.1.running_mean', 'downsample1_0.ext_conv3.1.running_var', 'downsample1_0.ext_conv3.1.num_batches_tracked', 'downsample1_0.ext_conv3.2.weight', 'downsample1_0.out_activation.weight', 'regular1_1.ext_conv1.0.weight', 'regular1_1.ext_conv1.1.weight', 'regular1_1.ext_conv1.1.bias', 'regular1_1.ext_conv1.1.running_mean', 'regular1_1.ext_conv1.1.running_var', 'regular1_1.ext_conv1.1.num_batches_tracked', 'regular1_1.ext_conv1.2.weight', 'regular1_1.ext_conv2.0.weight', 'regular1_1.ext_conv2.1.weight', 'regular1_1.ext_conv2.1.bias', 'regular1_1.ext_conv2.1.running_mean', 'regular1_1.ext_conv2.1.running_var', 'regular1_1.ext_conv2.1.num_batches_tracked', 'regular1_1.ext_conv2.2.weight', 'regular1_1.ext_conv3.0.weight', 'regular1_1.ext_conv3.1.weight', 'regular1_1.ext_conv3.1.bias', 'regular1_1.ext_conv3.1.running_mean', 'regular1_1.ext_conv3.1.running_var', 'regular1_1.ext_conv3.1.num_batches_tracked', 'regular1_1.ext_conv3.2.weight', 'regular1_1.out_activation.weight', 'regular1_2.ext_conv1.0.weight', 'regular1_2.ext_conv1.1.weight', 'regular1_2.ext_conv1.1.bias', 'regular1_2.ext_conv1.1.running_mean', 'regular1_2.ext_conv1.1.running_var', 'regular1_2.ext_conv1.1.num_batches_tracked', 'regular1_2.ext_conv1.2.weight', 'regular1_2.ext_conv2.0.weight', 'regular1_2.ext_conv2.1.weight', 'regular1_2.ext_conv2.1.bias', 'regular1_2.ext_conv2.1.running_mean', 'regular1_2.ext_conv2.1.running_var', 'regular1_2.ext_conv2.1.num_batches_tracked', 'regular1_2.ext_conv2.2.weight', 'regular1_2.ext_conv3.0.weight', 'regular1_2.ext_conv3.1.weight', 'regular1_2.ext_conv3.1.bias', 'regular1_2.ext_conv3.1.running_mean', 'regular1_2.ext_conv3.1.running_var', 'regular1_2.ext_conv3.1.num_batches_tracked', 'regular1_2.ext_conv3.2.weight', 'regular1_2.out_activation.weight', 'regular1_3.ext_conv1.0.weight', 'regular1_3.ext_conv1.1.weight', 'regular1_3.ext_conv1.1.bias', 'regular1_3.ext_conv1.1.running_mean', 'regular1_3.ext_conv1.1.running_var', 'regular1_3.ext_conv1.1.num_batches_tracked', 'regular1_3.ext_conv1.2.weight', 'regular1_3.ext_conv2.0.weight', 'regular1_3.ext_conv2.1.weight', 'regular1_3.ext_conv2.1.bias', 'regular1_3.ext_conv2.1.running_mean', 'regular1_3.ext_conv2.1.running_var', 'regular1_3.ext_conv2.1.num_batches_tracked', 'regular1_3.ext_conv2.2.weight', 'regular1_3.ext_conv3.0.weight', 'regular1_3.ext_conv3.1.weight', 'regular1_3.ext_conv3.1.bias', 'regular1_3.ext_conv3.1.running_mean', 'regular1_3.ext_conv3.1.running_var', 'regular1_3.ext_conv3.1.num_batches_tracked', 'regular1_3.ext_conv3.2.weight', 'regular1_3.out_activation.weight', 'regular1_4.ext_conv1.0.weight', 'regular1_4.ext_conv1.1.weight', 'regular1_4.ext_conv1.1.bias', 'regular1_4.ext_conv1.1.running_mean', 'regular1_4.ext_conv1.1.running_var', 'regular1_4.ext_conv1.1.num_batches_tracked', 'regular1_4.ext_conv1.2.weight', 'regular1_4.ext_conv2.0.weight', 'regular1_4.ext_conv2.1.weight', 'regular1_4.ext_conv2.1.bias', 'regular1_4.ext_conv2.1.running_mean', 'regular1_4.ext_conv2.1.running_var', 'regular1_4.ext_conv2.1.num_batches_tracked', 'regular1_4.ext_conv2.2.weight', 'regular1_4.ext_conv3.0.weight', 'regular1_4.ext_conv3.1.weight', 'regular1_4.ext_conv3.1.bias', 'regular1_4.ext_conv3.1.running_mean', 'regular1_4.ext_conv3.1.running_var', 'regular1_4.ext_conv3.1.num_batches_tracked', 'regular1_4.ext_conv3.2.weight', 'regular1_4.out_activation.weight', 'downsample2_0.ext_conv1.0.weight', 'downsample2_0.ext_conv1.1.weight', 'downsample2_0.ext_conv1.1.bias', 'downsample2_0.ext_conv1.1.running_mean', 'downsample2_0.ext_conv1.1.running_var', 'downsample2_0.ext_conv1.1.num_batches_tracked', 'downsample2_0.ext_conv1.2.weight', 'downsample2_0.ext_conv2.0.weight', 'downsample2_0.ext_conv2.1.weight', 'downsample2_0.ext_conv2.1.bias', 'downsample2_0.ext_conv2.1.running_mean', 'downsample2_0.ext_conv2.1.running_var', 'downsample2_0.ext_conv2.1.num_batches_tracked', 'downsample2_0.ext_conv2.2.weight', 'downsample2_0.ext_conv3.0.weight', 'downsample2_0.ext_conv3.1.weight', 'downsample2_0.ext_conv3.1.bias', 'downsample2_0.ext_conv3.1.running_mean', 'downsample2_0.ext_conv3.1.running_var', 'downsample2_0.ext_conv3.1.num_batches_tracked', 'downsample2_0.ext_conv3.2.weight', 'downsample2_0.out_activation.weight', 'regular2_1.ext_conv1.0.weight', 'regular2_1.ext_conv1.1.weight', 'regular2_1.ext_conv1.1.bias', 'regular2_1.ext_conv1.1.running_mean', 'regular2_1.ext_conv1.1.running_var', 'regular2_1.ext_conv1.1.num_batches_tracked', 'regular2_1.ext_conv1.2.weight', 'regular2_1.ext_conv2.0.weight', 'regular2_1.ext_conv2.1.weight', 'regular2_1.ext_conv2.1.bias', 'regular2_1.ext_conv2.1.running_mean', 'regular2_1.ext_conv2.1.running_var', 'regular2_1.ext_conv2.1.num_batches_tracked', 'regular2_1.ext_conv2.2.weight', 'regular2_1.ext_conv3.0.weight', 'regular2_1.ext_conv3.1.weight', 'regular2_1.ext_conv3.1.bias', 'regular2_1.ext_conv3.1.running_mean', 'regular2_1.ext_conv3.1.running_var', 'regular2_1.ext_conv3.1.num_batches_tracked', 'regular2_1.ext_conv3.2.weight', 'regular2_1.out_activation.weight', 'dilated2_2.ext_conv1.0.weight', 'dilated2_2.ext_conv1.1.weight', 'dilated2_2.ext_conv1.1.bias', 'dilated2_2.ext_conv1.1.running_mean', 'dilated2_2.ext_conv1.1.running_var', 'dilated2_2.ext_conv1.1.num_batches_tracked', 'dilated2_2.ext_conv1.2.weight', 'dilated2_2.ext_conv2.0.weight', 'dilated2_2.ext_conv2.1.weight', 'dilated2_2.ext_conv2.1.bias', 'dilated2_2.ext_conv2.1.running_mean', 'dilated2_2.ext_conv2.1.running_var', 'dilated2_2.ext_conv2.1.num_batches_tracked', 'dilated2_2.ext_conv2.2.weight', 'dilated2_2.ext_conv3.0.weight', 'dilated2_2.ext_conv3.1.weight', 'dilated2_2.ext_conv3.1.bias', 'dilated2_2.ext_conv3.1.running_mean', 'dilated2_2.ext_conv3.1.running_var', 'dilated2_2.ext_conv3.1.num_batches_tracked', 'dilated2_2.ext_conv3.2.weight', 'dilated2_2.out_activation.weight', 'asymmetric2_3.ext_conv1.0.weight', 'asymmetric2_3.ext_conv1.1.weight', 'asymmetric2_3.ext_conv1.1.bias', 'asymmetric2_3.ext_conv1.1.running_mean', 'asymmetric2_3.ext_conv1.1.running_var', 'asymmetric2_3.ext_conv1.1.num_batches_tracked', 'asymmetric2_3.ext_conv1.2.weight', 'asymmetric2_3.ext_conv2.0.weight', 'asymmetric2_3.ext_conv2.1.weight', 'asymmetric2_3.ext_conv2.1.bias', 'asymmetric2_3.ext_conv2.1.running_mean', 'asymmetric2_3.ext_conv2.1.running_var', 'asymmetric2_3.ext_conv2.1.num_batches_tracked', 'asymmetric2_3.ext_conv2.2.weight', 'asymmetric2_3.ext_conv2.3.weight', 'asymmetric2_3.ext_conv2.4.weight', 'asymmetric2_3.ext_conv2.4.bias', 'asymmetric2_3.ext_conv2.4.running_mean', 'asymmetric2_3.ext_conv2.4.running_var', 'asymmetric2_3.ext_conv2.4.num_batches_tracked', 'asymmetric2_3.ext_conv2.5.weight', 'asymmetric2_3.ext_conv3.0.weight', 'asymmetric2_3.ext_conv3.1.weight', 'asymmetric2_3.ext_conv3.1.bias', 'asymmetric2_3.ext_conv3.1.running_mean', 'asymmetric2_3.ext_conv3.1.running_var', 'asymmetric2_3.ext_conv3.1.num_batches_tracked', 'asymmetric2_3.ext_conv3.2.weight', 'asymmetric2_3.out_activation.weight', 'dilated2_4.ext_conv1.0.weight', 'dilated2_4.ext_conv1.1.weight', 'dilated2_4.ext_conv1.1.bias', 'dilated2_4.ext_conv1.1.running_mean', 'dilated2_4.ext_conv1.1.running_var', 'dilated2_4.ext_conv1.1.num_batches_tracked', 'dilated2_4.ext_conv1.2.weight', 'dilated2_4.ext_conv2.0.weight', 'dilated2_4.ext_conv2.1.weight', 'dilated2_4.ext_conv2.1.bias', 'dilated2_4.ext_conv2.1.running_mean', 'dilated2_4.ext_conv2.1.running_var', 'dilated2_4.ext_conv2.1.num_batches_tracked', 'dilated2_4.ext_conv2.2.weight', 'dilated2_4.ext_conv3.0.weight', 'dilated2_4.ext_conv3.1.weight', 'dilated2_4.ext_conv3.1.bias', 'dilated2_4.ext_conv3.1.running_mean', 'dilated2_4.ext_conv3.1.running_var', 'dilated2_4.ext_conv3.1.num_batches_tracked', 'dilated2_4.ext_conv3.2.weight', 'dilated2_4.out_activation.weight', 'regular2_5.ext_conv1.0.weight', 'regular2_5.ext_conv1.1.weight', 'regular2_5.ext_conv1.1.bias', 'regular2_5.ext_conv1.1.running_mean', 'regular2_5.ext_conv1.1.running_var', 'regular2_5.ext_conv1.1.num_batches_tracked', 'regular2_5.ext_conv1.2.weight', 'regular2_5.ext_conv2.0.weight', 'regular2_5.ext_conv2.1.weight', 'regular2_5.ext_conv2.1.bias', 'regular2_5.ext_conv2.1.running_mean', 'regular2_5.ext_conv2.1.running_var', 'regular2_5.ext_conv2.1.num_batches_tracked', 'regular2_5.ext_conv2.2.weight', 'regular2_5.ext_conv3.0.weight', 'regular2_5.ext_conv3.1.weight', 'regular2_5.ext_conv3.1.bias', 'regular2_5.ext_conv3.1.running_mean', 'regular2_5.ext_conv3.1.running_var', 'regular2_5.ext_conv3.1.num_batches_tracked', 'regular2_5.ext_conv3.2.weight', 'regular2_5.out_activation.weight', 'dilated2_6.ext_conv1.0.weight', 'dilated2_6.ext_conv1.1.weight', 'dilated2_6.ext_conv1.1.bias', 'dilated2_6.ext_conv1.1.running_mean', 'dilated2_6.ext_conv1.1.running_var', 'dilated2_6.ext_conv1.1.num_batches_tracked', 'dilated2_6.ext_conv1.2.weight', 'dilated2_6.ext_conv2.0.weight', 'dilated2_6.ext_conv2.1.weight', 'dilated2_6.ext_conv2.1.bias', 'dilated2_6.ext_conv2.1.running_mean', 'dilated2_6.ext_conv2.1.running_var', 'dilated2_6.ext_conv2.1.num_batches_tracked', 'dilated2_6.ext_conv2.2.weight', 'dilated2_6.ext_conv3.0.weight', 'dilated2_6.ext_conv3.1.weight', 'dilated2_6.ext_conv3.1.bias', 'dilated2_6.ext_conv3.1.running_mean', 'dilated2_6.ext_conv3.1.running_var', 'dilated2_6.ext_conv3.1.num_batches_tracked', 'dilated2_6.ext_conv3.2.weight', 'dilated2_6.out_activation.weight', 'asymmetric2_7.ext_conv1.0.weight', 'asymmetric2_7.ext_conv1.1.weight', 'asymmetric2_7.ext_conv1.1.bias', 'asymmetric2_7.ext_conv1.1.running_mean', 'asymmetric2_7.ext_conv1.1.running_var', 'asymmetric2_7.ext_conv1.1.num_batches_tracked', 'asymmetric2_7.ext_conv1.2.weight', 'asymmetric2_7.ext_conv2.0.weight', 'asymmetric2_7.ext_conv2.1.weight', 'asymmetric2_7.ext_conv2.1.bias', 'asymmetric2_7.ext_conv2.1.running_mean', 'asymmetric2_7.ext_conv2.1.running_var', 'asymmetric2_7.ext_conv2.1.num_batches_tracked', 'asymmetric2_7.ext_conv2.2.weight', 'asymmetric2_7.ext_conv2.3.weight', 'asymmetric2_7.ext_conv2.4.weight', 'asymmetric2_7.ext_conv2.4.bias', 'asymmetric2_7.ext_conv2.4.running_mean', 'asymmetric2_7.ext_conv2.4.running_var', 'asymmetric2_7.ext_conv2.4.num_batches_tracked', 'asymmetric2_7.ext_conv2.5.weight', 'asymmetric2_7.ext_conv3.0.weight', 'asymmetric2_7.ext_conv3.1.weight', 'asymmetric2_7.ext_conv3.1.bias', 'asymmetric2_7.ext_conv3.1.running_mean', 'asymmetric2_7.ext_conv3.1.running_var', 'asymmetric2_7.ext_conv3.1.num_batches_tracked', 'asymmetric2_7.ext_conv3.2.weight', 'asymmetric2_7.out_activation.weight', 'dilated2_8.ext_conv1.0.weight', 'dilated2_8.ext_conv1.1.weight', 'dilated2_8.ext_conv1.1.bias', 'dilated2_8.ext_conv1.1.running_mean', 'dilated2_8.ext_conv1.1.running_var', 'dilated2_8.ext_conv1.1.num_batches_tracked', 'dilated2_8.ext_conv1.2.weight', 'dilated2_8.ext_conv2.0.weight', 'dilated2_8.ext_conv2.1.weight', 'dilated2_8.ext_conv2.1.bias', 'dilated2_8.ext_conv2.1.running_mean', 'dilated2_8.ext_conv2.1.running_var', 'dilated2_8.ext_conv2.1.num_batches_tracked', 'dilated2_8.ext_conv2.2.weight', 'dilated2_8.ext_conv3.0.weight', 'dilated2_8.ext_conv3.1.weight', 'dilated2_8.ext_conv3.1.bias', 'dilated2_8.ext_conv3.1.running_mean', 'dilated2_8.ext_conv3.1.running_var', 'dilated2_8.ext_conv3.1.num_batches_tracked', 'dilated2_8.ext_conv3.2.weight', 'dilated2_8.out_activation.weight', 'regular3_0.ext_conv1.0.weight', 'regular3_0.ext_conv1.1.weight', 'regular3_0.ext_conv1.1.bias', 'regular3_0.ext_conv1.1.running_mean', 'regular3_0.ext_conv1.1.running_var', 'regular3_0.ext_conv1.1.num_batches_tracked', 'regular3_0.ext_conv1.2.weight', 'regular3_0.ext_conv2.0.weight', 'regular3_0.ext_conv2.1.weight', 'regular3_0.ext_conv2.1.bias', 'regular3_0.ext_conv2.1.running_mean', 'regular3_0.ext_conv2.1.running_var', 'regular3_0.ext_conv2.1.num_batches_tracked', 'regular3_0.ext_conv2.2.weight', 'regular3_0.ext_conv3.0.weight', 'regular3_0.ext_conv3.1.weight', 'regular3_0.ext_conv3.1.bias', 'regular3_0.ext_conv3.1.running_mean', 'regular3_0.ext_conv3.1.running_var', 'regular3_0.ext_conv3.1.num_batches_tracked', 'regular3_0.ext_conv3.2.weight', 'regular3_0.out_activation.weight', 'dilated3_1.ext_conv1.0.weight', 'dilated3_1.ext_conv1.1.weight', 'dilated3_1.ext_conv1.1.bias', 'dilated3_1.ext_conv1.1.running_mean', 'dilated3_1.ext_conv1.1.running_var', 'dilated3_1.ext_conv1.1.num_batches_tracked', 'dilated3_1.ext_conv1.2.weight', 'dilated3_1.ext_conv2.0.weight', 'dilated3_1.ext_conv2.1.weight', 'dilated3_1.ext_conv2.1.bias', 'dilated3_1.ext_conv2.1.running_mean', 'dilated3_1.ext_conv2.1.running_var', 'dilated3_1.ext_conv2.1.num_batches_tracked', 'dilated3_1.ext_conv2.2.weight', 'dilated3_1.ext_conv3.0.weight', 'dilated3_1.ext_conv3.1.weight', 'dilated3_1.ext_conv3.1.bias', 'dilated3_1.ext_conv3.1.running_mean', 'dilated3_1.ext_conv3.1.running_var', 'dilated3_1.ext_conv3.1.num_batches_tracked', 'dilated3_1.ext_conv3.2.weight', 'dilated3_1.out_activation.weight', 'asymmetric3_2.ext_conv1.0.weight', 'asymmetric3_2.ext_conv1.1.weight', 'asymmetric3_2.ext_conv1.1.bias', 'asymmetric3_2.ext_conv1.1.running_mean', 'asymmetric3_2.ext_conv1.1.running_var', 'asymmetric3_2.ext_conv1.1.num_batches_tracked', 'asymmetric3_2.ext_conv1.2.weight', 'asymmetric3_2.ext_conv2.0.weight', 'asymmetric3_2.ext_conv2.1.weight', 'asymmetric3_2.ext_conv2.1.bias', 'asymmetric3_2.ext_conv2.1.running_mean', 'asymmetric3_2.ext_conv2.1.running_var', 'asymmetric3_2.ext_conv2.1.num_batches_tracked', 'asymmetric3_2.ext_conv2.2.weight', 'asymmetric3_2.ext_conv2.3.weight', 'asymmetric3_2.ext_conv2.4.weight', 'asymmetric3_2.ext_conv2.4.bias', 'asymmetric3_2.ext_conv2.4.running_mean', 'asymmetric3_2.ext_conv2.4.running_var', 'asymmetric3_2.ext_conv2.4.num_batches_tracked', 'asymmetric3_2.ext_conv2.5.weight', 'asymmetric3_2.ext_conv3.0.weight', 'asymmetric3_2.ext_conv3.1.weight', 'asymmetric3_2.ext_conv3.1.bias', 'asymmetric3_2.ext_conv3.1.running_mean', 'asymmetric3_2.ext_conv3.1.running_var', 'asymmetric3_2.ext_conv3.1.num_batches_tracked', 'asymmetric3_2.ext_conv3.2.weight', 'asymmetric3_2.out_activation.weight', 'dilated3_3.ext_conv1.0.weight', 'dilated3_3.ext_conv1.1.weight', 'dilated3_3.ext_conv1.1.bias', 'dilated3_3.ext_conv1.1.running_mean', 'dilated3_3.ext_conv1.1.running_var', 'dilated3_3.ext_conv1.1.num_batches_tracked', 'dilated3_3.ext_conv1.2.weight', 'dilated3_3.ext_conv2.0.weight', 'dilated3_3.ext_conv2.1.weight', 'dilated3_3.ext_conv2.1.bias', 'dilated3_3.ext_conv2.1.running_mean', 'dilated3_3.ext_conv2.1.running_var', 'dilated3_3.ext_conv2.1.num_batches_tracked', 'dilated3_3.ext_conv2.2.weight', 'dilated3_3.ext_conv3.0.weight', 'dilated3_3.ext_conv3.1.weight', 'dilated3_3.ext_conv3.1.bias', 'dilated3_3.ext_conv3.1.running_mean', 'dilated3_3.ext_conv3.1.running_var', 'dilated3_3.ext_conv3.1.num_batches_tracked', 'dilated3_3.ext_conv3.2.weight', 'dilated3_3.out_activation.weight', 'regular3_4.ext_conv1.0.weight', 'regular3_4.ext_conv1.1.weight', 'regular3_4.ext_conv1.1.bias', 'regular3_4.ext_conv1.1.running_mean', 'regular3_4.ext_conv1.1.running_var', 'regular3_4.ext_conv1.1.num_batches_tracked', 'regular3_4.ext_conv1.2.weight', 'regular3_4.ext_conv2.0.weight', 'regular3_4.ext_conv2.1.weight', 'regular3_4.ext_conv2.1.bias', 'regular3_4.ext_conv2.1.running_mean', 'regular3_4.ext_conv2.1.running_var', 'regular3_4.ext_conv2.1.num_batches_tracked', 'regular3_4.ext_conv2.2.weight', 'regular3_4.ext_conv3.0.weight', 'regular3_4.ext_conv3.1.weight', 'regular3_4.ext_conv3.1.bias', 'regular3_4.ext_conv3.1.running_mean', 'regular3_4.ext_conv3.1.running_var', 'regular3_4.ext_conv3.1.num_batches_tracked', 'regular3_4.ext_conv3.2.weight', 'regular3_4.out_activation.weight', 'dilated3_5.ext_conv1.0.weight', 'dilated3_5.ext_conv1.1.weight', 'dilated3_5.ext_conv1.1.bias', 'dilated3_5.ext_conv1.1.running_mean', 'dilated3_5.ext_conv1.1.running_var', 'dilated3_5.ext_conv1.1.num_batches_tracked', 'dilated3_5.ext_conv1.2.weight', 'dilated3_5.ext_conv2.0.weight', 'dilated3_5.ext_conv2.1.weight', 'dilated3_5.ext_conv2.1.bias', 'dilated3_5.ext_conv2.1.running_mean', 'dilated3_5.ext_conv2.1.running_var', 'dilated3_5.ext_conv2.1.num_batches_tracked', 'dilated3_5.ext_conv2.2.weight', 'dilated3_5.ext_conv3.0.weight', 'dilated3_5.ext_conv3.1.weight', 'dilated3_5.ext_conv3.1.bias', 'dilated3_5.ext_conv3.1.running_mean', 'dilated3_5.ext_conv3.1.running_var', 'dilated3_5.ext_conv3.1.num_batches_tracked', 'dilated3_5.ext_conv3.2.weight', 'dilated3_5.out_activation.weight', 'asymmetric3_6.ext_conv1.0.weight', 'asymmetric3_6.ext_conv1.1.weight', 'asymmetric3_6.ext_conv1.1.bias', 'asymmetric3_6.ext_conv1.1.running_mean', 'asymmetric3_6.ext_conv1.1.running_var', 'asymmetric3_6.ext_conv1.1.num_batches_tracked', 'asymmetric3_6.ext_conv1.2.weight', 'asymmetric3_6.ext_conv2.0.weight', 'asymmetric3_6.ext_conv2.1.weight', 'asymmetric3_6.ext_conv2.1.bias', 'asymmetric3_6.ext_conv2.1.running_mean', 'asymmetric3_6.ext_conv2.1.running_var', 'asymmetric3_6.ext_conv2.1.num_batches_tracked', 'asymmetric3_6.ext_conv2.2.weight', 'asymmetric3_6.ext_conv2.3.weight', 'asymmetric3_6.ext_conv2.4.weight', 'asymmetric3_6.ext_conv2.4.bias', 'asymmetric3_6.ext_conv2.4.running_mean', 'asymmetric3_6.ext_conv2.4.running_var', 'asymmetric3_6.ext_conv2.4.num_batches_tracked', 'asymmetric3_6.ext_conv2.5.weight', 'asymmetric3_6.ext_conv3.0.weight', 'asymmetric3_6.ext_conv3.1.weight', 'asymmetric3_6.ext_conv3.1.bias', 'asymmetric3_6.ext_conv3.1.running_mean', 'asymmetric3_6.ext_conv3.1.running_var', 'asymmetric3_6.ext_conv3.1.num_batches_tracked', 'asymmetric3_6.ext_conv3.2.weight', 'asymmetric3_6.out_activation.weight', 'dilated3_7.ext_conv1.0.weight', 'dilated3_7.ext_conv1.1.weight', 'dilated3_7.ext_conv1.1.bias', 'dilated3_7.ext_conv1.1.running_mean', 'dilated3_7.ext_conv1.1.running_var', 'dilated3_7.ext_conv1.1.num_batches_tracked', 'dilated3_7.ext_conv1.2.weight', 'dilated3_7.ext_conv2.0.weight', 'dilated3_7.ext_conv2.1.weight', 'dilated3_7.ext_conv2.1.bias', 'dilated3_7.ext_conv2.1.running_mean', 'dilated3_7.ext_conv2.1.running_var', 'dilated3_7.ext_conv2.1.num_batches_tracked', 'dilated3_7.ext_conv2.2.weight', 'dilated3_7.ext_conv3.0.weight', 'dilated3_7.ext_conv3.1.weight', 'dilated3_7.ext_conv3.1.bias', 'dilated3_7.ext_conv3.1.running_mean', 'dilated3_7.ext_conv3.1.running_var', 'dilated3_7.ext_conv3.1.num_batches_tracked', 'dilated3_7.ext_conv3.2.weight', 'dilated3_7.out_activation.weight', 'upsample4_0.main_conv1.0.weight', 'upsample4_0.main_conv1.1.weight', 'upsample4_0.main_conv1.1.bias', 'upsample4_0.main_conv1.1.running_mean', 'upsample4_0.main_conv1.1.running_var', 'upsample4_0.main_conv1.1.num_batches_tracked', 'upsample4_0.ext_conv1.0.weight', 'upsample4_0.ext_conv1.1.weight', 'upsample4_0.ext_conv1.1.bias', 'upsample4_0.ext_conv1.1.running_mean', 'upsample4_0.ext_conv1.1.running_var', 'upsample4_0.ext_conv1.1.num_batches_tracked', 'upsample4_0.ext_tconv1.weight', 'upsample4_0.ext_tconv1_bnorm.weight', 'upsample4_0.ext_tconv1_bnorm.bias', 'upsample4_0.ext_tconv1_bnorm.running_mean', 'upsample4_0.ext_tconv1_bnorm.running_var', 'upsample4_0.ext_tconv1_bnorm.num_batches_tracked', 'upsample4_0.ext_conv2.0.weight', 'upsample4_0.ext_conv2.1.weight', 'upsample4_0.ext_conv2.1.bias', 'upsample4_0.ext_conv2.1.running_mean', 'upsample4_0.ext_conv2.1.running_var', 'upsample4_0.ext_conv2.1.num_batches_tracked', 'regular4_1.ext_conv1.0.weight', 'regular4_1.ext_conv1.1.weight', 'regular4_1.ext_conv1.1.bias', 'regular4_1.ext_conv1.1.running_mean', 'regular4_1.ext_conv1.1.running_var', 'regular4_1.ext_conv1.1.num_batches_tracked', 'regular4_1.ext_conv2.0.weight', 'regular4_1.ext_conv2.1.weight', 'regular4_1.ext_conv2.1.bias', 'regular4_1.ext_conv2.1.running_mean', 'regular4_1.ext_conv2.1.running_var', 'regular4_1.ext_conv2.1.num_batches_tracked', 'regular4_1.ext_conv3.0.weight', 'regular4_1.ext_conv3.1.weight', 'regular4_1.ext_conv3.1.bias', 'regular4_1.ext_conv3.1.running_mean', 'regular4_1.ext_conv3.1.running_var', 'regular4_1.ext_conv3.1.num_batches_tracked', 'regular4_2.ext_conv1.0.weight', 'regular4_2.ext_conv1.1.weight', 'regular4_2.ext_conv1.1.bias', 'regular4_2.ext_conv1.1.running_mean', 'regular4_2.ext_conv1.1.running_var', 'regular4_2.ext_conv1.1.num_batches_tracked', 'regular4_2.ext_conv2.0.weight', 'regular4_2.ext_conv2.1.weight', 'regular4_2.ext_conv2.1.bias', 'regular4_2.ext_conv2.1.running_mean', 'regular4_2.ext_conv2.1.running_var', 'regular4_2.ext_conv2.1.num_batches_tracked', 'regular4_2.ext_conv3.0.weight', 'regular4_2.ext_conv3.1.weight', 'regular4_2.ext_conv3.1.bias', 'regular4_2.ext_conv3.1.running_mean', 'regular4_2.ext_conv3.1.running_var', 'regular4_2.ext_conv3.1.num_batches_tracked', 'upsample5_0.main_conv1.0.weight', 'upsample5_0.main_conv1.1.weight', 'upsample5_0.main_conv1.1.bias', 'upsample5_0.main_conv1.1.running_mean', 'upsample5_0.main_conv1.1.running_var', 'upsample5_0.main_conv1.1.num_batches_tracked', 'upsample5_0.ext_conv1.0.weight', 'upsample5_0.ext_conv1.1.weight', 'upsample5_0.ext_conv1.1.bias', 'upsample5_0.ext_conv1.1.running_mean', 'upsample5_0.ext_conv1.1.running_var', 'upsample5_0.ext_conv1.1.num_batches_tracked', 'upsample5_0.ext_tconv1.weight', 'upsample5_0.ext_tconv1_bnorm.weight', 'upsample5_0.ext_tconv1_bnorm.bias', 'upsample5_0.ext_tconv1_bnorm.running_mean', 'upsample5_0.ext_tconv1_bnorm.running_var', 'upsample5_0.ext_tconv1_bnorm.num_batches_tracked', 'upsample5_0.ext_conv2.0.weight', 'upsample5_0.ext_conv2.1.weight', 'upsample5_0.ext_conv2.1.bias', 'upsample5_0.ext_conv2.1.running_mean', 'upsample5_0.ext_conv2.1.running_var', 'upsample5_0.ext_conv2.1.num_batches_tracked', 'regular5_1.ext_conv1.0.weight', 'regular5_1.ext_conv1.1.weight', 'regular5_1.ext_conv1.1.bias', 'regular5_1.ext_conv1.1.running_mean', 'regular5_1.ext_conv1.1.running_var', 'regular5_1.ext_conv1.1.num_batches_tracked', 'regular5_1.ext_conv2.0.weight', 'regular5_1.ext_conv2.1.weight', 'regular5_1.ext_conv2.1.bias', 'regular5_1.ext_conv2.1.running_mean', 'regular5_1.ext_conv2.1.running_var', 'regular5_1.ext_conv2.1.num_batches_tracked', 'regular5_1.ext_conv3.0.weight', 'regular5_1.ext_conv3.1.weight', 'regular5_1.ext_conv3.1.bias', 'regular5_1.ext_conv3.1.running_mean', 'regular5_1.ext_conv3.1.running_var', 'regular5_1.ext_conv3.1.num_batches_tracked', 'transposed_conv.weight'])\n",
            "odict_keys(['initial_block.main_branch.weight', 'initial_block.batch_norm.weight', 'initial_block.batch_norm.bias', 'initial_block.batch_norm.running_mean', 'initial_block.batch_norm.running_var', 'initial_block.batch_norm.num_batches_tracked', 'initial_block.out_activation.weight', 'downsample1_0.ext_conv1.0.weight', 'downsample1_0.ext_conv1.1.weight', 'downsample1_0.ext_conv1.1.bias', 'downsample1_0.ext_conv1.1.running_mean', 'downsample1_0.ext_conv1.1.running_var', 'downsample1_0.ext_conv1.1.num_batches_tracked', 'downsample1_0.ext_conv1.2.weight', 'downsample1_0.ext_conv2.0.weight', 'downsample1_0.ext_conv2.1.weight', 'downsample1_0.ext_conv2.1.bias', 'downsample1_0.ext_conv2.1.running_mean', 'downsample1_0.ext_conv2.1.running_var', 'downsample1_0.ext_conv2.1.num_batches_tracked', 'downsample1_0.ext_conv2.2.weight', 'downsample1_0.ext_conv3.0.weight', 'downsample1_0.ext_conv3.1.weight', 'downsample1_0.ext_conv3.1.bias', 'downsample1_0.ext_conv3.1.running_mean', 'downsample1_0.ext_conv3.1.running_var', 'downsample1_0.ext_conv3.1.num_batches_tracked', 'downsample1_0.ext_conv3.2.weight', 'downsample1_0.out_activation.weight', 'regular1_1.ext_conv1.0.weight', 'regular1_1.ext_conv1.1.weight', 'regular1_1.ext_conv1.1.bias', 'regular1_1.ext_conv1.1.running_mean', 'regular1_1.ext_conv1.1.running_var', 'regular1_1.ext_conv1.1.num_batches_tracked', 'regular1_1.ext_conv1.2.weight', 'regular1_1.ext_conv2.0.weight', 'regular1_1.ext_conv2.1.weight', 'regular1_1.ext_conv2.1.bias', 'regular1_1.ext_conv2.1.running_mean', 'regular1_1.ext_conv2.1.running_var', 'regular1_1.ext_conv2.1.num_batches_tracked', 'regular1_1.ext_conv2.2.weight', 'regular1_1.ext_conv3.0.weight', 'regular1_1.ext_conv3.1.weight', 'regular1_1.ext_conv3.1.bias', 'regular1_1.ext_conv3.1.running_mean', 'regular1_1.ext_conv3.1.running_var', 'regular1_1.ext_conv3.1.num_batches_tracked', 'regular1_1.ext_conv3.2.weight', 'regular1_1.out_activation.weight', 'regular1_2.ext_conv1.0.weight', 'regular1_2.ext_conv1.1.weight', 'regular1_2.ext_conv1.1.bias', 'regular1_2.ext_conv1.1.running_mean', 'regular1_2.ext_conv1.1.running_var', 'regular1_2.ext_conv1.1.num_batches_tracked', 'regular1_2.ext_conv1.2.weight', 'regular1_2.ext_conv2.0.weight', 'regular1_2.ext_conv2.1.weight', 'regular1_2.ext_conv2.1.bias', 'regular1_2.ext_conv2.1.running_mean', 'regular1_2.ext_conv2.1.running_var', 'regular1_2.ext_conv2.1.num_batches_tracked', 'regular1_2.ext_conv2.2.weight', 'regular1_2.ext_conv3.0.weight', 'regular1_2.ext_conv3.1.weight', 'regular1_2.ext_conv3.1.bias', 'regular1_2.ext_conv3.1.running_mean', 'regular1_2.ext_conv3.1.running_var', 'regular1_2.ext_conv3.1.num_batches_tracked', 'regular1_2.ext_conv3.2.weight', 'regular1_2.out_activation.weight', 'regular1_3.ext_conv1.0.weight', 'regular1_3.ext_conv1.1.weight', 'regular1_3.ext_conv1.1.bias', 'regular1_3.ext_conv1.1.running_mean', 'regular1_3.ext_conv1.1.running_var', 'regular1_3.ext_conv1.1.num_batches_tracked', 'regular1_3.ext_conv1.2.weight', 'regular1_3.ext_conv2.0.weight', 'regular1_3.ext_conv2.1.weight', 'regular1_3.ext_conv2.1.bias', 'regular1_3.ext_conv2.1.running_mean', 'regular1_3.ext_conv2.1.running_var', 'regular1_3.ext_conv2.1.num_batches_tracked', 'regular1_3.ext_conv2.2.weight', 'regular1_3.ext_conv3.0.weight', 'regular1_3.ext_conv3.1.weight', 'regular1_3.ext_conv3.1.bias', 'regular1_3.ext_conv3.1.running_mean', 'regular1_3.ext_conv3.1.running_var', 'regular1_3.ext_conv3.1.num_batches_tracked', 'regular1_3.ext_conv3.2.weight', 'regular1_3.out_activation.weight', 'regular1_4.ext_conv1.0.weight', 'regular1_4.ext_conv1.1.weight', 'regular1_4.ext_conv1.1.bias', 'regular1_4.ext_conv1.1.running_mean', 'regular1_4.ext_conv1.1.running_var', 'regular1_4.ext_conv1.1.num_batches_tracked', 'regular1_4.ext_conv1.2.weight', 'regular1_4.ext_conv2.0.weight', 'regular1_4.ext_conv2.1.weight', 'regular1_4.ext_conv2.1.bias', 'regular1_4.ext_conv2.1.running_mean', 'regular1_4.ext_conv2.1.running_var', 'regular1_4.ext_conv2.1.num_batches_tracked', 'regular1_4.ext_conv2.2.weight', 'regular1_4.ext_conv3.0.weight', 'regular1_4.ext_conv3.1.weight', 'regular1_4.ext_conv3.1.bias', 'regular1_4.ext_conv3.1.running_mean', 'regular1_4.ext_conv3.1.running_var', 'regular1_4.ext_conv3.1.num_batches_tracked', 'regular1_4.ext_conv3.2.weight', 'regular1_4.out_activation.weight', 'downsample2_0.ext_conv1.0.weight', 'downsample2_0.ext_conv1.1.weight', 'downsample2_0.ext_conv1.1.bias', 'downsample2_0.ext_conv1.1.running_mean', 'downsample2_0.ext_conv1.1.running_var', 'downsample2_0.ext_conv1.1.num_batches_tracked', 'downsample2_0.ext_conv1.2.weight', 'downsample2_0.ext_conv2.0.weight', 'downsample2_0.ext_conv2.1.weight', 'downsample2_0.ext_conv2.1.bias', 'downsample2_0.ext_conv2.1.running_mean', 'downsample2_0.ext_conv2.1.running_var', 'downsample2_0.ext_conv2.1.num_batches_tracked', 'downsample2_0.ext_conv2.2.weight', 'downsample2_0.ext_conv3.0.weight', 'downsample2_0.ext_conv3.1.weight', 'downsample2_0.ext_conv3.1.bias', 'downsample2_0.ext_conv3.1.running_mean', 'downsample2_0.ext_conv3.1.running_var', 'downsample2_0.ext_conv3.1.num_batches_tracked', 'downsample2_0.ext_conv3.2.weight', 'downsample2_0.out_activation.weight', 'regular2_1.ext_conv1.0.weight', 'regular2_1.ext_conv1.1.weight', 'regular2_1.ext_conv1.1.bias', 'regular2_1.ext_conv1.1.running_mean', 'regular2_1.ext_conv1.1.running_var', 'regular2_1.ext_conv1.1.num_batches_tracked', 'regular2_1.ext_conv1.2.weight', 'regular2_1.ext_conv2.0.weight', 'regular2_1.ext_conv2.1.weight', 'regular2_1.ext_conv2.1.bias', 'regular2_1.ext_conv2.1.running_mean', 'regular2_1.ext_conv2.1.running_var', 'regular2_1.ext_conv2.1.num_batches_tracked', 'regular2_1.ext_conv2.2.weight', 'regular2_1.ext_conv3.0.weight', 'regular2_1.ext_conv3.1.weight', 'regular2_1.ext_conv3.1.bias', 'regular2_1.ext_conv3.1.running_mean', 'regular2_1.ext_conv3.1.running_var', 'regular2_1.ext_conv3.1.num_batches_tracked', 'regular2_1.ext_conv3.2.weight', 'regular2_1.out_activation.weight', 'dilated2_2.ext_conv1.0.weight', 'dilated2_2.ext_conv1.1.weight', 'dilated2_2.ext_conv1.1.bias', 'dilated2_2.ext_conv1.1.running_mean', 'dilated2_2.ext_conv1.1.running_var', 'dilated2_2.ext_conv1.1.num_batches_tracked', 'dilated2_2.ext_conv1.2.weight', 'dilated2_2.ext_conv2.0.weight', 'dilated2_2.ext_conv2.1.weight', 'dilated2_2.ext_conv2.1.bias', 'dilated2_2.ext_conv2.1.running_mean', 'dilated2_2.ext_conv2.1.running_var', 'dilated2_2.ext_conv2.1.num_batches_tracked', 'dilated2_2.ext_conv2.2.weight', 'dilated2_2.ext_conv3.0.weight', 'dilated2_2.ext_conv3.1.weight', 'dilated2_2.ext_conv3.1.bias', 'dilated2_2.ext_conv3.1.running_mean', 'dilated2_2.ext_conv3.1.running_var', 'dilated2_2.ext_conv3.1.num_batches_tracked', 'dilated2_2.ext_conv3.2.weight', 'dilated2_2.out_activation.weight', 'asymmetric2_3.ext_conv1.0.weight', 'asymmetric2_3.ext_conv1.1.weight', 'asymmetric2_3.ext_conv1.1.bias', 'asymmetric2_3.ext_conv1.1.running_mean', 'asymmetric2_3.ext_conv1.1.running_var', 'asymmetric2_3.ext_conv1.1.num_batches_tracked', 'asymmetric2_3.ext_conv1.2.weight', 'asymmetric2_3.ext_conv2.0.weight', 'asymmetric2_3.ext_conv2.1.weight', 'asymmetric2_3.ext_conv2.1.bias', 'asymmetric2_3.ext_conv2.1.running_mean', 'asymmetric2_3.ext_conv2.1.running_var', 'asymmetric2_3.ext_conv2.1.num_batches_tracked', 'asymmetric2_3.ext_conv2.2.weight', 'asymmetric2_3.ext_conv2.3.weight', 'asymmetric2_3.ext_conv2.4.weight', 'asymmetric2_3.ext_conv2.4.bias', 'asymmetric2_3.ext_conv2.4.running_mean', 'asymmetric2_3.ext_conv2.4.running_var', 'asymmetric2_3.ext_conv2.4.num_batches_tracked', 'asymmetric2_3.ext_conv2.5.weight', 'asymmetric2_3.ext_conv3.0.weight', 'asymmetric2_3.ext_conv3.1.weight', 'asymmetric2_3.ext_conv3.1.bias', 'asymmetric2_3.ext_conv3.1.running_mean', 'asymmetric2_3.ext_conv3.1.running_var', 'asymmetric2_3.ext_conv3.1.num_batches_tracked', 'asymmetric2_3.ext_conv3.2.weight', 'asymmetric2_3.out_activation.weight', 'dilated2_4.ext_conv1.0.weight', 'dilated2_4.ext_conv1.1.weight', 'dilated2_4.ext_conv1.1.bias', 'dilated2_4.ext_conv1.1.running_mean', 'dilated2_4.ext_conv1.1.running_var', 'dilated2_4.ext_conv1.1.num_batches_tracked', 'dilated2_4.ext_conv1.2.weight', 'dilated2_4.ext_conv2.0.weight', 'dilated2_4.ext_conv2.1.weight', 'dilated2_4.ext_conv2.1.bias', 'dilated2_4.ext_conv2.1.running_mean', 'dilated2_4.ext_conv2.1.running_var', 'dilated2_4.ext_conv2.1.num_batches_tracked', 'dilated2_4.ext_conv2.2.weight', 'dilated2_4.ext_conv3.0.weight', 'dilated2_4.ext_conv3.1.weight', 'dilated2_4.ext_conv3.1.bias', 'dilated2_4.ext_conv3.1.running_mean', 'dilated2_4.ext_conv3.1.running_var', 'dilated2_4.ext_conv3.1.num_batches_tracked', 'dilated2_4.ext_conv3.2.weight', 'dilated2_4.out_activation.weight', 'regular2_5.ext_conv1.0.weight', 'regular2_5.ext_conv1.1.weight', 'regular2_5.ext_conv1.1.bias', 'regular2_5.ext_conv1.1.running_mean', 'regular2_5.ext_conv1.1.running_var', 'regular2_5.ext_conv1.1.num_batches_tracked', 'regular2_5.ext_conv1.2.weight', 'regular2_5.ext_conv2.0.weight', 'regular2_5.ext_conv2.1.weight', 'regular2_5.ext_conv2.1.bias', 'regular2_5.ext_conv2.1.running_mean', 'regular2_5.ext_conv2.1.running_var', 'regular2_5.ext_conv2.1.num_batches_tracked', 'regular2_5.ext_conv2.2.weight', 'regular2_5.ext_conv3.0.weight', 'regular2_5.ext_conv3.1.weight', 'regular2_5.ext_conv3.1.bias', 'regular2_5.ext_conv3.1.running_mean', 'regular2_5.ext_conv3.1.running_var', 'regular2_5.ext_conv3.1.num_batches_tracked', 'regular2_5.ext_conv3.2.weight', 'regular2_5.out_activation.weight', 'dilated2_6.ext_conv1.0.weight', 'dilated2_6.ext_conv1.1.weight', 'dilated2_6.ext_conv1.1.bias', 'dilated2_6.ext_conv1.1.running_mean', 'dilated2_6.ext_conv1.1.running_var', 'dilated2_6.ext_conv1.1.num_batches_tracked', 'dilated2_6.ext_conv1.2.weight', 'dilated2_6.ext_conv2.0.weight', 'dilated2_6.ext_conv2.1.weight', 'dilated2_6.ext_conv2.1.bias', 'dilated2_6.ext_conv2.1.running_mean', 'dilated2_6.ext_conv2.1.running_var', 'dilated2_6.ext_conv2.1.num_batches_tracked', 'dilated2_6.ext_conv2.2.weight', 'dilated2_6.ext_conv3.0.weight', 'dilated2_6.ext_conv3.1.weight', 'dilated2_6.ext_conv3.1.bias', 'dilated2_6.ext_conv3.1.running_mean', 'dilated2_6.ext_conv3.1.running_var', 'dilated2_6.ext_conv3.1.num_batches_tracked', 'dilated2_6.ext_conv3.2.weight', 'dilated2_6.out_activation.weight', 'asymmetric2_7.ext_conv1.0.weight', 'asymmetric2_7.ext_conv1.1.weight', 'asymmetric2_7.ext_conv1.1.bias', 'asymmetric2_7.ext_conv1.1.running_mean', 'asymmetric2_7.ext_conv1.1.running_var', 'asymmetric2_7.ext_conv1.1.num_batches_tracked', 'asymmetric2_7.ext_conv1.2.weight', 'asymmetric2_7.ext_conv2.0.weight', 'asymmetric2_7.ext_conv2.1.weight', 'asymmetric2_7.ext_conv2.1.bias', 'asymmetric2_7.ext_conv2.1.running_mean', 'asymmetric2_7.ext_conv2.1.running_var', 'asymmetric2_7.ext_conv2.1.num_batches_tracked', 'asymmetric2_7.ext_conv2.2.weight', 'asymmetric2_7.ext_conv2.3.weight', 'asymmetric2_7.ext_conv2.4.weight', 'asymmetric2_7.ext_conv2.4.bias', 'asymmetric2_7.ext_conv2.4.running_mean', 'asymmetric2_7.ext_conv2.4.running_var', 'asymmetric2_7.ext_conv2.4.num_batches_tracked', 'asymmetric2_7.ext_conv2.5.weight', 'asymmetric2_7.ext_conv3.0.weight', 'asymmetric2_7.ext_conv3.1.weight', 'asymmetric2_7.ext_conv3.1.bias', 'asymmetric2_7.ext_conv3.1.running_mean', 'asymmetric2_7.ext_conv3.1.running_var', 'asymmetric2_7.ext_conv3.1.num_batches_tracked', 'asymmetric2_7.ext_conv3.2.weight', 'asymmetric2_7.out_activation.weight', 'dilated2_8.ext_conv1.0.weight', 'dilated2_8.ext_conv1.1.weight', 'dilated2_8.ext_conv1.1.bias', 'dilated2_8.ext_conv1.1.running_mean', 'dilated2_8.ext_conv1.1.running_var', 'dilated2_8.ext_conv1.1.num_batches_tracked', 'dilated2_8.ext_conv1.2.weight', 'dilated2_8.ext_conv2.0.weight', 'dilated2_8.ext_conv2.1.weight', 'dilated2_8.ext_conv2.1.bias', 'dilated2_8.ext_conv2.1.running_mean', 'dilated2_8.ext_conv2.1.running_var', 'dilated2_8.ext_conv2.1.num_batches_tracked', 'dilated2_8.ext_conv2.2.weight', 'dilated2_8.ext_conv3.0.weight', 'dilated2_8.ext_conv3.1.weight', 'dilated2_8.ext_conv3.1.bias', 'dilated2_8.ext_conv3.1.running_mean', 'dilated2_8.ext_conv3.1.running_var', 'dilated2_8.ext_conv3.1.num_batches_tracked', 'dilated2_8.ext_conv3.2.weight', 'dilated2_8.out_activation.weight', 'regular3_0.ext_conv1.0.weight', 'regular3_0.ext_conv1.1.weight', 'regular3_0.ext_conv1.1.bias', 'regular3_0.ext_conv1.1.running_mean', 'regular3_0.ext_conv1.1.running_var', 'regular3_0.ext_conv1.1.num_batches_tracked', 'regular3_0.ext_conv1.2.weight', 'regular3_0.ext_conv2.0.weight', 'regular3_0.ext_conv2.1.weight', 'regular3_0.ext_conv2.1.bias', 'regular3_0.ext_conv2.1.running_mean', 'regular3_0.ext_conv2.1.running_var', 'regular3_0.ext_conv2.1.num_batches_tracked', 'regular3_0.ext_conv2.2.weight', 'regular3_0.ext_conv3.0.weight', 'regular3_0.ext_conv3.1.weight', 'regular3_0.ext_conv3.1.bias', 'regular3_0.ext_conv3.1.running_mean', 'regular3_0.ext_conv3.1.running_var', 'regular3_0.ext_conv3.1.num_batches_tracked', 'regular3_0.ext_conv3.2.weight', 'regular3_0.out_activation.weight', 'dilated3_1.ext_conv1.0.weight', 'dilated3_1.ext_conv1.1.weight', 'dilated3_1.ext_conv1.1.bias', 'dilated3_1.ext_conv1.1.running_mean', 'dilated3_1.ext_conv1.1.running_var', 'dilated3_1.ext_conv1.1.num_batches_tracked', 'dilated3_1.ext_conv1.2.weight', 'dilated3_1.ext_conv2.0.weight', 'dilated3_1.ext_conv2.1.weight', 'dilated3_1.ext_conv2.1.bias', 'dilated3_1.ext_conv2.1.running_mean', 'dilated3_1.ext_conv2.1.running_var', 'dilated3_1.ext_conv2.1.num_batches_tracked', 'dilated3_1.ext_conv2.2.weight', 'dilated3_1.ext_conv3.0.weight', 'dilated3_1.ext_conv3.1.weight', 'dilated3_1.ext_conv3.1.bias', 'dilated3_1.ext_conv3.1.running_mean', 'dilated3_1.ext_conv3.1.running_var', 'dilated3_1.ext_conv3.1.num_batches_tracked', 'dilated3_1.ext_conv3.2.weight', 'dilated3_1.out_activation.weight', 'asymmetric3_2.ext_conv1.0.weight', 'asymmetric3_2.ext_conv1.1.weight', 'asymmetric3_2.ext_conv1.1.bias', 'asymmetric3_2.ext_conv1.1.running_mean', 'asymmetric3_2.ext_conv1.1.running_var', 'asymmetric3_2.ext_conv1.1.num_batches_tracked', 'asymmetric3_2.ext_conv1.2.weight', 'asymmetric3_2.ext_conv2.0.weight', 'asymmetric3_2.ext_conv2.1.weight', 'asymmetric3_2.ext_conv2.1.bias', 'asymmetric3_2.ext_conv2.1.running_mean', 'asymmetric3_2.ext_conv2.1.running_var', 'asymmetric3_2.ext_conv2.1.num_batches_tracked', 'asymmetric3_2.ext_conv2.2.weight', 'asymmetric3_2.ext_conv2.3.weight', 'asymmetric3_2.ext_conv2.4.weight', 'asymmetric3_2.ext_conv2.4.bias', 'asymmetric3_2.ext_conv2.4.running_mean', 'asymmetric3_2.ext_conv2.4.running_var', 'asymmetric3_2.ext_conv2.4.num_batches_tracked', 'asymmetric3_2.ext_conv2.5.weight', 'asymmetric3_2.ext_conv3.0.weight', 'asymmetric3_2.ext_conv3.1.weight', 'asymmetric3_2.ext_conv3.1.bias', 'asymmetric3_2.ext_conv3.1.running_mean', 'asymmetric3_2.ext_conv3.1.running_var', 'asymmetric3_2.ext_conv3.1.num_batches_tracked', 'asymmetric3_2.ext_conv3.2.weight', 'asymmetric3_2.out_activation.weight', 'dilated3_3.ext_conv1.0.weight', 'dilated3_3.ext_conv1.1.weight', 'dilated3_3.ext_conv1.1.bias', 'dilated3_3.ext_conv1.1.running_mean', 'dilated3_3.ext_conv1.1.running_var', 'dilated3_3.ext_conv1.1.num_batches_tracked', 'dilated3_3.ext_conv1.2.weight', 'dilated3_3.ext_conv2.0.weight', 'dilated3_3.ext_conv2.1.weight', 'dilated3_3.ext_conv2.1.bias', 'dilated3_3.ext_conv2.1.running_mean', 'dilated3_3.ext_conv2.1.running_var', 'dilated3_3.ext_conv2.1.num_batches_tracked', 'dilated3_3.ext_conv2.2.weight', 'dilated3_3.ext_conv3.0.weight', 'dilated3_3.ext_conv3.1.weight', 'dilated3_3.ext_conv3.1.bias', 'dilated3_3.ext_conv3.1.running_mean', 'dilated3_3.ext_conv3.1.running_var', 'dilated3_3.ext_conv3.1.num_batches_tracked', 'dilated3_3.ext_conv3.2.weight', 'dilated3_3.out_activation.weight', 'regular3_4.ext_conv1.0.weight', 'regular3_4.ext_conv1.1.weight', 'regular3_4.ext_conv1.1.bias', 'regular3_4.ext_conv1.1.running_mean', 'regular3_4.ext_conv1.1.running_var', 'regular3_4.ext_conv1.1.num_batches_tracked', 'regular3_4.ext_conv1.2.weight', 'regular3_4.ext_conv2.0.weight', 'regular3_4.ext_conv2.1.weight', 'regular3_4.ext_conv2.1.bias', 'regular3_4.ext_conv2.1.running_mean', 'regular3_4.ext_conv2.1.running_var', 'regular3_4.ext_conv2.1.num_batches_tracked', 'regular3_4.ext_conv2.2.weight', 'regular3_4.ext_conv3.0.weight', 'regular3_4.ext_conv3.1.weight', 'regular3_4.ext_conv3.1.bias', 'regular3_4.ext_conv3.1.running_mean', 'regular3_4.ext_conv3.1.running_var', 'regular3_4.ext_conv3.1.num_batches_tracked', 'regular3_4.ext_conv3.2.weight', 'regular3_4.out_activation.weight', 'dilated3_5.ext_conv1.0.weight', 'dilated3_5.ext_conv1.1.weight', 'dilated3_5.ext_conv1.1.bias', 'dilated3_5.ext_conv1.1.running_mean', 'dilated3_5.ext_conv1.1.running_var', 'dilated3_5.ext_conv1.1.num_batches_tracked', 'dilated3_5.ext_conv1.2.weight', 'dilated3_5.ext_conv2.0.weight', 'dilated3_5.ext_conv2.1.weight', 'dilated3_5.ext_conv2.1.bias', 'dilated3_5.ext_conv2.1.running_mean', 'dilated3_5.ext_conv2.1.running_var', 'dilated3_5.ext_conv2.1.num_batches_tracked', 'dilated3_5.ext_conv2.2.weight', 'dilated3_5.ext_conv3.0.weight', 'dilated3_5.ext_conv3.1.weight', 'dilated3_5.ext_conv3.1.bias', 'dilated3_5.ext_conv3.1.running_mean', 'dilated3_5.ext_conv3.1.running_var', 'dilated3_5.ext_conv3.1.num_batches_tracked', 'dilated3_5.ext_conv3.2.weight', 'dilated3_5.out_activation.weight', 'asymmetric3_6.ext_conv1.0.weight', 'asymmetric3_6.ext_conv1.1.weight', 'asymmetric3_6.ext_conv1.1.bias', 'asymmetric3_6.ext_conv1.1.running_mean', 'asymmetric3_6.ext_conv1.1.running_var', 'asymmetric3_6.ext_conv1.1.num_batches_tracked', 'asymmetric3_6.ext_conv1.2.weight', 'asymmetric3_6.ext_conv2.0.weight', 'asymmetric3_6.ext_conv2.1.weight', 'asymmetric3_6.ext_conv2.1.bias', 'asymmetric3_6.ext_conv2.1.running_mean', 'asymmetric3_6.ext_conv2.1.running_var', 'asymmetric3_6.ext_conv2.1.num_batches_tracked', 'asymmetric3_6.ext_conv2.2.weight', 'asymmetric3_6.ext_conv2.3.weight', 'asymmetric3_6.ext_conv2.4.weight', 'asymmetric3_6.ext_conv2.4.bias', 'asymmetric3_6.ext_conv2.4.running_mean', 'asymmetric3_6.ext_conv2.4.running_var', 'asymmetric3_6.ext_conv2.4.num_batches_tracked', 'asymmetric3_6.ext_conv2.5.weight', 'asymmetric3_6.ext_conv3.0.weight', 'asymmetric3_6.ext_conv3.1.weight', 'asymmetric3_6.ext_conv3.1.bias', 'asymmetric3_6.ext_conv3.1.running_mean', 'asymmetric3_6.ext_conv3.1.running_var', 'asymmetric3_6.ext_conv3.1.num_batches_tracked', 'asymmetric3_6.ext_conv3.2.weight', 'asymmetric3_6.out_activation.weight', 'dilated3_7.ext_conv1.0.weight', 'dilated3_7.ext_conv1.1.weight', 'dilated3_7.ext_conv1.1.bias', 'dilated3_7.ext_conv1.1.running_mean', 'dilated3_7.ext_conv1.1.running_var', 'dilated3_7.ext_conv1.1.num_batches_tracked', 'dilated3_7.ext_conv1.2.weight', 'dilated3_7.ext_conv2.0.weight', 'dilated3_7.ext_conv2.1.weight', 'dilated3_7.ext_conv2.1.bias', 'dilated3_7.ext_conv2.1.running_mean', 'dilated3_7.ext_conv2.1.running_var', 'dilated3_7.ext_conv2.1.num_batches_tracked', 'dilated3_7.ext_conv2.2.weight', 'dilated3_7.ext_conv3.0.weight', 'dilated3_7.ext_conv3.1.weight', 'dilated3_7.ext_conv3.1.bias', 'dilated3_7.ext_conv3.1.running_mean', 'dilated3_7.ext_conv3.1.running_var', 'dilated3_7.ext_conv3.1.num_batches_tracked', 'dilated3_7.ext_conv3.2.weight', 'dilated3_7.out_activation.weight', 'upsample4_0.main_conv1.0.weight', 'upsample4_0.main_conv1.1.weight', 'upsample4_0.main_conv1.1.bias', 'upsample4_0.main_conv1.1.running_mean', 'upsample4_0.main_conv1.1.running_var', 'upsample4_0.main_conv1.1.num_batches_tracked', 'upsample4_0.ext_conv1.0.weight', 'upsample4_0.ext_conv1.1.weight', 'upsample4_0.ext_conv1.1.bias', 'upsample4_0.ext_conv1.1.running_mean', 'upsample4_0.ext_conv1.1.running_var', 'upsample4_0.ext_conv1.1.num_batches_tracked', 'upsample4_0.ext_tconv1.weight', 'upsample4_0.ext_tconv1_bnorm.weight', 'upsample4_0.ext_tconv1_bnorm.bias', 'upsample4_0.ext_tconv1_bnorm.running_mean', 'upsample4_0.ext_tconv1_bnorm.running_var', 'upsample4_0.ext_tconv1_bnorm.num_batches_tracked', 'upsample4_0.ext_conv2.0.weight', 'upsample4_0.ext_conv2.1.weight', 'upsample4_0.ext_conv2.1.bias', 'upsample4_0.ext_conv2.1.running_mean', 'upsample4_0.ext_conv2.1.running_var', 'upsample4_0.ext_conv2.1.num_batches_tracked', 'regular4_1.ext_conv1.0.weight', 'regular4_1.ext_conv1.1.weight', 'regular4_1.ext_conv1.1.bias', 'regular4_1.ext_conv1.1.running_mean', 'regular4_1.ext_conv1.1.running_var', 'regular4_1.ext_conv1.1.num_batches_tracked', 'regular4_1.ext_conv2.0.weight', 'regular4_1.ext_conv2.1.weight', 'regular4_1.ext_conv2.1.bias', 'regular4_1.ext_conv2.1.running_mean', 'regular4_1.ext_conv2.1.running_var', 'regular4_1.ext_conv2.1.num_batches_tracked', 'regular4_1.ext_conv3.0.weight', 'regular4_1.ext_conv3.1.weight', 'regular4_1.ext_conv3.1.bias', 'regular4_1.ext_conv3.1.running_mean', 'regular4_1.ext_conv3.1.running_var', 'regular4_1.ext_conv3.1.num_batches_tracked', 'regular4_2.ext_conv1.0.weight', 'regular4_2.ext_conv1.1.weight', 'regular4_2.ext_conv1.1.bias', 'regular4_2.ext_conv1.1.running_mean', 'regular4_2.ext_conv1.1.running_var', 'regular4_2.ext_conv1.1.num_batches_tracked', 'regular4_2.ext_conv2.0.weight', 'regular4_2.ext_conv2.1.weight', 'regular4_2.ext_conv2.1.bias', 'regular4_2.ext_conv2.1.running_mean', 'regular4_2.ext_conv2.1.running_var', 'regular4_2.ext_conv2.1.num_batches_tracked', 'regular4_2.ext_conv3.0.weight', 'regular4_2.ext_conv3.1.weight', 'regular4_2.ext_conv3.1.bias', 'regular4_2.ext_conv3.1.running_mean', 'regular4_2.ext_conv3.1.running_var', 'regular4_2.ext_conv3.1.num_batches_tracked', 'upsample5_0.main_conv1.0.weight', 'upsample5_0.main_conv1.1.weight', 'upsample5_0.main_conv1.1.bias', 'upsample5_0.main_conv1.1.running_mean', 'upsample5_0.main_conv1.1.running_var', 'upsample5_0.main_conv1.1.num_batches_tracked', 'upsample5_0.ext_conv1.0.weight', 'upsample5_0.ext_conv1.1.weight', 'upsample5_0.ext_conv1.1.bias', 'upsample5_0.ext_conv1.1.running_mean', 'upsample5_0.ext_conv1.1.running_var', 'upsample5_0.ext_conv1.1.num_batches_tracked', 'upsample5_0.ext_tconv1.weight', 'upsample5_0.ext_tconv1_bnorm.weight', 'upsample5_0.ext_tconv1_bnorm.bias', 'upsample5_0.ext_tconv1_bnorm.running_mean', 'upsample5_0.ext_tconv1_bnorm.running_var', 'upsample5_0.ext_tconv1_bnorm.num_batches_tracked', 'upsample5_0.ext_conv2.0.weight', 'upsample5_0.ext_conv2.1.weight', 'upsample5_0.ext_conv2.1.bias', 'upsample5_0.ext_conv2.1.running_mean', 'upsample5_0.ext_conv2.1.running_var', 'upsample5_0.ext_conv2.1.num_batches_tracked', 'regular5_1.ext_conv1.0.weight', 'regular5_1.ext_conv1.1.weight', 'regular5_1.ext_conv1.1.bias', 'regular5_1.ext_conv1.1.running_mean', 'regular5_1.ext_conv1.1.running_var', 'regular5_1.ext_conv1.1.num_batches_tracked', 'regular5_1.ext_conv2.0.weight', 'regular5_1.ext_conv2.1.weight', 'regular5_1.ext_conv2.1.bias', 'regular5_1.ext_conv2.1.running_mean', 'regular5_1.ext_conv2.1.running_var', 'regular5_1.ext_conv2.1.num_batches_tracked', 'regular5_1.ext_conv3.0.weight', 'regular5_1.ext_conv3.1.weight', 'regular5_1.ext_conv3.1.bias', 'regular5_1.ext_conv3.1.running_mean', 'regular5_1.ext_conv3.1.running_var', 'regular5_1.ext_conv3.1.num_batches_tracked', 'transposed_conv.weight'])\n",
            "Import Model enet with weights enet_pretrained.pth to FineTune\n",
            "========== TRAINING ===========\n",
            "/content/cityscapes/leftImg8bit/train\n",
            "/content/cityscapes/leftImg8bit/val\n",
            "----- TRAINING - EPOCH 1 -----\n",
            "LEARNING RATE:  5e-05\n",
            "loss: 11.78 (epoch: 1, step: 0) // Avg time/img: 0.4272 s\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/AnomalySegmentation/train/main.py\", line 581, in <module>\n",
            "    main(parser.parse_args())\n",
            "  File \"/content/AnomalySegmentation/train/main.py\", line 549, in main\n",
            "    model = train(args, model)\n",
            "  File \"/content/AnomalySegmentation/train/main.py\", line 258, in train\n",
            "    outputs = model(inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/data_parallel.py\", line 191, in forward\n",
            "    return self.module(*inputs[0], **module_kwargs[0])\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/AnomalySegmentation/train/enet.py\", line 596, in forward\n",
            "    x, max_indices1_0 = self.downsample1_0(x)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/AnomalySegmentation/train/enet.py\", line 338, in forward\n",
            "    padding = torch.zeros(n, ch_ext - ch_main, h, w)\n",
            "KeyboardInterrupt\n",
            "Model saved in /content/AnomalySegmentation/save/enet_training\n",
            "updating: content/AnomalySegmentation/save/enet_training/ (stored 0%)\n",
            "updating: content/AnomalySegmentation/save/enet_training/opts.txt (deflated 37%)\n",
            "updating: content/AnomalySegmentation/save/enet_training/model.txt (deflated 96%)\n",
            "updating: content/AnomalySegmentation/save/enet_training/automated_log.txt (deflated 27%)\n"
          ]
        }
      ],
      "source": [
        "# Fine-tune ENet for VOID classification using CrossEntropy\n",
        "\n",
        "model = \"enet\"\n",
        "savedir = \"enet_training\"\n",
        "pretrained_weights = \"enet_pretrained.pth\"\n",
        "epochs = 20\n",
        "\n",
        "# Base directory of the project\n",
        "base_dir = \"/content/AnomalySegmentation/train\"\n",
        "# Dataset directory\n",
        "data_dir = \"/content/cityscapes\"\n",
        "\n",
        "print(f\"----- Fine-tuning {model} for VOID classification -----\")\n",
        "!cd {base_dir} && python -W ignore main.py --savedir {savedir} --datadir {data_dir} --model {model} --cuda --num-epochs=20 --epochs-save=1 --FineTune --decoder --loadWeights={pretrained_weights}\n",
        "print(f\"Model saved in /content/AnomalySegmentation/save/{savedir}\")\n",
        "# zip folder\n",
        "!zip -r save_{savedir}.zip /content/AnomalySegmentation/save/{savedir}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgJKstjyV6A8",
        "outputId": "d6d81f2a-da8d-4022-e851-b392f60d01d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----- Fine-tuning bisenet for VOID classification -----\n",
            "odict_keys(['cp.resnet.conv1.weight', 'cp.resnet.bn1.weight', 'cp.resnet.bn1.bias', 'cp.resnet.bn1.running_mean', 'cp.resnet.bn1.running_var', 'cp.resnet.bn1.num_batches_tracked', 'cp.resnet.layer1.0.conv1.weight', 'cp.resnet.layer1.0.bn1.weight', 'cp.resnet.layer1.0.bn1.bias', 'cp.resnet.layer1.0.bn1.running_mean', 'cp.resnet.layer1.0.bn1.running_var', 'cp.resnet.layer1.0.bn1.num_batches_tracked', 'cp.resnet.layer1.0.conv2.weight', 'cp.resnet.layer1.0.bn2.weight', 'cp.resnet.layer1.0.bn2.bias', 'cp.resnet.layer1.0.bn2.running_mean', 'cp.resnet.layer1.0.bn2.running_var', 'cp.resnet.layer1.0.bn2.num_batches_tracked', 'cp.resnet.layer1.1.conv1.weight', 'cp.resnet.layer1.1.bn1.weight', 'cp.resnet.layer1.1.bn1.bias', 'cp.resnet.layer1.1.bn1.running_mean', 'cp.resnet.layer1.1.bn1.running_var', 'cp.resnet.layer1.1.bn1.num_batches_tracked', 'cp.resnet.layer1.1.conv2.weight', 'cp.resnet.layer1.1.bn2.weight', 'cp.resnet.layer1.1.bn2.bias', 'cp.resnet.layer1.1.bn2.running_mean', 'cp.resnet.layer1.1.bn2.running_var', 'cp.resnet.layer1.1.bn2.num_batches_tracked', 'cp.resnet.layer2.0.conv1.weight', 'cp.resnet.layer2.0.bn1.weight', 'cp.resnet.layer2.0.bn1.bias', 'cp.resnet.layer2.0.bn1.running_mean', 'cp.resnet.layer2.0.bn1.running_var', 'cp.resnet.layer2.0.bn1.num_batches_tracked', 'cp.resnet.layer2.0.conv2.weight', 'cp.resnet.layer2.0.bn2.weight', 'cp.resnet.layer2.0.bn2.bias', 'cp.resnet.layer2.0.bn2.running_mean', 'cp.resnet.layer2.0.bn2.running_var', 'cp.resnet.layer2.0.bn2.num_batches_tracked', 'cp.resnet.layer2.0.downsample.0.weight', 'cp.resnet.layer2.0.downsample.1.weight', 'cp.resnet.layer2.0.downsample.1.bias', 'cp.resnet.layer2.0.downsample.1.running_mean', 'cp.resnet.layer2.0.downsample.1.running_var', 'cp.resnet.layer2.0.downsample.1.num_batches_tracked', 'cp.resnet.layer2.1.conv1.weight', 'cp.resnet.layer2.1.bn1.weight', 'cp.resnet.layer2.1.bn1.bias', 'cp.resnet.layer2.1.bn1.running_mean', 'cp.resnet.layer2.1.bn1.running_var', 'cp.resnet.layer2.1.bn1.num_batches_tracked', 'cp.resnet.layer2.1.conv2.weight', 'cp.resnet.layer2.1.bn2.weight', 'cp.resnet.layer2.1.bn2.bias', 'cp.resnet.layer2.1.bn2.running_mean', 'cp.resnet.layer2.1.bn2.running_var', 'cp.resnet.layer2.1.bn2.num_batches_tracked', 'cp.resnet.layer3.0.conv1.weight', 'cp.resnet.layer3.0.bn1.weight', 'cp.resnet.layer3.0.bn1.bias', 'cp.resnet.layer3.0.bn1.running_mean', 'cp.resnet.layer3.0.bn1.running_var', 'cp.resnet.layer3.0.bn1.num_batches_tracked', 'cp.resnet.layer3.0.conv2.weight', 'cp.resnet.layer3.0.bn2.weight', 'cp.resnet.layer3.0.bn2.bias', 'cp.resnet.layer3.0.bn2.running_mean', 'cp.resnet.layer3.0.bn2.running_var', 'cp.resnet.layer3.0.bn2.num_batches_tracked', 'cp.resnet.layer3.0.downsample.0.weight', 'cp.resnet.layer3.0.downsample.1.weight', 'cp.resnet.layer3.0.downsample.1.bias', 'cp.resnet.layer3.0.downsample.1.running_mean', 'cp.resnet.layer3.0.downsample.1.running_var', 'cp.resnet.layer3.0.downsample.1.num_batches_tracked', 'cp.resnet.layer3.1.conv1.weight', 'cp.resnet.layer3.1.bn1.weight', 'cp.resnet.layer3.1.bn1.bias', 'cp.resnet.layer3.1.bn1.running_mean', 'cp.resnet.layer3.1.bn1.running_var', 'cp.resnet.layer3.1.bn1.num_batches_tracked', 'cp.resnet.layer3.1.conv2.weight', 'cp.resnet.layer3.1.bn2.weight', 'cp.resnet.layer3.1.bn2.bias', 'cp.resnet.layer3.1.bn2.running_mean', 'cp.resnet.layer3.1.bn2.running_var', 'cp.resnet.layer3.1.bn2.num_batches_tracked', 'cp.resnet.layer4.0.conv1.weight', 'cp.resnet.layer4.0.bn1.weight', 'cp.resnet.layer4.0.bn1.bias', 'cp.resnet.layer4.0.bn1.running_mean', 'cp.resnet.layer4.0.bn1.running_var', 'cp.resnet.layer4.0.bn1.num_batches_tracked', 'cp.resnet.layer4.0.conv2.weight', 'cp.resnet.layer4.0.bn2.weight', 'cp.resnet.layer4.0.bn2.bias', 'cp.resnet.layer4.0.bn2.running_mean', 'cp.resnet.layer4.0.bn2.running_var', 'cp.resnet.layer4.0.bn2.num_batches_tracked', 'cp.resnet.layer4.0.downsample.0.weight', 'cp.resnet.layer4.0.downsample.1.weight', 'cp.resnet.layer4.0.downsample.1.bias', 'cp.resnet.layer4.0.downsample.1.running_mean', 'cp.resnet.layer4.0.downsample.1.running_var', 'cp.resnet.layer4.0.downsample.1.num_batches_tracked', 'cp.resnet.layer4.1.conv1.weight', 'cp.resnet.layer4.1.bn1.weight', 'cp.resnet.layer4.1.bn1.bias', 'cp.resnet.layer4.1.bn1.running_mean', 'cp.resnet.layer4.1.bn1.running_var', 'cp.resnet.layer4.1.bn1.num_batches_tracked', 'cp.resnet.layer4.1.conv2.weight', 'cp.resnet.layer4.1.bn2.weight', 'cp.resnet.layer4.1.bn2.bias', 'cp.resnet.layer4.1.bn2.running_mean', 'cp.resnet.layer4.1.bn2.running_var', 'cp.resnet.layer4.1.bn2.num_batches_tracked', 'cp.arm16.conv.conv.weight', 'cp.arm16.conv.bn.weight', 'cp.arm16.conv.bn.bias', 'cp.arm16.conv.bn.running_mean', 'cp.arm16.conv.bn.running_var', 'cp.arm16.conv.bn.num_batches_tracked', 'cp.arm16.conv_atten.weight', 'cp.arm16.bn_atten.weight', 'cp.arm16.bn_atten.bias', 'cp.arm16.bn_atten.running_mean', 'cp.arm16.bn_atten.running_var', 'cp.arm16.bn_atten.num_batches_tracked', 'cp.arm32.conv.conv.weight', 'cp.arm32.conv.bn.weight', 'cp.arm32.conv.bn.bias', 'cp.arm32.conv.bn.running_mean', 'cp.arm32.conv.bn.running_var', 'cp.arm32.conv.bn.num_batches_tracked', 'cp.arm32.conv_atten.weight', 'cp.arm32.bn_atten.weight', 'cp.arm32.bn_atten.bias', 'cp.arm32.bn_atten.running_mean', 'cp.arm32.bn_atten.running_var', 'cp.arm32.bn_atten.num_batches_tracked', 'cp.conv_head32.conv.weight', 'cp.conv_head32.bn.weight', 'cp.conv_head32.bn.bias', 'cp.conv_head32.bn.running_mean', 'cp.conv_head32.bn.running_var', 'cp.conv_head32.bn.num_batches_tracked', 'cp.conv_head16.conv.weight', 'cp.conv_head16.bn.weight', 'cp.conv_head16.bn.bias', 'cp.conv_head16.bn.running_mean', 'cp.conv_head16.bn.running_var', 'cp.conv_head16.bn.num_batches_tracked', 'cp.conv_avg.conv.weight', 'cp.conv_avg.bn.weight', 'cp.conv_avg.bn.bias', 'cp.conv_avg.bn.running_mean', 'cp.conv_avg.bn.running_var', 'cp.conv_avg.bn.num_batches_tracked', 'sp.conv1.conv.weight', 'sp.conv1.bn.weight', 'sp.conv1.bn.bias', 'sp.conv1.bn.running_mean', 'sp.conv1.bn.running_var', 'sp.conv1.bn.num_batches_tracked', 'sp.conv2.conv.weight', 'sp.conv2.bn.weight', 'sp.conv2.bn.bias', 'sp.conv2.bn.running_mean', 'sp.conv2.bn.running_var', 'sp.conv2.bn.num_batches_tracked', 'sp.conv3.conv.weight', 'sp.conv3.bn.weight', 'sp.conv3.bn.bias', 'sp.conv3.bn.running_mean', 'sp.conv3.bn.running_var', 'sp.conv3.bn.num_batches_tracked', 'sp.conv_out.conv.weight', 'sp.conv_out.bn.weight', 'sp.conv_out.bn.bias', 'sp.conv_out.bn.running_mean', 'sp.conv_out.bn.running_var', 'sp.conv_out.bn.num_batches_tracked', 'ffm.convblk.conv.weight', 'ffm.convblk.bn.weight', 'ffm.convblk.bn.bias', 'ffm.convblk.bn.running_mean', 'ffm.convblk.bn.running_var', 'ffm.convblk.bn.num_batches_tracked', 'ffm.conv.weight', 'ffm.bn.weight', 'ffm.bn.bias', 'ffm.bn.running_mean', 'ffm.bn.running_var', 'ffm.bn.num_batches_tracked', 'conv_out.conv.conv.weight', 'conv_out.conv.bn.weight', 'conv_out.conv.bn.bias', 'conv_out.conv.bn.running_mean', 'conv_out.conv.bn.running_var', 'conv_out.conv.bn.num_batches_tracked', 'conv_out.conv_out.weight', 'conv_out.conv_out.bias', 'conv_out16.conv.conv.weight', 'conv_out16.conv.bn.weight', 'conv_out16.conv.bn.bias', 'conv_out16.conv.bn.running_mean', 'conv_out16.conv.bn.running_var', 'conv_out16.conv.bn.num_batches_tracked', 'conv_out16.conv_out.weight', 'conv_out16.conv_out.bias', 'conv_out32.conv.conv.weight', 'conv_out32.conv.bn.weight', 'conv_out32.conv.bn.bias', 'conv_out32.conv.bn.running_mean', 'conv_out32.conv.bn.running_var', 'conv_out32.conv.bn.num_batches_tracked', 'conv_out32.conv_out.weight', 'conv_out32.conv_out.bias'])\n",
            "odict_keys(['cp.resnet.conv1.weight', 'cp.resnet.bn1.weight', 'cp.resnet.bn1.bias', 'cp.resnet.bn1.running_mean', 'cp.resnet.bn1.running_var', 'cp.resnet.bn1.num_batches_tracked', 'cp.resnet.layer1.0.conv1.weight', 'cp.resnet.layer1.0.bn1.weight', 'cp.resnet.layer1.0.bn1.bias', 'cp.resnet.layer1.0.bn1.running_mean', 'cp.resnet.layer1.0.bn1.running_var', 'cp.resnet.layer1.0.bn1.num_batches_tracked', 'cp.resnet.layer1.0.conv2.weight', 'cp.resnet.layer1.0.bn2.weight', 'cp.resnet.layer1.0.bn2.bias', 'cp.resnet.layer1.0.bn2.running_mean', 'cp.resnet.layer1.0.bn2.running_var', 'cp.resnet.layer1.0.bn2.num_batches_tracked', 'cp.resnet.layer1.1.conv1.weight', 'cp.resnet.layer1.1.bn1.weight', 'cp.resnet.layer1.1.bn1.bias', 'cp.resnet.layer1.1.bn1.running_mean', 'cp.resnet.layer1.1.bn1.running_var', 'cp.resnet.layer1.1.bn1.num_batches_tracked', 'cp.resnet.layer1.1.conv2.weight', 'cp.resnet.layer1.1.bn2.weight', 'cp.resnet.layer1.1.bn2.bias', 'cp.resnet.layer1.1.bn2.running_mean', 'cp.resnet.layer1.1.bn2.running_var', 'cp.resnet.layer1.1.bn2.num_batches_tracked', 'cp.resnet.layer2.0.conv1.weight', 'cp.resnet.layer2.0.bn1.weight', 'cp.resnet.layer2.0.bn1.bias', 'cp.resnet.layer2.0.bn1.running_mean', 'cp.resnet.layer2.0.bn1.running_var', 'cp.resnet.layer2.0.bn1.num_batches_tracked', 'cp.resnet.layer2.0.conv2.weight', 'cp.resnet.layer2.0.bn2.weight', 'cp.resnet.layer2.0.bn2.bias', 'cp.resnet.layer2.0.bn2.running_mean', 'cp.resnet.layer2.0.bn2.running_var', 'cp.resnet.layer2.0.bn2.num_batches_tracked', 'cp.resnet.layer2.0.downsample.0.weight', 'cp.resnet.layer2.0.downsample.1.weight', 'cp.resnet.layer2.0.downsample.1.bias', 'cp.resnet.layer2.0.downsample.1.running_mean', 'cp.resnet.layer2.0.downsample.1.running_var', 'cp.resnet.layer2.0.downsample.1.num_batches_tracked', 'cp.resnet.layer2.1.conv1.weight', 'cp.resnet.layer2.1.bn1.weight', 'cp.resnet.layer2.1.bn1.bias', 'cp.resnet.layer2.1.bn1.running_mean', 'cp.resnet.layer2.1.bn1.running_var', 'cp.resnet.layer2.1.bn1.num_batches_tracked', 'cp.resnet.layer2.1.conv2.weight', 'cp.resnet.layer2.1.bn2.weight', 'cp.resnet.layer2.1.bn2.bias', 'cp.resnet.layer2.1.bn2.running_mean', 'cp.resnet.layer2.1.bn2.running_var', 'cp.resnet.layer2.1.bn2.num_batches_tracked', 'cp.resnet.layer3.0.conv1.weight', 'cp.resnet.layer3.0.bn1.weight', 'cp.resnet.layer3.0.bn1.bias', 'cp.resnet.layer3.0.bn1.running_mean', 'cp.resnet.layer3.0.bn1.running_var', 'cp.resnet.layer3.0.bn1.num_batches_tracked', 'cp.resnet.layer3.0.conv2.weight', 'cp.resnet.layer3.0.bn2.weight', 'cp.resnet.layer3.0.bn2.bias', 'cp.resnet.layer3.0.bn2.running_mean', 'cp.resnet.layer3.0.bn2.running_var', 'cp.resnet.layer3.0.bn2.num_batches_tracked', 'cp.resnet.layer3.0.downsample.0.weight', 'cp.resnet.layer3.0.downsample.1.weight', 'cp.resnet.layer3.0.downsample.1.bias', 'cp.resnet.layer3.0.downsample.1.running_mean', 'cp.resnet.layer3.0.downsample.1.running_var', 'cp.resnet.layer3.0.downsample.1.num_batches_tracked', 'cp.resnet.layer3.1.conv1.weight', 'cp.resnet.layer3.1.bn1.weight', 'cp.resnet.layer3.1.bn1.bias', 'cp.resnet.layer3.1.bn1.running_mean', 'cp.resnet.layer3.1.bn1.running_var', 'cp.resnet.layer3.1.bn1.num_batches_tracked', 'cp.resnet.layer3.1.conv2.weight', 'cp.resnet.layer3.1.bn2.weight', 'cp.resnet.layer3.1.bn2.bias', 'cp.resnet.layer3.1.bn2.running_mean', 'cp.resnet.layer3.1.bn2.running_var', 'cp.resnet.layer3.1.bn2.num_batches_tracked', 'cp.resnet.layer4.0.conv1.weight', 'cp.resnet.layer4.0.bn1.weight', 'cp.resnet.layer4.0.bn1.bias', 'cp.resnet.layer4.0.bn1.running_mean', 'cp.resnet.layer4.0.bn1.running_var', 'cp.resnet.layer4.0.bn1.num_batches_tracked', 'cp.resnet.layer4.0.conv2.weight', 'cp.resnet.layer4.0.bn2.weight', 'cp.resnet.layer4.0.bn2.bias', 'cp.resnet.layer4.0.bn2.running_mean', 'cp.resnet.layer4.0.bn2.running_var', 'cp.resnet.layer4.0.bn2.num_batches_tracked', 'cp.resnet.layer4.0.downsample.0.weight', 'cp.resnet.layer4.0.downsample.1.weight', 'cp.resnet.layer4.0.downsample.1.bias', 'cp.resnet.layer4.0.downsample.1.running_mean', 'cp.resnet.layer4.0.downsample.1.running_var', 'cp.resnet.layer4.0.downsample.1.num_batches_tracked', 'cp.resnet.layer4.1.conv1.weight', 'cp.resnet.layer4.1.bn1.weight', 'cp.resnet.layer4.1.bn1.bias', 'cp.resnet.layer4.1.bn1.running_mean', 'cp.resnet.layer4.1.bn1.running_var', 'cp.resnet.layer4.1.bn1.num_batches_tracked', 'cp.resnet.layer4.1.conv2.weight', 'cp.resnet.layer4.1.bn2.weight', 'cp.resnet.layer4.1.bn2.bias', 'cp.resnet.layer4.1.bn2.running_mean', 'cp.resnet.layer4.1.bn2.running_var', 'cp.resnet.layer4.1.bn2.num_batches_tracked', 'cp.arm16.conv.conv.weight', 'cp.arm16.conv.bn.weight', 'cp.arm16.conv.bn.bias', 'cp.arm16.conv.bn.running_mean', 'cp.arm16.conv.bn.running_var', 'cp.arm16.conv.bn.num_batches_tracked', 'cp.arm16.conv_atten.weight', 'cp.arm16.bn_atten.weight', 'cp.arm16.bn_atten.bias', 'cp.arm16.bn_atten.running_mean', 'cp.arm16.bn_atten.running_var', 'cp.arm16.bn_atten.num_batches_tracked', 'cp.arm32.conv.conv.weight', 'cp.arm32.conv.bn.weight', 'cp.arm32.conv.bn.bias', 'cp.arm32.conv.bn.running_mean', 'cp.arm32.conv.bn.running_var', 'cp.arm32.conv.bn.num_batches_tracked', 'cp.arm32.conv_atten.weight', 'cp.arm32.bn_atten.weight', 'cp.arm32.bn_atten.bias', 'cp.arm32.bn_atten.running_mean', 'cp.arm32.bn_atten.running_var', 'cp.arm32.bn_atten.num_batches_tracked', 'cp.conv_head32.conv.weight', 'cp.conv_head32.bn.weight', 'cp.conv_head32.bn.bias', 'cp.conv_head32.bn.running_mean', 'cp.conv_head32.bn.running_var', 'cp.conv_head32.bn.num_batches_tracked', 'cp.conv_head16.conv.weight', 'cp.conv_head16.bn.weight', 'cp.conv_head16.bn.bias', 'cp.conv_head16.bn.running_mean', 'cp.conv_head16.bn.running_var', 'cp.conv_head16.bn.num_batches_tracked', 'cp.conv_avg.conv.weight', 'cp.conv_avg.bn.weight', 'cp.conv_avg.bn.bias', 'cp.conv_avg.bn.running_mean', 'cp.conv_avg.bn.running_var', 'cp.conv_avg.bn.num_batches_tracked', 'sp.conv1.conv.weight', 'sp.conv1.bn.weight', 'sp.conv1.bn.bias', 'sp.conv1.bn.running_mean', 'sp.conv1.bn.running_var', 'sp.conv1.bn.num_batches_tracked', 'sp.conv2.conv.weight', 'sp.conv2.bn.weight', 'sp.conv2.bn.bias', 'sp.conv2.bn.running_mean', 'sp.conv2.bn.running_var', 'sp.conv2.bn.num_batches_tracked', 'sp.conv3.conv.weight', 'sp.conv3.bn.weight', 'sp.conv3.bn.bias', 'sp.conv3.bn.running_mean', 'sp.conv3.bn.running_var', 'sp.conv3.bn.num_batches_tracked', 'sp.conv_out.conv.weight', 'sp.conv_out.bn.weight', 'sp.conv_out.bn.bias', 'sp.conv_out.bn.running_mean', 'sp.conv_out.bn.running_var', 'sp.conv_out.bn.num_batches_tracked', 'ffm.convblk.conv.weight', 'ffm.convblk.bn.weight', 'ffm.convblk.bn.bias', 'ffm.convblk.bn.running_mean', 'ffm.convblk.bn.running_var', 'ffm.convblk.bn.num_batches_tracked', 'ffm.conv.weight', 'ffm.bn.weight', 'ffm.bn.bias', 'ffm.bn.running_mean', 'ffm.bn.running_var', 'ffm.bn.num_batches_tracked', 'conv_out.conv.conv.weight', 'conv_out.conv.bn.weight', 'conv_out.conv.bn.bias', 'conv_out.conv.bn.running_mean', 'conv_out.conv.bn.running_var', 'conv_out.conv.bn.num_batches_tracked', 'conv_out.conv_out.weight', 'conv_out.conv_out.bias', 'conv_out16.conv.conv.weight', 'conv_out16.conv.bn.weight', 'conv_out16.conv.bn.bias', 'conv_out16.conv.bn.running_mean', 'conv_out16.conv.bn.running_var', 'conv_out16.conv.bn.num_batches_tracked', 'conv_out16.conv_out.weight', 'conv_out16.conv_out.bias', 'conv_out32.conv.conv.weight', 'conv_out32.conv.bn.weight', 'conv_out32.conv.bn.bias', 'conv_out32.conv.bn.running_mean', 'conv_out32.conv.bn.running_var', 'conv_out32.conv.bn.num_batches_tracked', 'conv_out32.conv_out.weight', 'conv_out32.conv_out.bias'])\n",
            "conv_out.conv_out.weight in own_state, but size mismatch: torch.Size([20, 256, 1, 1]) vs torch.Size([19, 256, 1, 1])\n",
            "conv_out.conv_out.bias in own_state, but size mismatch: torch.Size([20]) vs torch.Size([19])\n",
            "conv_out16.conv_out.weight in own_state, but size mismatch: torch.Size([20, 64, 1, 1]) vs torch.Size([19, 64, 1, 1])\n",
            "conv_out16.conv_out.bias in own_state, but size mismatch: torch.Size([20]) vs torch.Size([19])\n",
            "conv_out32.conv_out.weight in own_state, but size mismatch: torch.Size([20, 64, 1, 1]) vs torch.Size([19, 64, 1, 1])\n",
            "conv_out32.conv_out.bias in own_state, but size mismatch: torch.Size([20]) vs torch.Size([19])\n",
            "Import Model bisenet with weights bisenetv1_pretrained.pth to FineTune\n",
            "========== TRAINING ===========\n",
            "/content/cityscapes/leftImg8bit/train\n",
            "/content/cityscapes/leftImg8bit/val\n",
            "----- TRAINING - EPOCH 1 -----\n",
            "LEARNING RATE:  0.0025\n",
            "loss: 20.57 (epoch: 1, step: 0) // Avg time/img: 0.9830 s\n",
            "loss: 14.76 (epoch: 1, step: 50) // Avg time/img: 0.0927 s\n",
            "\n",
            "Model saved in /content/AnomalySegmentation/save/bisenet_training\n",
            "updating: content/AnomalySegmentation/save/bisenet_training/ (stored 0%)\n",
            "updating: content/AnomalySegmentation/save/bisenet_training/opts.txt (deflated 37%)\n",
            "updating: content/AnomalySegmentation/save/bisenet_training/model.txt (deflated 91%)\n",
            "updating: content/AnomalySegmentation/save/bisenet_training/automated_log.txt (deflated 27%)\n"
          ]
        }
      ],
      "source": [
        "# Fine-tune BiSeNet for VOID classification using CrossEntropy\n",
        "\n",
        "model = \"bisenet\"\n",
        "savedir = \"bisenet_training\"\n",
        "pretrained_weights = \"bisenetv1_pretrained.pth\"\n",
        "epochs = 20\n",
        "\n",
        "# Base directory of the project\n",
        "base_dir = \"/content/AnomalySegmentation/train\"\n",
        "# Dataset directory\n",
        "data_dir = \"/content/cityscapes\"\n",
        "\n",
        "print(f\"----- Fine-tuning {model} for VOID classification -----\")\n",
        "!cd {base_dir} && python -W ignore main.py --savedir {savedir} --datadir {data_dir} --model {model} --cuda --num-epochs=20 --epochs-save=1 --FineTune --decoder --loadWeights={pretrained_weights}\n",
        "print(f\"Model saved in /content/AnomalySegmentation/save/{savedir}\")\n",
        "# zip folder\n",
        "!zip -r save_{savedir}.zip /content/AnomalySegmentation/save/{savedir}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMrPCZ56IShf"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cchB40LlIT9a",
        "outputId": "30674a33-f5d0-47a4-a215-15cf17f372ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------\n",
            "\n",
            "Dataset: RoadAnomaly21 net: erfnet\n",
            "AUPRC score: 23.066538132595678\n",
            "FPR@TPR95: 83.00218872131218\n",
            "\n",
            "Dataset: RoadObsticle21 net: erfnet\n",
            "AUPRC score: 1.2479619783498568\n",
            "FPR@TPR95: 98.77720541475112\n",
            "\n",
            "Dataset: FS_LostFound_full net: erfnet\n",
            "AUPRC score: 3.9670465669000987\n",
            "FPR@TPR95: 37.15986952996774\n",
            "\n",
            "Dataset: fs_static net: erfnet\n",
            "AUPRC score: 12.255619101525266\n",
            "FPR@TPR95: 82.25043369836908\n",
            "\n",
            "Dataset: RoadAnomaly net: erfnet\n",
            "AUPRC score: 10.108372222814976\n",
            "FPR@TPR95: 97.9176876261683\n",
            "----------------------------\n",
            "\n",
            "Dataset: RoadAnomaly21 net: enet\n",
            "AUPRC score: 17.710540775846635\n",
            "FPR@TPR95: 93.9867224686995\n",
            "\n",
            "Dataset: RoadObsticle21 net: enet\n",
            "AUPRC score: 1.3713287968833945\n",
            "FPR@TPR95: 91.93726483525218\n",
            "\n",
            "Dataset: FS_LostFound_full net: enet\n",
            "AUPRC score: 0.9859109956888955\n",
            "FPR@TPR95: 60.28533261005652\n",
            "\n",
            "Dataset: fs_static net: enet\n",
            "AUPRC score: 7.72351282202996\n",
            "FPR@TPR95: 78.34549796336687\n",
            "\n",
            "Dataset: RoadAnomaly net: enet\n",
            "AUPRC score: 12.788489618794117\n",
            "FPR@TPR95: 86.93573427839908\n",
            "----------------------------\n",
            "\n",
            "Dataset: RoadAnomaly21 net: bisenet\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n",
            "100% 44.7M/44.7M [00:00<00:00, 352MB/s]\n",
            "AUPRC score: 21.81055194591118\n",
            "FPR@TPR95: 91.87575225697388\n",
            "\n",
            "Dataset: RoadObsticle21 net: bisenet\n",
            "AUPRC score: 10.298027408646206\n",
            "FPR@TPR95: 44.90818638296744\n",
            "\n",
            "Dataset: FS_LostFound_full net: bisenet\n",
            "AUPRC score: 3.5811069764660606\n",
            "FPR@TPR95: 44.204070137081445\n",
            "\n",
            "Dataset: fs_static net: bisenet\n",
            "AUPRC score: 9.766178585596988\n",
            "FPR@TPR95: 50.448052314843984\n",
            "\n",
            "Dataset: RoadAnomaly net: bisenet\n",
            "AUPRC score: 12.153410762011895\n",
            "FPR@TPR95: 91.2516594411978\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "no_execute = False\n",
        "just_once = False\n",
        "\n",
        "for net in [\"erfnet\", \"enet\", \"bisenet\"]:\n",
        "  print(\"----------------------------\")\n",
        "  for dataset_dir in ['RoadAnomaly21', 'RoadObsticle21', 'FS_LostFound_full', 'fs_static', 'RoadAnomaly']:\n",
        "\n",
        "    if no_execute:\n",
        "      break\n",
        "\n",
        "    load_dir = f'/content/AnomalySegmentation/save/{net}_training_void'\n",
        "    weights = f'/model_best.pth'\n",
        "    format_file = os.listdir(f'/content/Validation_Dataset/{dataset_dir}/images')[0].split(\".\")[1]\n",
        "    input =f'/content/Validation_Dataset/{dataset_dir}/images/\\*.{format_file}'\n",
        "    print(f\"\\nDataset: {dataset_dir} net: {net}\")\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "      !python -W ignore /content/AnomalySegmentation/eval/evalAnomaly.py --input {input} --void --model {net} --loadDir {load_dir} --loadWeights {weights} | tail -n 2\n",
        "    else:\n",
        "      !python -W ignore /content/AnomalySegmentation/eval/evalAnomaly.py --input {input} --void --model {net} --loadDir {load_dir} --loadWeights {weights} --cpu | tail -n 2\n",
        "\n",
        "    if just_once:\n",
        "      no_execute = True\n",
        "      just_once = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xviXChktBk0"
      },
      "source": [
        "# Extensions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVugUIVbxMSq"
      },
      "source": [
        "##Mahalanobis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "S70ucntWxy4F",
        "outputId": "c7bcb158-a13b-4ba9-f3f3-f4bb98129185"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model: erfnet\n",
            "Loading weights: /content/AnomalySegmentation/trained_models/erfnet_pretrained.pth\n",
            "/content/cityscapes/leftImg8bit/train\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/content/AnomalySegmentation/eval/mahalanobis.py:90: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model = load_my_state_dict(model, torch.load(weightspath, map_location=lambda storage, loc: storage))\n",
            "odict_keys(['module.encoder.initial_block.conv.weight', 'module.encoder.initial_block.conv.bias', 'module.encoder.initial_block.bn.weight', 'module.encoder.initial_block.bn.bias', 'module.encoder.initial_block.bn.running_mean', 'module.encoder.initial_block.bn.running_var', 'module.encoder.layers.0.conv.weight', 'module.encoder.layers.0.conv.bias', 'module.encoder.layers.0.bn.weight', 'module.encoder.layers.0.bn.bias', 'module.encoder.layers.0.bn.running_mean', 'module.encoder.layers.0.bn.running_var', 'module.encoder.layers.1.conv3x1_1.weight', 'module.encoder.layers.1.conv3x1_1.bias', 'module.encoder.layers.1.conv1x3_1.weight', 'module.encoder.layers.1.conv1x3_1.bias', 'module.encoder.layers.1.conv3x1_2.weight', 'module.encoder.layers.1.conv3x1_2.bias', 'module.encoder.layers.1.conv1x3_2.weight', 'module.encoder.layers.1.conv1x3_2.bias', 'module.encoder.layers.1.bn1.weight', 'module.encoder.layers.1.bn1.bias', 'module.encoder.layers.1.bn1.running_mean', 'module.encoder.layers.1.bn1.running_var', 'module.encoder.layers.1.bn2.weight', 'module.encoder.layers.1.bn2.bias', 'module.encoder.layers.1.bn2.running_mean', 'module.encoder.layers.1.bn2.running_var', 'module.encoder.layers.2.conv3x1_1.weight', 'module.encoder.layers.2.conv3x1_1.bias', 'module.encoder.layers.2.conv1x3_1.weight', 'module.encoder.layers.2.conv1x3_1.bias', 'module.encoder.layers.2.conv3x1_2.weight', 'module.encoder.layers.2.conv3x1_2.bias', 'module.encoder.layers.2.conv1x3_2.weight', 'module.encoder.layers.2.conv1x3_2.bias', 'module.encoder.layers.2.bn1.weight', 'module.encoder.layers.2.bn1.bias', 'module.encoder.layers.2.bn1.running_mean', 'module.encoder.layers.2.bn1.running_var', 'module.encoder.layers.2.bn2.weight', 'module.encoder.layers.2.bn2.bias', 'module.encoder.layers.2.bn2.running_mean', 'module.encoder.layers.2.bn2.running_var', 'module.encoder.layers.3.conv3x1_1.weight', 'module.encoder.layers.3.conv3x1_1.bias', 'module.encoder.layers.3.conv1x3_1.weight', 'module.encoder.layers.3.conv1x3_1.bias', 'module.encoder.layers.3.conv3x1_2.weight', 'module.encoder.layers.3.conv3x1_2.bias', 'module.encoder.layers.3.conv1x3_2.weight', 'module.encoder.layers.3.conv1x3_2.bias', 'module.encoder.layers.3.bn1.weight', 'module.encoder.layers.3.bn1.bias', 'module.encoder.layers.3.bn1.running_mean', 'module.encoder.layers.3.bn1.running_var', 'module.encoder.layers.3.bn2.weight', 'module.encoder.layers.3.bn2.bias', 'module.encoder.layers.3.bn2.running_mean', 'module.encoder.layers.3.bn2.running_var', 'module.encoder.layers.4.conv3x1_1.weight', 'module.encoder.layers.4.conv3x1_1.bias', 'module.encoder.layers.4.conv1x3_1.weight', 'module.encoder.layers.4.conv1x3_1.bias', 'module.encoder.layers.4.conv3x1_2.weight', 'module.encoder.layers.4.conv3x1_2.bias', 'module.encoder.layers.4.conv1x3_2.weight', 'module.encoder.layers.4.conv1x3_2.bias', 'module.encoder.layers.4.bn1.weight', 'module.encoder.layers.4.bn1.bias', 'module.encoder.layers.4.bn1.running_mean', 'module.encoder.layers.4.bn1.running_var', 'module.encoder.layers.4.bn2.weight', 'module.encoder.layers.4.bn2.bias', 'module.encoder.layers.4.bn2.running_mean', 'module.encoder.layers.4.bn2.running_var', 'module.encoder.layers.5.conv3x1_1.weight', 'module.encoder.layers.5.conv3x1_1.bias', 'module.encoder.layers.5.conv1x3_1.weight', 'module.encoder.layers.5.conv1x3_1.bias', 'module.encoder.layers.5.conv3x1_2.weight', 'module.encoder.layers.5.conv3x1_2.bias', 'module.encoder.layers.5.conv1x3_2.weight', 'module.encoder.layers.5.conv1x3_2.bias', 'module.encoder.layers.5.bn1.weight', 'module.encoder.layers.5.bn1.bias', 'module.encoder.layers.5.bn1.running_mean', 'module.encoder.layers.5.bn1.running_var', 'module.encoder.layers.5.bn2.weight', 'module.encoder.layers.5.bn2.bias', 'module.encoder.layers.5.bn2.running_mean', 'module.encoder.layers.5.bn2.running_var', 'module.encoder.layers.6.conv.weight', 'module.encoder.layers.6.conv.bias', 'module.encoder.layers.6.bn.weight', 'module.encoder.layers.6.bn.bias', 'module.encoder.layers.6.bn.running_mean', 'module.encoder.layers.6.bn.running_var', 'module.encoder.layers.7.conv3x1_1.weight', 'module.encoder.layers.7.conv3x1_1.bias', 'module.encoder.layers.7.conv1x3_1.weight', 'module.encoder.layers.7.conv1x3_1.bias', 'module.encoder.layers.7.conv3x1_2.weight', 'module.encoder.layers.7.conv3x1_2.bias', 'module.encoder.layers.7.conv1x3_2.weight', 'module.encoder.layers.7.conv1x3_2.bias', 'module.encoder.layers.7.bn1.weight', 'module.encoder.layers.7.bn1.bias', 'module.encoder.layers.7.bn1.running_mean', 'module.encoder.layers.7.bn1.running_var', 'module.encoder.layers.7.bn2.weight', 'module.encoder.layers.7.bn2.bias', 'module.encoder.layers.7.bn2.running_mean', 'module.encoder.layers.7.bn2.running_var', 'module.encoder.layers.8.conv3x1_1.weight', 'module.encoder.layers.8.conv3x1_1.bias', 'module.encoder.layers.8.conv1x3_1.weight', 'module.encoder.layers.8.conv1x3_1.bias', 'module.encoder.layers.8.conv3x1_2.weight', 'module.encoder.layers.8.conv3x1_2.bias', 'module.encoder.layers.8.conv1x3_2.weight', 'module.encoder.layers.8.conv1x3_2.bias', 'module.encoder.layers.8.bn1.weight', 'module.encoder.layers.8.bn1.bias', 'module.encoder.layers.8.bn1.running_mean', 'module.encoder.layers.8.bn1.running_var', 'module.encoder.layers.8.bn2.weight', 'module.encoder.layers.8.bn2.bias', 'module.encoder.layers.8.bn2.running_mean', 'module.encoder.layers.8.bn2.running_var', 'module.encoder.layers.9.conv3x1_1.weight', 'module.encoder.layers.9.conv3x1_1.bias', 'module.encoder.layers.9.conv1x3_1.weight', 'module.encoder.layers.9.conv1x3_1.bias', 'module.encoder.layers.9.conv3x1_2.weight', 'module.encoder.layers.9.conv3x1_2.bias', 'module.encoder.layers.9.conv1x3_2.weight', 'module.encoder.layers.9.conv1x3_2.bias', 'module.encoder.layers.9.bn1.weight', 'module.encoder.layers.9.bn1.bias', 'module.encoder.layers.9.bn1.running_mean', 'module.encoder.layers.9.bn1.running_var', 'module.encoder.layers.9.bn2.weight', 'module.encoder.layers.9.bn2.bias', 'module.encoder.layers.9.bn2.running_mean', 'module.encoder.layers.9.bn2.running_var', 'module.encoder.layers.10.conv3x1_1.weight', 'module.encoder.layers.10.conv3x1_1.bias', 'module.encoder.layers.10.conv1x3_1.weight', 'module.encoder.layers.10.conv1x3_1.bias', 'module.encoder.layers.10.conv3x1_2.weight', 'module.encoder.layers.10.conv3x1_2.bias', 'module.encoder.layers.10.conv1x3_2.weight', 'module.encoder.layers.10.conv1x3_2.bias', 'module.encoder.layers.10.bn1.weight', 'module.encoder.layers.10.bn1.bias', 'module.encoder.layers.10.bn1.running_mean', 'module.encoder.layers.10.bn1.running_var', 'module.encoder.layers.10.bn2.weight', 'module.encoder.layers.10.bn2.bias', 'module.encoder.layers.10.bn2.running_mean', 'module.encoder.layers.10.bn2.running_var', 'module.encoder.layers.11.conv3x1_1.weight', 'module.encoder.layers.11.conv3x1_1.bias', 'module.encoder.layers.11.conv1x3_1.weight', 'module.encoder.layers.11.conv1x3_1.bias', 'module.encoder.layers.11.conv3x1_2.weight', 'module.encoder.layers.11.conv3x1_2.bias', 'module.encoder.layers.11.conv1x3_2.weight', 'module.encoder.layers.11.conv1x3_2.bias', 'module.encoder.layers.11.bn1.weight', 'module.encoder.layers.11.bn1.bias', 'module.encoder.layers.11.bn1.running_mean', 'module.encoder.layers.11.bn1.running_var', 'module.encoder.layers.11.bn2.weight', 'module.encoder.layers.11.bn2.bias', 'module.encoder.layers.11.bn2.running_mean', 'module.encoder.layers.11.bn2.running_var', 'module.encoder.layers.12.conv3x1_1.weight', 'module.encoder.layers.12.conv3x1_1.bias', 'module.encoder.layers.12.conv1x3_1.weight', 'module.encoder.layers.12.conv1x3_1.bias', 'module.encoder.layers.12.conv3x1_2.weight', 'module.encoder.layers.12.conv3x1_2.bias', 'module.encoder.layers.12.conv1x3_2.weight', 'module.encoder.layers.12.conv1x3_2.bias', 'module.encoder.layers.12.bn1.weight', 'module.encoder.layers.12.bn1.bias', 'module.encoder.layers.12.bn1.running_mean', 'module.encoder.layers.12.bn1.running_var', 'module.encoder.layers.12.bn2.weight', 'module.encoder.layers.12.bn2.bias', 'module.encoder.layers.12.bn2.running_mean', 'module.encoder.layers.12.bn2.running_var', 'module.encoder.layers.13.conv3x1_1.weight', 'module.encoder.layers.13.conv3x1_1.bias', 'module.encoder.layers.13.conv1x3_1.weight', 'module.encoder.layers.13.conv1x3_1.bias', 'module.encoder.layers.13.conv3x1_2.weight', 'module.encoder.layers.13.conv3x1_2.bias', 'module.encoder.layers.13.conv1x3_2.weight', 'module.encoder.layers.13.conv1x3_2.bias', 'module.encoder.layers.13.bn1.weight', 'module.encoder.layers.13.bn1.bias', 'module.encoder.layers.13.bn1.running_mean', 'module.encoder.layers.13.bn1.running_var', 'module.encoder.layers.13.bn2.weight', 'module.encoder.layers.13.bn2.bias', 'module.encoder.layers.13.bn2.running_mean', 'module.encoder.layers.13.bn2.running_var', 'module.encoder.layers.14.conv3x1_1.weight', 'module.encoder.layers.14.conv3x1_1.bias', 'module.encoder.layers.14.conv1x3_1.weight', 'module.encoder.layers.14.conv1x3_1.bias', 'module.encoder.layers.14.conv3x1_2.weight', 'module.encoder.layers.14.conv3x1_2.bias', 'module.encoder.layers.14.conv1x3_2.weight', 'module.encoder.layers.14.conv1x3_2.bias', 'module.encoder.layers.14.bn1.weight', 'module.encoder.layers.14.bn1.bias', 'module.encoder.layers.14.bn1.running_mean', 'module.encoder.layers.14.bn1.running_var', 'module.encoder.layers.14.bn2.weight', 'module.encoder.layers.14.bn2.bias', 'module.encoder.layers.14.bn2.running_mean', 'module.encoder.layers.14.bn2.running_var', 'module.decoder.layers.0.conv.weight', 'module.decoder.layers.0.conv.bias', 'module.decoder.layers.0.bn.weight', 'module.decoder.layers.0.bn.bias', 'module.decoder.layers.0.bn.running_mean', 'module.decoder.layers.0.bn.running_var', 'module.decoder.layers.1.conv3x1_1.weight', 'module.decoder.layers.1.conv3x1_1.bias', 'module.decoder.layers.1.conv1x3_1.weight', 'module.decoder.layers.1.conv1x3_1.bias', 'module.decoder.layers.1.bn1.weight', 'module.decoder.layers.1.bn1.bias', 'module.decoder.layers.1.bn1.running_mean', 'module.decoder.layers.1.bn1.running_var', 'module.decoder.layers.1.conv3x1_2.weight', 'module.decoder.layers.1.conv3x1_2.bias', 'module.decoder.layers.1.conv1x3_2.weight', 'module.decoder.layers.1.conv1x3_2.bias', 'module.decoder.layers.1.bn2.weight', 'module.decoder.layers.1.bn2.bias', 'module.decoder.layers.1.bn2.running_mean', 'module.decoder.layers.1.bn2.running_var', 'module.decoder.layers.2.conv3x1_1.weight', 'module.decoder.layers.2.conv3x1_1.bias', 'module.decoder.layers.2.conv1x3_1.weight', 'module.decoder.layers.2.conv1x3_1.bias', 'module.decoder.layers.2.bn1.weight', 'module.decoder.layers.2.bn1.bias', 'module.decoder.layers.2.bn1.running_mean', 'module.decoder.layers.2.bn1.running_var', 'module.decoder.layers.2.conv3x1_2.weight', 'module.decoder.layers.2.conv3x1_2.bias', 'module.decoder.layers.2.conv1x3_2.weight', 'module.decoder.layers.2.conv1x3_2.bias', 'module.decoder.layers.2.bn2.weight', 'module.decoder.layers.2.bn2.bias', 'module.decoder.layers.2.bn2.running_mean', 'module.decoder.layers.2.bn2.running_var', 'module.decoder.layers.3.conv.weight', 'module.decoder.layers.3.conv.bias', 'module.decoder.layers.3.bn.weight', 'module.decoder.layers.3.bn.bias', 'module.decoder.layers.3.bn.running_mean', 'module.decoder.layers.3.bn.running_var', 'module.decoder.layers.4.conv3x1_1.weight', 'module.decoder.layers.4.conv3x1_1.bias', 'module.decoder.layers.4.conv1x3_1.weight', 'module.decoder.layers.4.conv1x3_1.bias', 'module.decoder.layers.4.bn1.weight', 'module.decoder.layers.4.bn1.bias', 'module.decoder.layers.4.bn1.running_mean', 'module.decoder.layers.4.bn1.running_var', 'module.decoder.layers.4.conv3x1_2.weight', 'module.decoder.layers.4.conv3x1_2.bias', 'module.decoder.layers.4.conv1x3_2.weight', 'module.decoder.layers.4.conv1x3_2.bias', 'module.decoder.layers.4.bn2.weight', 'module.decoder.layers.4.bn2.bias', 'module.decoder.layers.4.bn2.running_mean', 'module.decoder.layers.4.bn2.running_var', 'module.decoder.layers.5.conv3x1_1.weight', 'module.decoder.layers.5.conv3x1_1.bias', 'module.decoder.layers.5.conv1x3_1.weight', 'module.decoder.layers.5.conv1x3_1.bias', 'module.decoder.layers.5.bn1.weight', 'module.decoder.layers.5.bn1.bias', 'module.decoder.layers.5.bn1.running_mean', 'module.decoder.layers.5.bn1.running_var', 'module.decoder.layers.5.conv3x1_2.weight', 'module.decoder.layers.5.conv3x1_2.bias', 'module.decoder.layers.5.conv1x3_2.weight', 'module.decoder.layers.5.conv1x3_2.bias', 'module.decoder.layers.5.bn2.weight', 'module.decoder.layers.5.bn2.bias', 'module.decoder.layers.5.bn2.running_mean', 'module.decoder.layers.5.bn2.running_var', 'module.decoder.output_conv.weight', 'module.decoder.output_conv.bias'])\n",
            "odict_keys(['module.encoder.initial_block.conv.weight', 'module.encoder.initial_block.conv.bias', 'module.encoder.initial_block.bn.weight', 'module.encoder.initial_block.bn.bias', 'module.encoder.initial_block.bn.running_mean', 'module.encoder.initial_block.bn.running_var', 'module.encoder.initial_block.bn.num_batches_tracked', 'module.encoder.layers.0.conv.weight', 'module.encoder.layers.0.conv.bias', 'module.encoder.layers.0.bn.weight', 'module.encoder.layers.0.bn.bias', 'module.encoder.layers.0.bn.running_mean', 'module.encoder.layers.0.bn.running_var', 'module.encoder.layers.0.bn.num_batches_tracked', 'module.encoder.layers.1.conv3x1_1.weight', 'module.encoder.layers.1.conv3x1_1.bias', 'module.encoder.layers.1.conv1x3_1.weight', 'module.encoder.layers.1.conv1x3_1.bias', 'module.encoder.layers.1.bn1.weight', 'module.encoder.layers.1.bn1.bias', 'module.encoder.layers.1.bn1.running_mean', 'module.encoder.layers.1.bn1.running_var', 'module.encoder.layers.1.bn1.num_batches_tracked', 'module.encoder.layers.1.conv3x1_2.weight', 'module.encoder.layers.1.conv3x1_2.bias', 'module.encoder.layers.1.conv1x3_2.weight', 'module.encoder.layers.1.conv1x3_2.bias', 'module.encoder.layers.1.bn2.weight', 'module.encoder.layers.1.bn2.bias', 'module.encoder.layers.1.bn2.running_mean', 'module.encoder.layers.1.bn2.running_var', 'module.encoder.layers.1.bn2.num_batches_tracked', 'module.encoder.layers.2.conv3x1_1.weight', 'module.encoder.layers.2.conv3x1_1.bias', 'module.encoder.layers.2.conv1x3_1.weight', 'module.encoder.layers.2.conv1x3_1.bias', 'module.encoder.layers.2.bn1.weight', 'module.encoder.layers.2.bn1.bias', 'module.encoder.layers.2.bn1.running_mean', 'module.encoder.layers.2.bn1.running_var', 'module.encoder.layers.2.bn1.num_batches_tracked', 'module.encoder.layers.2.conv3x1_2.weight', 'module.encoder.layers.2.conv3x1_2.bias', 'module.encoder.layers.2.conv1x3_2.weight', 'module.encoder.layers.2.conv1x3_2.bias', 'module.encoder.layers.2.bn2.weight', 'module.encoder.layers.2.bn2.bias', 'module.encoder.layers.2.bn2.running_mean', 'module.encoder.layers.2.bn2.running_var', 'module.encoder.layers.2.bn2.num_batches_tracked', 'module.encoder.layers.3.conv3x1_1.weight', 'module.encoder.layers.3.conv3x1_1.bias', 'module.encoder.layers.3.conv1x3_1.weight', 'module.encoder.layers.3.conv1x3_1.bias', 'module.encoder.layers.3.bn1.weight', 'module.encoder.layers.3.bn1.bias', 'module.encoder.layers.3.bn1.running_mean', 'module.encoder.layers.3.bn1.running_var', 'module.encoder.layers.3.bn1.num_batches_tracked', 'module.encoder.layers.3.conv3x1_2.weight', 'module.encoder.layers.3.conv3x1_2.bias', 'module.encoder.layers.3.conv1x3_2.weight', 'module.encoder.layers.3.conv1x3_2.bias', 'module.encoder.layers.3.bn2.weight', 'module.encoder.layers.3.bn2.bias', 'module.encoder.layers.3.bn2.running_mean', 'module.encoder.layers.3.bn2.running_var', 'module.encoder.layers.3.bn2.num_batches_tracked', 'module.encoder.layers.4.conv3x1_1.weight', 'module.encoder.layers.4.conv3x1_1.bias', 'module.encoder.layers.4.conv1x3_1.weight', 'module.encoder.layers.4.conv1x3_1.bias', 'module.encoder.layers.4.bn1.weight', 'module.encoder.layers.4.bn1.bias', 'module.encoder.layers.4.bn1.running_mean', 'module.encoder.layers.4.bn1.running_var', 'module.encoder.layers.4.bn1.num_batches_tracked', 'module.encoder.layers.4.conv3x1_2.weight', 'module.encoder.layers.4.conv3x1_2.bias', 'module.encoder.layers.4.conv1x3_2.weight', 'module.encoder.layers.4.conv1x3_2.bias', 'module.encoder.layers.4.bn2.weight', 'module.encoder.layers.4.bn2.bias', 'module.encoder.layers.4.bn2.running_mean', 'module.encoder.layers.4.bn2.running_var', 'module.encoder.layers.4.bn2.num_batches_tracked', 'module.encoder.layers.5.conv3x1_1.weight', 'module.encoder.layers.5.conv3x1_1.bias', 'module.encoder.layers.5.conv1x3_1.weight', 'module.encoder.layers.5.conv1x3_1.bias', 'module.encoder.layers.5.bn1.weight', 'module.encoder.layers.5.bn1.bias', 'module.encoder.layers.5.bn1.running_mean', 'module.encoder.layers.5.bn1.running_var', 'module.encoder.layers.5.bn1.num_batches_tracked', 'module.encoder.layers.5.conv3x1_2.weight', 'module.encoder.layers.5.conv3x1_2.bias', 'module.encoder.layers.5.conv1x3_2.weight', 'module.encoder.layers.5.conv1x3_2.bias', 'module.encoder.layers.5.bn2.weight', 'module.encoder.layers.5.bn2.bias', 'module.encoder.layers.5.bn2.running_mean', 'module.encoder.layers.5.bn2.running_var', 'module.encoder.layers.5.bn2.num_batches_tracked', 'module.encoder.layers.6.conv.weight', 'module.encoder.layers.6.conv.bias', 'module.encoder.layers.6.bn.weight', 'module.encoder.layers.6.bn.bias', 'module.encoder.layers.6.bn.running_mean', 'module.encoder.layers.6.bn.running_var', 'module.encoder.layers.6.bn.num_batches_tracked', 'module.encoder.layers.7.conv3x1_1.weight', 'module.encoder.layers.7.conv3x1_1.bias', 'module.encoder.layers.7.conv1x3_1.weight', 'module.encoder.layers.7.conv1x3_1.bias', 'module.encoder.layers.7.bn1.weight', 'module.encoder.layers.7.bn1.bias', 'module.encoder.layers.7.bn1.running_mean', 'module.encoder.layers.7.bn1.running_var', 'module.encoder.layers.7.bn1.num_batches_tracked', 'module.encoder.layers.7.conv3x1_2.weight', 'module.encoder.layers.7.conv3x1_2.bias', 'module.encoder.layers.7.conv1x3_2.weight', 'module.encoder.layers.7.conv1x3_2.bias', 'module.encoder.layers.7.bn2.weight', 'module.encoder.layers.7.bn2.bias', 'module.encoder.layers.7.bn2.running_mean', 'module.encoder.layers.7.bn2.running_var', 'module.encoder.layers.7.bn2.num_batches_tracked', 'module.encoder.layers.8.conv3x1_1.weight', 'module.encoder.layers.8.conv3x1_1.bias', 'module.encoder.layers.8.conv1x3_1.weight', 'module.encoder.layers.8.conv1x3_1.bias', 'module.encoder.layers.8.bn1.weight', 'module.encoder.layers.8.bn1.bias', 'module.encoder.layers.8.bn1.running_mean', 'module.encoder.layers.8.bn1.running_var', 'module.encoder.layers.8.bn1.num_batches_tracked', 'module.encoder.layers.8.conv3x1_2.weight', 'module.encoder.layers.8.conv3x1_2.bias', 'module.encoder.layers.8.conv1x3_2.weight', 'module.encoder.layers.8.conv1x3_2.bias', 'module.encoder.layers.8.bn2.weight', 'module.encoder.layers.8.bn2.bias', 'module.encoder.layers.8.bn2.running_mean', 'module.encoder.layers.8.bn2.running_var', 'module.encoder.layers.8.bn2.num_batches_tracked', 'module.encoder.layers.9.conv3x1_1.weight', 'module.encoder.layers.9.conv3x1_1.bias', 'module.encoder.layers.9.conv1x3_1.weight', 'module.encoder.layers.9.conv1x3_1.bias', 'module.encoder.layers.9.bn1.weight', 'module.encoder.layers.9.bn1.bias', 'module.encoder.layers.9.bn1.running_mean', 'module.encoder.layers.9.bn1.running_var', 'module.encoder.layers.9.bn1.num_batches_tracked', 'module.encoder.layers.9.conv3x1_2.weight', 'module.encoder.layers.9.conv3x1_2.bias', 'module.encoder.layers.9.conv1x3_2.weight', 'module.encoder.layers.9.conv1x3_2.bias', 'module.encoder.layers.9.bn2.weight', 'module.encoder.layers.9.bn2.bias', 'module.encoder.layers.9.bn2.running_mean', 'module.encoder.layers.9.bn2.running_var', 'module.encoder.layers.9.bn2.num_batches_tracked', 'module.encoder.layers.10.conv3x1_1.weight', 'module.encoder.layers.10.conv3x1_1.bias', 'module.encoder.layers.10.conv1x3_1.weight', 'module.encoder.layers.10.conv1x3_1.bias', 'module.encoder.layers.10.bn1.weight', 'module.encoder.layers.10.bn1.bias', 'module.encoder.layers.10.bn1.running_mean', 'module.encoder.layers.10.bn1.running_var', 'module.encoder.layers.10.bn1.num_batches_tracked', 'module.encoder.layers.10.conv3x1_2.weight', 'module.encoder.layers.10.conv3x1_2.bias', 'module.encoder.layers.10.conv1x3_2.weight', 'module.encoder.layers.10.conv1x3_2.bias', 'module.encoder.layers.10.bn2.weight', 'module.encoder.layers.10.bn2.bias', 'module.encoder.layers.10.bn2.running_mean', 'module.encoder.layers.10.bn2.running_var', 'module.encoder.layers.10.bn2.num_batches_tracked', 'module.encoder.layers.11.conv3x1_1.weight', 'module.encoder.layers.11.conv3x1_1.bias', 'module.encoder.layers.11.conv1x3_1.weight', 'module.encoder.layers.11.conv1x3_1.bias', 'module.encoder.layers.11.bn1.weight', 'module.encoder.layers.11.bn1.bias', 'module.encoder.layers.11.bn1.running_mean', 'module.encoder.layers.11.bn1.running_var', 'module.encoder.layers.11.bn1.num_batches_tracked', 'module.encoder.layers.11.conv3x1_2.weight', 'module.encoder.layers.11.conv3x1_2.bias', 'module.encoder.layers.11.conv1x3_2.weight', 'module.encoder.layers.11.conv1x3_2.bias', 'module.encoder.layers.11.bn2.weight', 'module.encoder.layers.11.bn2.bias', 'module.encoder.layers.11.bn2.running_mean', 'module.encoder.layers.11.bn2.running_var', 'module.encoder.layers.11.bn2.num_batches_tracked', 'module.encoder.layers.12.conv3x1_1.weight', 'module.encoder.layers.12.conv3x1_1.bias', 'module.encoder.layers.12.conv1x3_1.weight', 'module.encoder.layers.12.conv1x3_1.bias', 'module.encoder.layers.12.bn1.weight', 'module.encoder.layers.12.bn1.bias', 'module.encoder.layers.12.bn1.running_mean', 'module.encoder.layers.12.bn1.running_var', 'module.encoder.layers.12.bn1.num_batches_tracked', 'module.encoder.layers.12.conv3x1_2.weight', 'module.encoder.layers.12.conv3x1_2.bias', 'module.encoder.layers.12.conv1x3_2.weight', 'module.encoder.layers.12.conv1x3_2.bias', 'module.encoder.layers.12.bn2.weight', 'module.encoder.layers.12.bn2.bias', 'module.encoder.layers.12.bn2.running_mean', 'module.encoder.layers.12.bn2.running_var', 'module.encoder.layers.12.bn2.num_batches_tracked', 'module.encoder.layers.13.conv3x1_1.weight', 'module.encoder.layers.13.conv3x1_1.bias', 'module.encoder.layers.13.conv1x3_1.weight', 'module.encoder.layers.13.conv1x3_1.bias', 'module.encoder.layers.13.bn1.weight', 'module.encoder.layers.13.bn1.bias', 'module.encoder.layers.13.bn1.running_mean', 'module.encoder.layers.13.bn1.running_var', 'module.encoder.layers.13.bn1.num_batches_tracked', 'module.encoder.layers.13.conv3x1_2.weight', 'module.encoder.layers.13.conv3x1_2.bias', 'module.encoder.layers.13.conv1x3_2.weight', 'module.encoder.layers.13.conv1x3_2.bias', 'module.encoder.layers.13.bn2.weight', 'module.encoder.layers.13.bn2.bias', 'module.encoder.layers.13.bn2.running_mean', 'module.encoder.layers.13.bn2.running_var', 'module.encoder.layers.13.bn2.num_batches_tracked', 'module.encoder.layers.14.conv3x1_1.weight', 'module.encoder.layers.14.conv3x1_1.bias', 'module.encoder.layers.14.conv1x3_1.weight', 'module.encoder.layers.14.conv1x3_1.bias', 'module.encoder.layers.14.bn1.weight', 'module.encoder.layers.14.bn1.bias', 'module.encoder.layers.14.bn1.running_mean', 'module.encoder.layers.14.bn1.running_var', 'module.encoder.layers.14.bn1.num_batches_tracked', 'module.encoder.layers.14.conv3x1_2.weight', 'module.encoder.layers.14.conv3x1_2.bias', 'module.encoder.layers.14.conv1x3_2.weight', 'module.encoder.layers.14.conv1x3_2.bias', 'module.encoder.layers.14.bn2.weight', 'module.encoder.layers.14.bn2.bias', 'module.encoder.layers.14.bn2.running_mean', 'module.encoder.layers.14.bn2.running_var', 'module.encoder.layers.14.bn2.num_batches_tracked', 'module.encoder.output_conv.weight', 'module.encoder.output_conv.bias', 'module.decoder.layers.0.conv.weight', 'module.decoder.layers.0.conv.bias', 'module.decoder.layers.0.bn.weight', 'module.decoder.layers.0.bn.bias', 'module.decoder.layers.0.bn.running_mean', 'module.decoder.layers.0.bn.running_var', 'module.decoder.layers.0.bn.num_batches_tracked', 'module.decoder.layers.1.conv3x1_1.weight', 'module.decoder.layers.1.conv3x1_1.bias', 'module.decoder.layers.1.conv1x3_1.weight', 'module.decoder.layers.1.conv1x3_1.bias', 'module.decoder.layers.1.bn1.weight', 'module.decoder.layers.1.bn1.bias', 'module.decoder.layers.1.bn1.running_mean', 'module.decoder.layers.1.bn1.running_var', 'module.decoder.layers.1.bn1.num_batches_tracked', 'module.decoder.layers.1.conv3x1_2.weight', 'module.decoder.layers.1.conv3x1_2.bias', 'module.decoder.layers.1.conv1x3_2.weight', 'module.decoder.layers.1.conv1x3_2.bias', 'module.decoder.layers.1.bn2.weight', 'module.decoder.layers.1.bn2.bias', 'module.decoder.layers.1.bn2.running_mean', 'module.decoder.layers.1.bn2.running_var', 'module.decoder.layers.1.bn2.num_batches_tracked', 'module.decoder.layers.2.conv3x1_1.weight', 'module.decoder.layers.2.conv3x1_1.bias', 'module.decoder.layers.2.conv1x3_1.weight', 'module.decoder.layers.2.conv1x3_1.bias', 'module.decoder.layers.2.bn1.weight', 'module.decoder.layers.2.bn1.bias', 'module.decoder.layers.2.bn1.running_mean', 'module.decoder.layers.2.bn1.running_var', 'module.decoder.layers.2.bn1.num_batches_tracked', 'module.decoder.layers.2.conv3x1_2.weight', 'module.decoder.layers.2.conv3x1_2.bias', 'module.decoder.layers.2.conv1x3_2.weight', 'module.decoder.layers.2.conv1x3_2.bias', 'module.decoder.layers.2.bn2.weight', 'module.decoder.layers.2.bn2.bias', 'module.decoder.layers.2.bn2.running_mean', 'module.decoder.layers.2.bn2.running_var', 'module.decoder.layers.2.bn2.num_batches_tracked', 'module.decoder.layers.3.conv.weight', 'module.decoder.layers.3.conv.bias', 'module.decoder.layers.3.bn.weight', 'module.decoder.layers.3.bn.bias', 'module.decoder.layers.3.bn.running_mean', 'module.decoder.layers.3.bn.running_var', 'module.decoder.layers.3.bn.num_batches_tracked', 'module.decoder.layers.4.conv3x1_1.weight', 'module.decoder.layers.4.conv3x1_1.bias', 'module.decoder.layers.4.conv1x3_1.weight', 'module.decoder.layers.4.conv1x3_1.bias', 'module.decoder.layers.4.bn1.weight', 'module.decoder.layers.4.bn1.bias', 'module.decoder.layers.4.bn1.running_mean', 'module.decoder.layers.4.bn1.running_var', 'module.decoder.layers.4.bn1.num_batches_tracked', 'module.decoder.layers.4.conv3x1_2.weight', 'module.decoder.layers.4.conv3x1_2.bias', 'module.decoder.layers.4.conv1x3_2.weight', 'module.decoder.layers.4.conv1x3_2.bias', 'module.decoder.layers.4.bn2.weight', 'module.decoder.layers.4.bn2.bias', 'module.decoder.layers.4.bn2.running_mean', 'module.decoder.layers.4.bn2.running_var', 'module.decoder.layers.4.bn2.num_batches_tracked', 'module.decoder.layers.5.conv3x1_1.weight', 'module.decoder.layers.5.conv3x1_1.bias', 'module.decoder.layers.5.conv1x3_1.weight', 'module.decoder.layers.5.conv1x3_1.bias', 'module.decoder.layers.5.bn1.weight', 'module.decoder.layers.5.bn1.bias', 'module.decoder.layers.5.bn1.running_mean', 'module.decoder.layers.5.bn1.running_var', 'module.decoder.layers.5.bn1.num_batches_tracked', 'module.decoder.layers.5.conv3x1_2.weight', 'module.decoder.layers.5.conv3x1_2.bias', 'module.decoder.layers.5.conv1x3_2.weight', 'module.decoder.layers.5.conv1x3_2.bias', 'module.decoder.layers.5.bn2.weight', 'module.decoder.layers.5.bn2.bias', 'module.decoder.layers.5.bn2.running_mean', 'module.decoder.layers.5.bn2.running_var', 'module.decoder.layers.5.bn2.num_batches_tracked', 'module.decoder.output_conv.weight', 'module.decoder.output_conv.bias'])\n",
            "Model and weights LOADED successfully\n",
            "100% 2975/2975 [07:55<00:00,  6.26it/s]\n",
            "Mean per class: torch.Size([19, 19])\n",
            "Mean output saved as '/content/AnomalySegmentation/save/mean_cityscapes_erfnet.npy'\n",
            "Loading model: erfnet\n",
            "Loading weights: /content/AnomalySegmentation/trained_models/erfnet_pretrained.pth\n",
            "pre_computed_mean torch.Size([19, 19])\n",
            "/content/cityscapes/leftImg8bit/train\n",
            "/content/AnomalySegmentation/eval/mahalanobis.py:90: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model = load_my_state_dict(model, torch.load(weightspath, map_location=lambda storage, loc: storage))\n",
            "odict_keys(['module.encoder.initial_block.conv.weight', 'module.encoder.initial_block.conv.bias', 'module.encoder.initial_block.bn.weight', 'module.encoder.initial_block.bn.bias', 'module.encoder.initial_block.bn.running_mean', 'module.encoder.initial_block.bn.running_var', 'module.encoder.layers.0.conv.weight', 'module.encoder.layers.0.conv.bias', 'module.encoder.layers.0.bn.weight', 'module.encoder.layers.0.bn.bias', 'module.encoder.layers.0.bn.running_mean', 'module.encoder.layers.0.bn.running_var', 'module.encoder.layers.1.conv3x1_1.weight', 'module.encoder.layers.1.conv3x1_1.bias', 'module.encoder.layers.1.conv1x3_1.weight', 'module.encoder.layers.1.conv1x3_1.bias', 'module.encoder.layers.1.conv3x1_2.weight', 'module.encoder.layers.1.conv3x1_2.bias', 'module.encoder.layers.1.conv1x3_2.weight', 'module.encoder.layers.1.conv1x3_2.bias', 'module.encoder.layers.1.bn1.weight', 'module.encoder.layers.1.bn1.bias', 'module.encoder.layers.1.bn1.running_mean', 'module.encoder.layers.1.bn1.running_var', 'module.encoder.layers.1.bn2.weight', 'module.encoder.layers.1.bn2.bias', 'module.encoder.layers.1.bn2.running_mean', 'module.encoder.layers.1.bn2.running_var', 'module.encoder.layers.2.conv3x1_1.weight', 'module.encoder.layers.2.conv3x1_1.bias', 'module.encoder.layers.2.conv1x3_1.weight', 'module.encoder.layers.2.conv1x3_1.bias', 'module.encoder.layers.2.conv3x1_2.weight', 'module.encoder.layers.2.conv3x1_2.bias', 'module.encoder.layers.2.conv1x3_2.weight', 'module.encoder.layers.2.conv1x3_2.bias', 'module.encoder.layers.2.bn1.weight', 'module.encoder.layers.2.bn1.bias', 'module.encoder.layers.2.bn1.running_mean', 'module.encoder.layers.2.bn1.running_var', 'module.encoder.layers.2.bn2.weight', 'module.encoder.layers.2.bn2.bias', 'module.encoder.layers.2.bn2.running_mean', 'module.encoder.layers.2.bn2.running_var', 'module.encoder.layers.3.conv3x1_1.weight', 'module.encoder.layers.3.conv3x1_1.bias', 'module.encoder.layers.3.conv1x3_1.weight', 'module.encoder.layers.3.conv1x3_1.bias', 'module.encoder.layers.3.conv3x1_2.weight', 'module.encoder.layers.3.conv3x1_2.bias', 'module.encoder.layers.3.conv1x3_2.weight', 'module.encoder.layers.3.conv1x3_2.bias', 'module.encoder.layers.3.bn1.weight', 'module.encoder.layers.3.bn1.bias', 'module.encoder.layers.3.bn1.running_mean', 'module.encoder.layers.3.bn1.running_var', 'module.encoder.layers.3.bn2.weight', 'module.encoder.layers.3.bn2.bias', 'module.encoder.layers.3.bn2.running_mean', 'module.encoder.layers.3.bn2.running_var', 'module.encoder.layers.4.conv3x1_1.weight', 'module.encoder.layers.4.conv3x1_1.bias', 'module.encoder.layers.4.conv1x3_1.weight', 'module.encoder.layers.4.conv1x3_1.bias', 'module.encoder.layers.4.conv3x1_2.weight', 'module.encoder.layers.4.conv3x1_2.bias', 'module.encoder.layers.4.conv1x3_2.weight', 'module.encoder.layers.4.conv1x3_2.bias', 'module.encoder.layers.4.bn1.weight', 'module.encoder.layers.4.bn1.bias', 'module.encoder.layers.4.bn1.running_mean', 'module.encoder.layers.4.bn1.running_var', 'module.encoder.layers.4.bn2.weight', 'module.encoder.layers.4.bn2.bias', 'module.encoder.layers.4.bn2.running_mean', 'module.encoder.layers.4.bn2.running_var', 'module.encoder.layers.5.conv3x1_1.weight', 'module.encoder.layers.5.conv3x1_1.bias', 'module.encoder.layers.5.conv1x3_1.weight', 'module.encoder.layers.5.conv1x3_1.bias', 'module.encoder.layers.5.conv3x1_2.weight', 'module.encoder.layers.5.conv3x1_2.bias', 'module.encoder.layers.5.conv1x3_2.weight', 'module.encoder.layers.5.conv1x3_2.bias', 'module.encoder.layers.5.bn1.weight', 'module.encoder.layers.5.bn1.bias', 'module.encoder.layers.5.bn1.running_mean', 'module.encoder.layers.5.bn1.running_var', 'module.encoder.layers.5.bn2.weight', 'module.encoder.layers.5.bn2.bias', 'module.encoder.layers.5.bn2.running_mean', 'module.encoder.layers.5.bn2.running_var', 'module.encoder.layers.6.conv.weight', 'module.encoder.layers.6.conv.bias', 'module.encoder.layers.6.bn.weight', 'module.encoder.layers.6.bn.bias', 'module.encoder.layers.6.bn.running_mean', 'module.encoder.layers.6.bn.running_var', 'module.encoder.layers.7.conv3x1_1.weight', 'module.encoder.layers.7.conv3x1_1.bias', 'module.encoder.layers.7.conv1x3_1.weight', 'module.encoder.layers.7.conv1x3_1.bias', 'module.encoder.layers.7.conv3x1_2.weight', 'module.encoder.layers.7.conv3x1_2.bias', 'module.encoder.layers.7.conv1x3_2.weight', 'module.encoder.layers.7.conv1x3_2.bias', 'module.encoder.layers.7.bn1.weight', 'module.encoder.layers.7.bn1.bias', 'module.encoder.layers.7.bn1.running_mean', 'module.encoder.layers.7.bn1.running_var', 'module.encoder.layers.7.bn2.weight', 'module.encoder.layers.7.bn2.bias', 'module.encoder.layers.7.bn2.running_mean', 'module.encoder.layers.7.bn2.running_var', 'module.encoder.layers.8.conv3x1_1.weight', 'module.encoder.layers.8.conv3x1_1.bias', 'module.encoder.layers.8.conv1x3_1.weight', 'module.encoder.layers.8.conv1x3_1.bias', 'module.encoder.layers.8.conv3x1_2.weight', 'module.encoder.layers.8.conv3x1_2.bias', 'module.encoder.layers.8.conv1x3_2.weight', 'module.encoder.layers.8.conv1x3_2.bias', 'module.encoder.layers.8.bn1.weight', 'module.encoder.layers.8.bn1.bias', 'module.encoder.layers.8.bn1.running_mean', 'module.encoder.layers.8.bn1.running_var', 'module.encoder.layers.8.bn2.weight', 'module.encoder.layers.8.bn2.bias', 'module.encoder.layers.8.bn2.running_mean', 'module.encoder.layers.8.bn2.running_var', 'module.encoder.layers.9.conv3x1_1.weight', 'module.encoder.layers.9.conv3x1_1.bias', 'module.encoder.layers.9.conv1x3_1.weight', 'module.encoder.layers.9.conv1x3_1.bias', 'module.encoder.layers.9.conv3x1_2.weight', 'module.encoder.layers.9.conv3x1_2.bias', 'module.encoder.layers.9.conv1x3_2.weight', 'module.encoder.layers.9.conv1x3_2.bias', 'module.encoder.layers.9.bn1.weight', 'module.encoder.layers.9.bn1.bias', 'module.encoder.layers.9.bn1.running_mean', 'module.encoder.layers.9.bn1.running_var', 'module.encoder.layers.9.bn2.weight', 'module.encoder.layers.9.bn2.bias', 'module.encoder.layers.9.bn2.running_mean', 'module.encoder.layers.9.bn2.running_var', 'module.encoder.layers.10.conv3x1_1.weight', 'module.encoder.layers.10.conv3x1_1.bias', 'module.encoder.layers.10.conv1x3_1.weight', 'module.encoder.layers.10.conv1x3_1.bias', 'module.encoder.layers.10.conv3x1_2.weight', 'module.encoder.layers.10.conv3x1_2.bias', 'module.encoder.layers.10.conv1x3_2.weight', 'module.encoder.layers.10.conv1x3_2.bias', 'module.encoder.layers.10.bn1.weight', 'module.encoder.layers.10.bn1.bias', 'module.encoder.layers.10.bn1.running_mean', 'module.encoder.layers.10.bn1.running_var', 'module.encoder.layers.10.bn2.weight', 'module.encoder.layers.10.bn2.bias', 'module.encoder.layers.10.bn2.running_mean', 'module.encoder.layers.10.bn2.running_var', 'module.encoder.layers.11.conv3x1_1.weight', 'module.encoder.layers.11.conv3x1_1.bias', 'module.encoder.layers.11.conv1x3_1.weight', 'module.encoder.layers.11.conv1x3_1.bias', 'module.encoder.layers.11.conv3x1_2.weight', 'module.encoder.layers.11.conv3x1_2.bias', 'module.encoder.layers.11.conv1x3_2.weight', 'module.encoder.layers.11.conv1x3_2.bias', 'module.encoder.layers.11.bn1.weight', 'module.encoder.layers.11.bn1.bias', 'module.encoder.layers.11.bn1.running_mean', 'module.encoder.layers.11.bn1.running_var', 'module.encoder.layers.11.bn2.weight', 'module.encoder.layers.11.bn2.bias', 'module.encoder.layers.11.bn2.running_mean', 'module.encoder.layers.11.bn2.running_var', 'module.encoder.layers.12.conv3x1_1.weight', 'module.encoder.layers.12.conv3x1_1.bias', 'module.encoder.layers.12.conv1x3_1.weight', 'module.encoder.layers.12.conv1x3_1.bias', 'module.encoder.layers.12.conv3x1_2.weight', 'module.encoder.layers.12.conv3x1_2.bias', 'module.encoder.layers.12.conv1x3_2.weight', 'module.encoder.layers.12.conv1x3_2.bias', 'module.encoder.layers.12.bn1.weight', 'module.encoder.layers.12.bn1.bias', 'module.encoder.layers.12.bn1.running_mean', 'module.encoder.layers.12.bn1.running_var', 'module.encoder.layers.12.bn2.weight', 'module.encoder.layers.12.bn2.bias', 'module.encoder.layers.12.bn2.running_mean', 'module.encoder.layers.12.bn2.running_var', 'module.encoder.layers.13.conv3x1_1.weight', 'module.encoder.layers.13.conv3x1_1.bias', 'module.encoder.layers.13.conv1x3_1.weight', 'module.encoder.layers.13.conv1x3_1.bias', 'module.encoder.layers.13.conv3x1_2.weight', 'module.encoder.layers.13.conv3x1_2.bias', 'module.encoder.layers.13.conv1x3_2.weight', 'module.encoder.layers.13.conv1x3_2.bias', 'module.encoder.layers.13.bn1.weight', 'module.encoder.layers.13.bn1.bias', 'module.encoder.layers.13.bn1.running_mean', 'module.encoder.layers.13.bn1.running_var', 'module.encoder.layers.13.bn2.weight', 'module.encoder.layers.13.bn2.bias', 'module.encoder.layers.13.bn2.running_mean', 'module.encoder.layers.13.bn2.running_var', 'module.encoder.layers.14.conv3x1_1.weight', 'module.encoder.layers.14.conv3x1_1.bias', 'module.encoder.layers.14.conv1x3_1.weight', 'module.encoder.layers.14.conv1x3_1.bias', 'module.encoder.layers.14.conv3x1_2.weight', 'module.encoder.layers.14.conv3x1_2.bias', 'module.encoder.layers.14.conv1x3_2.weight', 'module.encoder.layers.14.conv1x3_2.bias', 'module.encoder.layers.14.bn1.weight', 'module.encoder.layers.14.bn1.bias', 'module.encoder.layers.14.bn1.running_mean', 'module.encoder.layers.14.bn1.running_var', 'module.encoder.layers.14.bn2.weight', 'module.encoder.layers.14.bn2.bias', 'module.encoder.layers.14.bn2.running_mean', 'module.encoder.layers.14.bn2.running_var', 'module.decoder.layers.0.conv.weight', 'module.decoder.layers.0.conv.bias', 'module.decoder.layers.0.bn.weight', 'module.decoder.layers.0.bn.bias', 'module.decoder.layers.0.bn.running_mean', 'module.decoder.layers.0.bn.running_var', 'module.decoder.layers.1.conv3x1_1.weight', 'module.decoder.layers.1.conv3x1_1.bias', 'module.decoder.layers.1.conv1x3_1.weight', 'module.decoder.layers.1.conv1x3_1.bias', 'module.decoder.layers.1.bn1.weight', 'module.decoder.layers.1.bn1.bias', 'module.decoder.layers.1.bn1.running_mean', 'module.decoder.layers.1.bn1.running_var', 'module.decoder.layers.1.conv3x1_2.weight', 'module.decoder.layers.1.conv3x1_2.bias', 'module.decoder.layers.1.conv1x3_2.weight', 'module.decoder.layers.1.conv1x3_2.bias', 'module.decoder.layers.1.bn2.weight', 'module.decoder.layers.1.bn2.bias', 'module.decoder.layers.1.bn2.running_mean', 'module.decoder.layers.1.bn2.running_var', 'module.decoder.layers.2.conv3x1_1.weight', 'module.decoder.layers.2.conv3x1_1.bias', 'module.decoder.layers.2.conv1x3_1.weight', 'module.decoder.layers.2.conv1x3_1.bias', 'module.decoder.layers.2.bn1.weight', 'module.decoder.layers.2.bn1.bias', 'module.decoder.layers.2.bn1.running_mean', 'module.decoder.layers.2.bn1.running_var', 'module.decoder.layers.2.conv3x1_2.weight', 'module.decoder.layers.2.conv3x1_2.bias', 'module.decoder.layers.2.conv1x3_2.weight', 'module.decoder.layers.2.conv1x3_2.bias', 'module.decoder.layers.2.bn2.weight', 'module.decoder.layers.2.bn2.bias', 'module.decoder.layers.2.bn2.running_mean', 'module.decoder.layers.2.bn2.running_var', 'module.decoder.layers.3.conv.weight', 'module.decoder.layers.3.conv.bias', 'module.decoder.layers.3.bn.weight', 'module.decoder.layers.3.bn.bias', 'module.decoder.layers.3.bn.running_mean', 'module.decoder.layers.3.bn.running_var', 'module.decoder.layers.4.conv3x1_1.weight', 'module.decoder.layers.4.conv3x1_1.bias', 'module.decoder.layers.4.conv1x3_1.weight', 'module.decoder.layers.4.conv1x3_1.bias', 'module.decoder.layers.4.bn1.weight', 'module.decoder.layers.4.bn1.bias', 'module.decoder.layers.4.bn1.running_mean', 'module.decoder.layers.4.bn1.running_var', 'module.decoder.layers.4.conv3x1_2.weight', 'module.decoder.layers.4.conv3x1_2.bias', 'module.decoder.layers.4.conv1x3_2.weight', 'module.decoder.layers.4.conv1x3_2.bias', 'module.decoder.layers.4.bn2.weight', 'module.decoder.layers.4.bn2.bias', 'module.decoder.layers.4.bn2.running_mean', 'module.decoder.layers.4.bn2.running_var', 'module.decoder.layers.5.conv3x1_1.weight', 'module.decoder.layers.5.conv3x1_1.bias', 'module.decoder.layers.5.conv1x3_1.weight', 'module.decoder.layers.5.conv1x3_1.bias', 'module.decoder.layers.5.bn1.weight', 'module.decoder.layers.5.bn1.bias', 'module.decoder.layers.5.bn1.running_mean', 'module.decoder.layers.5.bn1.running_var', 'module.decoder.layers.5.conv3x1_2.weight', 'module.decoder.layers.5.conv3x1_2.bias', 'module.decoder.layers.5.conv1x3_2.weight', 'module.decoder.layers.5.conv1x3_2.bias', 'module.decoder.layers.5.bn2.weight', 'module.decoder.layers.5.bn2.bias', 'module.decoder.layers.5.bn2.running_mean', 'module.decoder.layers.5.bn2.running_var', 'module.decoder.output_conv.weight', 'module.decoder.output_conv.bias'])\n",
            "odict_keys(['module.encoder.initial_block.conv.weight', 'module.encoder.initial_block.conv.bias', 'module.encoder.initial_block.bn.weight', 'module.encoder.initial_block.bn.bias', 'module.encoder.initial_block.bn.running_mean', 'module.encoder.initial_block.bn.running_var', 'module.encoder.initial_block.bn.num_batches_tracked', 'module.encoder.layers.0.conv.weight', 'module.encoder.layers.0.conv.bias', 'module.encoder.layers.0.bn.weight', 'module.encoder.layers.0.bn.bias', 'module.encoder.layers.0.bn.running_mean', 'module.encoder.layers.0.bn.running_var', 'module.encoder.layers.0.bn.num_batches_tracked', 'module.encoder.layers.1.conv3x1_1.weight', 'module.encoder.layers.1.conv3x1_1.bias', 'module.encoder.layers.1.conv1x3_1.weight', 'module.encoder.layers.1.conv1x3_1.bias', 'module.encoder.layers.1.bn1.weight', 'module.encoder.layers.1.bn1.bias', 'module.encoder.layers.1.bn1.running_mean', 'module.encoder.layers.1.bn1.running_var', 'module.encoder.layers.1.bn1.num_batches_tracked', 'module.encoder.layers.1.conv3x1_2.weight', 'module.encoder.layers.1.conv3x1_2.bias', 'module.encoder.layers.1.conv1x3_2.weight', 'module.encoder.layers.1.conv1x3_2.bias', 'module.encoder.layers.1.bn2.weight', 'module.encoder.layers.1.bn2.bias', 'module.encoder.layers.1.bn2.running_mean', 'module.encoder.layers.1.bn2.running_var', 'module.encoder.layers.1.bn2.num_batches_tracked', 'module.encoder.layers.2.conv3x1_1.weight', 'module.encoder.layers.2.conv3x1_1.bias', 'module.encoder.layers.2.conv1x3_1.weight', 'module.encoder.layers.2.conv1x3_1.bias', 'module.encoder.layers.2.bn1.weight', 'module.encoder.layers.2.bn1.bias', 'module.encoder.layers.2.bn1.running_mean', 'module.encoder.layers.2.bn1.running_var', 'module.encoder.layers.2.bn1.num_batches_tracked', 'module.encoder.layers.2.conv3x1_2.weight', 'module.encoder.layers.2.conv3x1_2.bias', 'module.encoder.layers.2.conv1x3_2.weight', 'module.encoder.layers.2.conv1x3_2.bias', 'module.encoder.layers.2.bn2.weight', 'module.encoder.layers.2.bn2.bias', 'module.encoder.layers.2.bn2.running_mean', 'module.encoder.layers.2.bn2.running_var', 'module.encoder.layers.2.bn2.num_batches_tracked', 'module.encoder.layers.3.conv3x1_1.weight', 'module.encoder.layers.3.conv3x1_1.bias', 'module.encoder.layers.3.conv1x3_1.weight', 'module.encoder.layers.3.conv1x3_1.bias', 'module.encoder.layers.3.bn1.weight', 'module.encoder.layers.3.bn1.bias', 'module.encoder.layers.3.bn1.running_mean', 'module.encoder.layers.3.bn1.running_var', 'module.encoder.layers.3.bn1.num_batches_tracked', 'module.encoder.layers.3.conv3x1_2.weight', 'module.encoder.layers.3.conv3x1_2.bias', 'module.encoder.layers.3.conv1x3_2.weight', 'module.encoder.layers.3.conv1x3_2.bias', 'module.encoder.layers.3.bn2.weight', 'module.encoder.layers.3.bn2.bias', 'module.encoder.layers.3.bn2.running_mean', 'module.encoder.layers.3.bn2.running_var', 'module.encoder.layers.3.bn2.num_batches_tracked', 'module.encoder.layers.4.conv3x1_1.weight', 'module.encoder.layers.4.conv3x1_1.bias', 'module.encoder.layers.4.conv1x3_1.weight', 'module.encoder.layers.4.conv1x3_1.bias', 'module.encoder.layers.4.bn1.weight', 'module.encoder.layers.4.bn1.bias', 'module.encoder.layers.4.bn1.running_mean', 'module.encoder.layers.4.bn1.running_var', 'module.encoder.layers.4.bn1.num_batches_tracked', 'module.encoder.layers.4.conv3x1_2.weight', 'module.encoder.layers.4.conv3x1_2.bias', 'module.encoder.layers.4.conv1x3_2.weight', 'module.encoder.layers.4.conv1x3_2.bias', 'module.encoder.layers.4.bn2.weight', 'module.encoder.layers.4.bn2.bias', 'module.encoder.layers.4.bn2.running_mean', 'module.encoder.layers.4.bn2.running_var', 'module.encoder.layers.4.bn2.num_batches_tracked', 'module.encoder.layers.5.conv3x1_1.weight', 'module.encoder.layers.5.conv3x1_1.bias', 'module.encoder.layers.5.conv1x3_1.weight', 'module.encoder.layers.5.conv1x3_1.bias', 'module.encoder.layers.5.bn1.weight', 'module.encoder.layers.5.bn1.bias', 'module.encoder.layers.5.bn1.running_mean', 'module.encoder.layers.5.bn1.running_var', 'module.encoder.layers.5.bn1.num_batches_tracked', 'module.encoder.layers.5.conv3x1_2.weight', 'module.encoder.layers.5.conv3x1_2.bias', 'module.encoder.layers.5.conv1x3_2.weight', 'module.encoder.layers.5.conv1x3_2.bias', 'module.encoder.layers.5.bn2.weight', 'module.encoder.layers.5.bn2.bias', 'module.encoder.layers.5.bn2.running_mean', 'module.encoder.layers.5.bn2.running_var', 'module.encoder.layers.5.bn2.num_batches_tracked', 'module.encoder.layers.6.conv.weight', 'module.encoder.layers.6.conv.bias', 'module.encoder.layers.6.bn.weight', 'module.encoder.layers.6.bn.bias', 'module.encoder.layers.6.bn.running_mean', 'module.encoder.layers.6.bn.running_var', 'module.encoder.layers.6.bn.num_batches_tracked', 'module.encoder.layers.7.conv3x1_1.weight', 'module.encoder.layers.7.conv3x1_1.bias', 'module.encoder.layers.7.conv1x3_1.weight', 'module.encoder.layers.7.conv1x3_1.bias', 'module.encoder.layers.7.bn1.weight', 'module.encoder.layers.7.bn1.bias', 'module.encoder.layers.7.bn1.running_mean', 'module.encoder.layers.7.bn1.running_var', 'module.encoder.layers.7.bn1.num_batches_tracked', 'module.encoder.layers.7.conv3x1_2.weight', 'module.encoder.layers.7.conv3x1_2.bias', 'module.encoder.layers.7.conv1x3_2.weight', 'module.encoder.layers.7.conv1x3_2.bias', 'module.encoder.layers.7.bn2.weight', 'module.encoder.layers.7.bn2.bias', 'module.encoder.layers.7.bn2.running_mean', 'module.encoder.layers.7.bn2.running_var', 'module.encoder.layers.7.bn2.num_batches_tracked', 'module.encoder.layers.8.conv3x1_1.weight', 'module.encoder.layers.8.conv3x1_1.bias', 'module.encoder.layers.8.conv1x3_1.weight', 'module.encoder.layers.8.conv1x3_1.bias', 'module.encoder.layers.8.bn1.weight', 'module.encoder.layers.8.bn1.bias', 'module.encoder.layers.8.bn1.running_mean', 'module.encoder.layers.8.bn1.running_var', 'module.encoder.layers.8.bn1.num_batches_tracked', 'module.encoder.layers.8.conv3x1_2.weight', 'module.encoder.layers.8.conv3x1_2.bias', 'module.encoder.layers.8.conv1x3_2.weight', 'module.encoder.layers.8.conv1x3_2.bias', 'module.encoder.layers.8.bn2.weight', 'module.encoder.layers.8.bn2.bias', 'module.encoder.layers.8.bn2.running_mean', 'module.encoder.layers.8.bn2.running_var', 'module.encoder.layers.8.bn2.num_batches_tracked', 'module.encoder.layers.9.conv3x1_1.weight', 'module.encoder.layers.9.conv3x1_1.bias', 'module.encoder.layers.9.conv1x3_1.weight', 'module.encoder.layers.9.conv1x3_1.bias', 'module.encoder.layers.9.bn1.weight', 'module.encoder.layers.9.bn1.bias', 'module.encoder.layers.9.bn1.running_mean', 'module.encoder.layers.9.bn1.running_var', 'module.encoder.layers.9.bn1.num_batches_tracked', 'module.encoder.layers.9.conv3x1_2.weight', 'module.encoder.layers.9.conv3x1_2.bias', 'module.encoder.layers.9.conv1x3_2.weight', 'module.encoder.layers.9.conv1x3_2.bias', 'module.encoder.layers.9.bn2.weight', 'module.encoder.layers.9.bn2.bias', 'module.encoder.layers.9.bn2.running_mean', 'module.encoder.layers.9.bn2.running_var', 'module.encoder.layers.9.bn2.num_batches_tracked', 'module.encoder.layers.10.conv3x1_1.weight', 'module.encoder.layers.10.conv3x1_1.bias', 'module.encoder.layers.10.conv1x3_1.weight', 'module.encoder.layers.10.conv1x3_1.bias', 'module.encoder.layers.10.bn1.weight', 'module.encoder.layers.10.bn1.bias', 'module.encoder.layers.10.bn1.running_mean', 'module.encoder.layers.10.bn1.running_var', 'module.encoder.layers.10.bn1.num_batches_tracked', 'module.encoder.layers.10.conv3x1_2.weight', 'module.encoder.layers.10.conv3x1_2.bias', 'module.encoder.layers.10.conv1x3_2.weight', 'module.encoder.layers.10.conv1x3_2.bias', 'module.encoder.layers.10.bn2.weight', 'module.encoder.layers.10.bn2.bias', 'module.encoder.layers.10.bn2.running_mean', 'module.encoder.layers.10.bn2.running_var', 'module.encoder.layers.10.bn2.num_batches_tracked', 'module.encoder.layers.11.conv3x1_1.weight', 'module.encoder.layers.11.conv3x1_1.bias', 'module.encoder.layers.11.conv1x3_1.weight', 'module.encoder.layers.11.conv1x3_1.bias', 'module.encoder.layers.11.bn1.weight', 'module.encoder.layers.11.bn1.bias', 'module.encoder.layers.11.bn1.running_mean', 'module.encoder.layers.11.bn1.running_var', 'module.encoder.layers.11.bn1.num_batches_tracked', 'module.encoder.layers.11.conv3x1_2.weight', 'module.encoder.layers.11.conv3x1_2.bias', 'module.encoder.layers.11.conv1x3_2.weight', 'module.encoder.layers.11.conv1x3_2.bias', 'module.encoder.layers.11.bn2.weight', 'module.encoder.layers.11.bn2.bias', 'module.encoder.layers.11.bn2.running_mean', 'module.encoder.layers.11.bn2.running_var', 'module.encoder.layers.11.bn2.num_batches_tracked', 'module.encoder.layers.12.conv3x1_1.weight', 'module.encoder.layers.12.conv3x1_1.bias', 'module.encoder.layers.12.conv1x3_1.weight', 'module.encoder.layers.12.conv1x3_1.bias', 'module.encoder.layers.12.bn1.weight', 'module.encoder.layers.12.bn1.bias', 'module.encoder.layers.12.bn1.running_mean', 'module.encoder.layers.12.bn1.running_var', 'module.encoder.layers.12.bn1.num_batches_tracked', 'module.encoder.layers.12.conv3x1_2.weight', 'module.encoder.layers.12.conv3x1_2.bias', 'module.encoder.layers.12.conv1x3_2.weight', 'module.encoder.layers.12.conv1x3_2.bias', 'module.encoder.layers.12.bn2.weight', 'module.encoder.layers.12.bn2.bias', 'module.encoder.layers.12.bn2.running_mean', 'module.encoder.layers.12.bn2.running_var', 'module.encoder.layers.12.bn2.num_batches_tracked', 'module.encoder.layers.13.conv3x1_1.weight', 'module.encoder.layers.13.conv3x1_1.bias', 'module.encoder.layers.13.conv1x3_1.weight', 'module.encoder.layers.13.conv1x3_1.bias', 'module.encoder.layers.13.bn1.weight', 'module.encoder.layers.13.bn1.bias', 'module.encoder.layers.13.bn1.running_mean', 'module.encoder.layers.13.bn1.running_var', 'module.encoder.layers.13.bn1.num_batches_tracked', 'module.encoder.layers.13.conv3x1_2.weight', 'module.encoder.layers.13.conv3x1_2.bias', 'module.encoder.layers.13.conv1x3_2.weight', 'module.encoder.layers.13.conv1x3_2.bias', 'module.encoder.layers.13.bn2.weight', 'module.encoder.layers.13.bn2.bias', 'module.encoder.layers.13.bn2.running_mean', 'module.encoder.layers.13.bn2.running_var', 'module.encoder.layers.13.bn2.num_batches_tracked', 'module.encoder.layers.14.conv3x1_1.weight', 'module.encoder.layers.14.conv3x1_1.bias', 'module.encoder.layers.14.conv1x3_1.weight', 'module.encoder.layers.14.conv1x3_1.bias', 'module.encoder.layers.14.bn1.weight', 'module.encoder.layers.14.bn1.bias', 'module.encoder.layers.14.bn1.running_mean', 'module.encoder.layers.14.bn1.running_var', 'module.encoder.layers.14.bn1.num_batches_tracked', 'module.encoder.layers.14.conv3x1_2.weight', 'module.encoder.layers.14.conv3x1_2.bias', 'module.encoder.layers.14.conv1x3_2.weight', 'module.encoder.layers.14.conv1x3_2.bias', 'module.encoder.layers.14.bn2.weight', 'module.encoder.layers.14.bn2.bias', 'module.encoder.layers.14.bn2.running_mean', 'module.encoder.layers.14.bn2.running_var', 'module.encoder.layers.14.bn2.num_batches_tracked', 'module.encoder.output_conv.weight', 'module.encoder.output_conv.bias', 'module.decoder.layers.0.conv.weight', 'module.decoder.layers.0.conv.bias', 'module.decoder.layers.0.bn.weight', 'module.decoder.layers.0.bn.bias', 'module.decoder.layers.0.bn.running_mean', 'module.decoder.layers.0.bn.running_var', 'module.decoder.layers.0.bn.num_batches_tracked', 'module.decoder.layers.1.conv3x1_1.weight', 'module.decoder.layers.1.conv3x1_1.bias', 'module.decoder.layers.1.conv1x3_1.weight', 'module.decoder.layers.1.conv1x3_1.bias', 'module.decoder.layers.1.bn1.weight', 'module.decoder.layers.1.bn1.bias', 'module.decoder.layers.1.bn1.running_mean', 'module.decoder.layers.1.bn1.running_var', 'module.decoder.layers.1.bn1.num_batches_tracked', 'module.decoder.layers.1.conv3x1_2.weight', 'module.decoder.layers.1.conv3x1_2.bias', 'module.decoder.layers.1.conv1x3_2.weight', 'module.decoder.layers.1.conv1x3_2.bias', 'module.decoder.layers.1.bn2.weight', 'module.decoder.layers.1.bn2.bias', 'module.decoder.layers.1.bn2.running_mean', 'module.decoder.layers.1.bn2.running_var', 'module.decoder.layers.1.bn2.num_batches_tracked', 'module.decoder.layers.2.conv3x1_1.weight', 'module.decoder.layers.2.conv3x1_1.bias', 'module.decoder.layers.2.conv1x3_1.weight', 'module.decoder.layers.2.conv1x3_1.bias', 'module.decoder.layers.2.bn1.weight', 'module.decoder.layers.2.bn1.bias', 'module.decoder.layers.2.bn1.running_mean', 'module.decoder.layers.2.bn1.running_var', 'module.decoder.layers.2.bn1.num_batches_tracked', 'module.decoder.layers.2.conv3x1_2.weight', 'module.decoder.layers.2.conv3x1_2.bias', 'module.decoder.layers.2.conv1x3_2.weight', 'module.decoder.layers.2.conv1x3_2.bias', 'module.decoder.layers.2.bn2.weight', 'module.decoder.layers.2.bn2.bias', 'module.decoder.layers.2.bn2.running_mean', 'module.decoder.layers.2.bn2.running_var', 'module.decoder.layers.2.bn2.num_batches_tracked', 'module.decoder.layers.3.conv.weight', 'module.decoder.layers.3.conv.bias', 'module.decoder.layers.3.bn.weight', 'module.decoder.layers.3.bn.bias', 'module.decoder.layers.3.bn.running_mean', 'module.decoder.layers.3.bn.running_var', 'module.decoder.layers.3.bn.num_batches_tracked', 'module.decoder.layers.4.conv3x1_1.weight', 'module.decoder.layers.4.conv3x1_1.bias', 'module.decoder.layers.4.conv1x3_1.weight', 'module.decoder.layers.4.conv1x3_1.bias', 'module.decoder.layers.4.bn1.weight', 'module.decoder.layers.4.bn1.bias', 'module.decoder.layers.4.bn1.running_mean', 'module.decoder.layers.4.bn1.running_var', 'module.decoder.layers.4.bn1.num_batches_tracked', 'module.decoder.layers.4.conv3x1_2.weight', 'module.decoder.layers.4.conv3x1_2.bias', 'module.decoder.layers.4.conv1x3_2.weight', 'module.decoder.layers.4.conv1x3_2.bias', 'module.decoder.layers.4.bn2.weight', 'module.decoder.layers.4.bn2.bias', 'module.decoder.layers.4.bn2.running_mean', 'module.decoder.layers.4.bn2.running_var', 'module.decoder.layers.4.bn2.num_batches_tracked', 'module.decoder.layers.5.conv3x1_1.weight', 'module.decoder.layers.5.conv3x1_1.bias', 'module.decoder.layers.5.conv1x3_1.weight', 'module.decoder.layers.5.conv1x3_1.bias', 'module.decoder.layers.5.bn1.weight', 'module.decoder.layers.5.bn1.bias', 'module.decoder.layers.5.bn1.running_mean', 'module.decoder.layers.5.bn1.running_var', 'module.decoder.layers.5.bn1.num_batches_tracked', 'module.decoder.layers.5.conv3x1_2.weight', 'module.decoder.layers.5.conv3x1_2.bias', 'module.decoder.layers.5.conv1x3_2.weight', 'module.decoder.layers.5.conv1x3_2.bias', 'module.decoder.layers.5.bn2.weight', 'module.decoder.layers.5.bn2.bias', 'module.decoder.layers.5.bn2.running_mean', 'module.decoder.layers.5.bn2.running_var', 'module.decoder.layers.5.bn2.num_batches_tracked', 'module.decoder.output_conv.weight', 'module.decoder.output_conv.bias'])\n",
            "Model and weights LOADED successfully\n",
            "100% 2975/2975 [07:41<00:00,  6.45it/s]\n",
            "cov_matrix tensor([[ 2.3956e+09,  5.3233e+08, -1.1117e+09,  7.9754e+07, -3.0860e+08,\n",
            "         -4.5878e+08, -9.7728e+07,  9.4537e+07,  1.2570e+08,  7.6442e+08,\n",
            "          6.7353e+08,  8.9282e+07,  2.8561e+08,  2.4825e+08,  3.8140e+08,\n",
            "          3.5417e+08,  3.4480e+08,  4.1080e+08, -5.2754e+07],\n",
            "        [ 5.3233e+08,  2.4650e+09, -9.4928e+07,  3.2850e+08, -3.8250e+08,\n",
            "          2.2306e+08, -5.7414e+08, -5.6602e+08, -5.7101e+08,  6.6016e+08,\n",
            "          4.4618e+08, -1.1564e+08, -5.4575e+08,  1.9169e+08, -3.1271e+08,\n",
            "         -1.0353e+09,  8.6958e+07, -9.8419e+07,  4.3876e+08],\n",
            "        [-1.1117e+09, -9.4928e+07,  2.9623e+09,  6.3566e+08,  3.0863e+08,\n",
            "          2.1515e+08,  5.4991e+08,  1.7934e+08, -1.1649e+08, -1.1383e+09,\n",
            "          4.6287e+08,  4.6533e+05, -2.5552e+08, -5.2459e+08,  5.5244e+08,\n",
            "         -2.8486e+08,  6.8704e+08, -9.7038e+07, -1.5765e+08],\n",
            "        [ 7.9754e+07,  3.2850e+08,  6.3566e+08,  1.7032e+09,  6.6750e+08,\n",
            "         -3.3863e+08, -3.2469e+08, -9.6637e+07,  3.9011e+08,  2.8685e+08,\n",
            "         -3.3193e+08, -2.0280e+08, -1.9761e+08,  1.3337e+08,  5.1907e+08,\n",
            "         -1.7092e+08, -5.0282e+08,  6.0503e+08, -1.8244e+08],\n",
            "        [-3.0860e+08, -3.8250e+08,  3.0863e+08,  6.6750e+08,  1.2267e+09,\n",
            "          3.1085e+07,  2.1584e+08,  2.6093e+08, -1.2286e+07,  2.6611e+07,\n",
            "         -7.7656e+08,  5.1364e+07, -6.3603e+07, -4.3606e+08, -1.9027e+08,\n",
            "          6.3518e+07, -3.7639e+08,  1.6301e+07, -1.2184e+07],\n",
            "        [-4.5878e+08,  2.2306e+08,  2.1515e+08, -3.3863e+08,  3.1085e+07,\n",
            "          1.5329e+09,  6.2660e+08,  4.7480e+08,  5.8965e+07, -2.8814e+08,\n",
            "          3.7905e+08, -5.6487e+07, -4.1709e+08, -1.3862e+08, -2.0653e+08,\n",
            "         -4.2598e+08,  1.1674e+08, -6.9226e+08,  1.2850e+08],\n",
            "        [-9.7728e+07, -5.7414e+08,  5.4991e+08, -3.2469e+08,  2.1584e+08,\n",
            "          6.2660e+08,  1.5053e+09,  8.3542e+08,  6.0996e+08, -1.2172e+08,\n",
            "          7.8723e+08,  2.7645e+08,  1.7060e+08, -4.9118e+08,  1.6640e+08,\n",
            "          5.2793e+08,  4.9058e+08, -5.4750e+08, -4.0819e+08],\n",
            "        [ 9.4537e+07, -5.6602e+08,  1.7934e+08, -9.6637e+07,  2.6093e+08,\n",
            "          4.7480e+08,  8.3542e+08,  1.4146e+09,  1.0751e+08, -3.0878e+08,\n",
            "          6.9653e+08,  8.0042e+07,  2.6429e+08,  5.1791e+07,  4.5839e+08,\n",
            "          2.0180e+08, -1.4713e+08, -6.4726e+08, -4.1251e+08],\n",
            "        [ 1.2570e+08, -5.7101e+08, -1.1649e+08,  3.9011e+08, -1.2286e+07,\n",
            "          5.8965e+07,  6.0996e+08,  1.0751e+08,  2.8543e+09,  1.0083e+09,\n",
            "          6.4216e+08, -3.7732e+08, -1.5921e+07,  2.9349e+08, -1.1691e+08,\n",
            "          4.0528e+08,  2.1552e+07, -9.7056e+07, -3.8597e+08],\n",
            "        [ 7.6442e+08,  6.6016e+08, -1.1383e+09,  2.8685e+08,  2.6611e+07,\n",
            "         -2.8814e+08, -1.2172e+08, -3.0878e+08,  1.0083e+09,  1.8508e+09,\n",
            "          4.2747e+08, -1.8856e+08, -8.3740e+07,  5.2486e+07, -6.4068e+08,\n",
            "          6.4876e+07, -4.1535e+08,  5.6166e+07,  1.3810e+08],\n",
            "        [ 6.7353e+08,  4.4618e+08,  4.6287e+08, -3.3193e+08, -7.7656e+08,\n",
            "          3.7905e+08,  7.8723e+08,  6.9653e+08,  6.4216e+08,  4.2747e+08,\n",
            "          3.0382e+09, -6.4473e+08,  3.7103e+08, -5.6801e+08,  6.2797e+08,\n",
            "          2.1460e+08,  9.0749e+08, -4.5075e+08, -2.7436e+07],\n",
            "        [ 8.9282e+07, -1.1564e+08,  4.6533e+05, -2.0280e+08,  5.1364e+07,\n",
            "         -5.6487e+07,  2.7645e+08,  8.0042e+07, -3.7732e+08, -1.8856e+08,\n",
            "         -6.4473e+08,  1.0631e+09,  2.5722e+08,  6.0621e+07, -2.6910e+08,\n",
            "         -2.4720e+07, -9.3999e+07,  1.3856e+08, -1.1033e+08],\n",
            "        [ 2.8561e+08, -5.4575e+08, -2.5552e+08, -1.9761e+08, -6.3603e+07,\n",
            "         -4.1709e+08,  1.7060e+08,  2.6429e+08, -1.5921e+07, -8.3740e+07,\n",
            "          3.7103e+08,  2.5722e+08,  8.1854e+08, -2.0374e+08,  3.7366e+08,\n",
            "          5.2344e+08,  1.9202e+08,  3.0640e+08,  1.1162e+07],\n",
            "        [ 2.4825e+08,  1.9169e+08, -5.2459e+08,  1.3337e+08, -4.3606e+08,\n",
            "         -1.3862e+08, -4.9118e+08,  5.1791e+07,  2.9349e+08,  5.2486e+07,\n",
            "         -5.6801e+08,  6.0621e+07, -2.0374e+08,  1.8755e+09,  4.1776e+08,\n",
            "          1.3729e+08, -1.5414e+08,  3.2404e+08, -9.3867e+07],\n",
            "        [ 3.8140e+08, -3.1271e+08,  5.5244e+08,  5.1907e+08, -1.9027e+08,\n",
            "         -2.0653e+08,  1.6640e+08,  4.5839e+08, -1.1691e+08, -6.4068e+08,\n",
            "          6.2797e+08, -2.6910e+08,  3.7366e+08,  4.1776e+08,  1.4679e+09,\n",
            "          6.1755e+08,  5.1360e+08,  5.0407e+08, -2.7239e+08],\n",
            "        [ 3.5417e+08, -1.0353e+09, -2.8486e+08, -1.7092e+08,  6.3518e+07,\n",
            "         -4.2598e+08,  5.2793e+08,  2.0180e+08,  4.0528e+08,  6.4876e+07,\n",
            "          2.1460e+08, -2.4720e+07,  5.2344e+08,  1.3729e+08,  6.1755e+08,\n",
            "          1.2261e+09,  5.2249e+08,  4.5047e+08, -2.0018e+08],\n",
            "        [ 3.4480e+08,  8.6958e+07,  6.8704e+08, -5.0282e+08, -3.7639e+08,\n",
            "          1.1674e+08,  4.9058e+08, -1.4713e+08,  2.1552e+07, -4.1535e+08,\n",
            "          9.0749e+08, -9.3999e+07,  1.9202e+08, -1.5414e+08,  5.1360e+08,\n",
            "          5.2249e+08,  1.4009e+09,  2.5537e+08,  2.0861e+08],\n",
            "        [ 4.1080e+08, -9.8419e+07, -9.7038e+07,  6.0503e+08,  1.6301e+07,\n",
            "         -6.9226e+08, -5.4750e+08, -6.4726e+08, -9.7056e+07,  5.6166e+07,\n",
            "         -4.5075e+08,  1.3856e+08,  3.0640e+08,  3.2404e+08,  5.0407e+08,\n",
            "          4.5047e+08,  2.5537e+08,  1.1670e+09,  1.9000e+08],\n",
            "        [-5.2754e+07,  4.3876e+08, -1.5765e+08, -1.8244e+08, -1.2184e+07,\n",
            "          1.2850e+08, -4.0819e+08, -4.1251e+08, -3.8597e+08,  1.3810e+08,\n",
            "         -2.7436e+07, -1.1033e+08,  1.1162e+07, -9.3867e+07, -2.7239e+08,\n",
            "         -2.0018e+08,  2.0861e+08,  1.9000e+08,  6.0700e+08]], device='cuda:0')\n",
            "Covariance matrix: torch.Size([19, 19])\n",
            "cov_matrix tensor([[ 1.5359e+00,  3.4129e-01, -7.1275e-01,  5.1132e-02, -1.9785e-01,\n",
            "         -2.9414e-01, -6.2656e-02,  6.0610e-02,  8.0590e-02,  4.9009e-01,\n",
            "          4.3182e-01,  5.7241e-02,  1.8311e-01,  1.5916e-01,  2.4452e-01,\n",
            "          2.2707e-01,  2.2106e-01,  2.6337e-01, -3.3822e-02],\n",
            "        [ 3.4129e-01,  1.5804e+00, -6.0861e-02,  2.1061e-01, -2.4523e-01,\n",
            "          1.4301e-01, -3.6810e-01, -3.6289e-01, -3.6609e-01,  4.2324e-01,\n",
            "          2.8606e-01, -7.4141e-02, -3.4990e-01,  1.2290e-01, -2.0049e-01,\n",
            "         -6.6376e-01,  5.5751e-02, -6.3099e-02,  2.8130e-01],\n",
            "        [-7.1275e-01, -6.0861e-02,  1.8992e+00,  4.0754e-01,  1.9787e-01,\n",
            "          1.3794e-01,  3.5256e-01,  1.1498e-01, -7.4682e-02, -7.2982e-01,\n",
            "          2.9676e-01,  2.9834e-04, -1.6382e-01, -3.3633e-01,  3.5418e-01,\n",
            "         -1.8263e-01,  4.4048e-01, -6.2213e-02, -1.0107e-01],\n",
            "        [ 5.1132e-02,  2.1061e-01,  4.0754e-01,  1.0920e+00,  4.2795e-01,\n",
            "         -2.1711e-01, -2.0817e-01, -6.1957e-02,  2.5011e-01,  1.8390e-01,\n",
            "         -2.1281e-01, -1.3002e-01, -1.2669e-01,  8.5507e-02,  3.3279e-01,\n",
            "         -1.0958e-01, -3.2237e-01,  3.8790e-01, -1.1697e-01],\n",
            "        [-1.9785e-01, -2.4523e-01,  1.9787e-01,  4.2795e-01,  7.8647e-01,\n",
            "          1.9929e-02,  1.3838e-01,  1.6729e-01, -7.8769e-03,  1.7061e-02,\n",
            "         -4.9787e-01,  3.2931e-02, -4.0777e-02, -2.7957e-01, -1.2199e-01,\n",
            "          4.0723e-02, -2.4132e-01,  1.0451e-02, -7.8113e-03],\n",
            "        [-2.9414e-01,  1.4301e-01,  1.3794e-01, -2.1711e-01,  1.9929e-02,\n",
            "          9.8279e-01,  4.0173e-01,  3.0441e-01,  3.7804e-02, -1.8473e-01,\n",
            "          2.4302e-01, -3.6215e-02, -2.6740e-01, -8.8874e-02, -1.3241e-01,\n",
            "         -2.7311e-01,  7.4848e-02, -4.4383e-01,  8.2387e-02],\n",
            "        [-6.2656e-02, -3.6810e-01,  3.5256e-01, -2.0817e-01,  1.3838e-01,\n",
            "          4.0173e-01,  9.6510e-01,  5.3561e-01,  3.9106e-01, -7.8035e-02,\n",
            "          5.0471e-01,  1.7724e-01,  1.0938e-01, -3.1491e-01,  1.0668e-01,\n",
            "          3.3847e-01,  3.1453e-01, -3.5102e-01, -2.6170e-01],\n",
            "        [ 6.0610e-02, -3.6289e-01,  1.1498e-01, -6.1957e-02,  1.6729e-01,\n",
            "          3.0441e-01,  5.3561e-01,  9.0694e-01,  6.8927e-02, -1.9797e-01,\n",
            "          4.4657e-01,  5.1317e-02,  1.6944e-01,  3.3205e-02,  2.9389e-01,\n",
            "          1.2938e-01, -9.4329e-02, -4.1498e-01, -2.6447e-01],\n",
            "        [ 8.0590e-02, -3.6609e-01, -7.4682e-02,  2.5011e-01, -7.8769e-03,\n",
            "          3.7804e-02,  3.9106e-01,  6.8927e-02,  1.8300e+00,  6.4644e-01,\n",
            "          4.1171e-01, -2.4191e-01, -1.0207e-02,  1.8816e-01, -7.4957e-02,\n",
            "          2.5984e-01,  1.3817e-02, -6.2225e-02, -2.4746e-01],\n",
            "        [ 4.9009e-01,  4.2324e-01, -7.2982e-01,  1.8390e-01,  1.7061e-02,\n",
            "         -1.8473e-01, -7.8035e-02, -1.9797e-01,  6.4644e-01,  1.1866e+00,\n",
            "          2.7407e-01, -1.2089e-01, -5.3688e-02,  3.3650e-02, -4.1076e-01,\n",
            "          4.1593e-02, -2.6629e-01,  3.6010e-02,  8.8542e-02],\n",
            "        [ 4.3182e-01,  2.8606e-01,  2.9676e-01, -2.1281e-01, -4.9787e-01,\n",
            "          2.4302e-01,  5.0471e-01,  4.4657e-01,  4.1171e-01,  2.7407e-01,\n",
            "          1.9479e+00, -4.1336e-01,  2.3788e-01, -3.6417e-01,  4.0261e-01,\n",
            "          1.3759e-01,  5.8182e-01, -2.8899e-01, -1.7590e-02],\n",
            "        [ 5.7241e-02, -7.4141e-02,  2.9834e-04, -1.3002e-01,  3.2931e-02,\n",
            "         -3.6215e-02,  1.7724e-01,  5.1317e-02, -2.4191e-01, -1.2089e-01,\n",
            "         -4.1336e-01,  6.8156e-01,  1.6491e-01,  3.8866e-02, -1.7253e-01,\n",
            "         -1.5849e-02, -6.0265e-02,  8.8833e-02, -7.0733e-02],\n",
            "        [ 1.8311e-01, -3.4990e-01, -1.6382e-01, -1.2669e-01, -4.0777e-02,\n",
            "         -2.6740e-01,  1.0938e-01,  1.6944e-01, -1.0207e-02, -5.3688e-02,\n",
            "          2.3788e-01,  1.6491e-01,  5.2479e-01, -1.3063e-01,  2.3957e-01,\n",
            "          3.3559e-01,  1.2311e-01,  1.9644e-01,  7.1560e-03],\n",
            "        [ 1.5916e-01,  1.2290e-01, -3.3633e-01,  8.5507e-02, -2.7957e-01,\n",
            "         -8.8874e-02, -3.1491e-01,  3.3205e-02,  1.8816e-01,  3.3650e-02,\n",
            "         -3.6417e-01,  3.8866e-02, -1.3063e-01,  1.2024e+00,  2.6784e-01,\n",
            "          8.8022e-02, -9.8823e-02,  2.0775e-01, -6.0181e-02],\n",
            "        [ 2.4452e-01, -2.0049e-01,  3.5418e-01,  3.3279e-01, -1.2199e-01,\n",
            "         -1.3241e-01,  1.0668e-01,  2.9389e-01, -7.4957e-02, -4.1076e-01,\n",
            "          4.0261e-01, -1.7253e-01,  2.3957e-01,  2.6784e-01,  9.4109e-01,\n",
            "          3.9593e-01,  3.2929e-01,  3.2317e-01, -1.7463e-01],\n",
            "        [ 2.2707e-01, -6.6376e-01, -1.8263e-01, -1.0958e-01,  4.0723e-02,\n",
            "         -2.7311e-01,  3.3847e-01,  1.2938e-01,  2.5984e-01,  4.1593e-02,\n",
            "          1.3759e-01, -1.5849e-02,  3.3559e-01,  8.8022e-02,  3.9593e-01,\n",
            "          7.8606e-01,  3.3498e-01,  2.8881e-01, -1.2834e-01],\n",
            "        [ 2.2106e-01,  5.5751e-02,  4.4048e-01, -3.2237e-01, -2.4132e-01,\n",
            "          7.4848e-02,  3.1453e-01, -9.4329e-02,  1.3817e-02, -2.6629e-01,\n",
            "          5.8182e-01, -6.0265e-02,  1.2311e-01, -9.8823e-02,  3.2929e-01,\n",
            "          3.3498e-01,  8.9816e-01,  1.6373e-01,  1.3374e-01],\n",
            "        [ 2.6337e-01, -6.3099e-02, -6.2213e-02,  3.8790e-01,  1.0451e-02,\n",
            "         -4.4383e-01, -3.5102e-01, -4.1498e-01, -6.2225e-02,  3.6010e-02,\n",
            "         -2.8899e-01,  8.8833e-02,  1.9644e-01,  2.0775e-01,  3.2317e-01,\n",
            "          2.8881e-01,  1.6373e-01,  7.4819e-01,  1.2181e-01],\n",
            "        [-3.3822e-02,  2.8130e-01, -1.0107e-01, -1.1697e-01, -7.8113e-03,\n",
            "          8.2387e-02, -2.6170e-01, -2.6447e-01, -2.4746e-01,  8.8542e-02,\n",
            "         -1.7590e-02, -7.0733e-02,  7.1560e-03, -6.0181e-02, -1.7463e-01,\n",
            "         -1.2834e-01,  1.3374e-01,  1.2181e-01,  3.8917e-01]], device='cuda:0')\n",
            "Covariance matrice saved as '/content/AnomalySegmentation/save/cov_matrix_erfnet.npy'\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "datadir = '/content/cityscapes'\n",
        "loadWeights = '/trained_models/erfnet_pretrained.pth'\n",
        "loadDir = '/content/AnomalySegmentation'\n",
        "\n",
        "# Compute Dataset Mean\n",
        "!python /content/AnomalySegmentation/eval/mahalanobis.py --datadir {datadir} --loadDir {loadDir} --loadWeights {loadWeights}\n",
        "\n",
        "# Compute Dataset Covariance\n",
        "mean = \"/save/mean_cityscapes_erfnet.npy\"\n",
        "!python /content/AnomalySegmentation/eval/mahalanobis.py --datadir {datadir} --loadDir {loadDir} --loadWeights {loadWeights} --mean {mean} --num-workers 2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "no_execute = False\n",
        "just_once = False\n",
        "\n",
        "for dataset_dir in ['RoadAnomaly21', 'RoadObsticle21', 'FS_LostFound_full', 'fs_static', 'RoadAnomaly']:\n",
        "  print(\"----------------------------\")\n",
        "  for method in [\"Mahalanobis\"]: # [\"Mahalanobis\", \"MSP\", \"MaxLogit\", \"MaxEntropy\"]:\n",
        "\n",
        "    if no_execute:\n",
        "      break\n",
        "\n",
        "    format_file = os.listdir(f'/content/Validation_Dataset/{dataset_dir}/images')[0].split(\".\")[1]\n",
        "    input =f'/content/Validation_Dataset/{dataset_dir}/images/\\*.{format_file}'\n",
        "    print(f\"\\nDataset: {dataset_dir} method: {method}\")\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "      !python -W ignore /content/AnomalySegmentation/eval/evalAnomaly.py --input {input} --method  {method} | tail -n 2\n",
        "    else:\n",
        "      !python -W ignore /content/AnomalySegmentation/eval/evalAnomaly.py --input {input} --method {method}  --cpu | tail -n 2\n",
        "\n",
        "    if just_once:\n",
        "      no_execute = True\n",
        "      just_once = False"
      ],
      "metadata": {
        "id": "-I1lq_KSp8E3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "c722a709-29c6-44dd-fe58-77d506d3e6f5"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------\n",
            "\n",
            "Dataset: RoadAnomaly21 method: Mahalanobis\n",
            "100% 10/10 [00:02<00:00,  3.75it/s]\n",
            "AUPRC score: 30.882157230765973\n",
            "FPR@TPR95: 74.4879201650216\n",
            "----------------------------\n",
            "\n",
            "Dataset: RoadObsticle21 method: Mahalanobis\n",
            "100% 30/30 [00:08<00:00,  3.63it/s]\n",
            "AUPRC score: 9.641072388098362\n",
            "FPR@TPR95: 52.43062225917142\n",
            "----------------------------\n",
            "\n",
            "Dataset: FS_LostFound_full method: Mahalanobis\n",
            "100% 100/100 [00:26<00:00,  3.78it/s]\n",
            "AUPRC score: 2.9424493821312754\n",
            "FPR@TPR95: 55.231371209083505\n",
            "----------------------------\n",
            "\n",
            "Dataset: fs_static method: Mahalanobis\n",
            "100% 30/30 [00:06<00:00,  4.96it/s]\n",
            "AUPRC score: 8.926899026567218\n",
            "FPR@TPR95: 39.33961912182676\n",
            "----------------------------\n",
            "\n",
            "Dataset: RoadAnomaly method: Mahalanobis\n",
            "100% 60/60 [00:11<00:00,  5.39it/s]\n",
            "AUPRC score: 13.528992306695075\n",
            "FPR@TPR95: 79.6254790023211\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFHIDiwduTGq"
      },
      "source": [
        "## Losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95d_Y3uG6ktP",
        "outputId": "233bd51a-c6c5-4060-b9ac-93595b7511a9",
        "collapsed": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "----- Fine-tuning with Focal loss -----\n",
            "odict_keys(['module.encoder.initial_block.conv.weight', 'module.encoder.initial_block.conv.bias', 'module.encoder.initial_block.bn.weight', 'module.encoder.initial_block.bn.bias', 'module.encoder.initial_block.bn.running_mean', 'module.encoder.initial_block.bn.running_var', 'module.encoder.layers.0.conv.weight', 'module.encoder.layers.0.conv.bias', 'module.encoder.layers.0.bn.weight', 'module.encoder.layers.0.bn.bias', 'module.encoder.layers.0.bn.running_mean', 'module.encoder.layers.0.bn.running_var', 'module.encoder.layers.1.conv3x1_1.weight', 'module.encoder.layers.1.conv3x1_1.bias', 'module.encoder.layers.1.conv1x3_1.weight', 'module.encoder.layers.1.conv1x3_1.bias', 'module.encoder.layers.1.conv3x1_2.weight', 'module.encoder.layers.1.conv3x1_2.bias', 'module.encoder.layers.1.conv1x3_2.weight', 'module.encoder.layers.1.conv1x3_2.bias', 'module.encoder.layers.1.bn1.weight', 'module.encoder.layers.1.bn1.bias', 'module.encoder.layers.1.bn1.running_mean', 'module.encoder.layers.1.bn1.running_var', 'module.encoder.layers.1.bn2.weight', 'module.encoder.layers.1.bn2.bias', 'module.encoder.layers.1.bn2.running_mean', 'module.encoder.layers.1.bn2.running_var', 'module.encoder.layers.2.conv3x1_1.weight', 'module.encoder.layers.2.conv3x1_1.bias', 'module.encoder.layers.2.conv1x3_1.weight', 'module.encoder.layers.2.conv1x3_1.bias', 'module.encoder.layers.2.conv3x1_2.weight', 'module.encoder.layers.2.conv3x1_2.bias', 'module.encoder.layers.2.conv1x3_2.weight', 'module.encoder.layers.2.conv1x3_2.bias', 'module.encoder.layers.2.bn1.weight', 'module.encoder.layers.2.bn1.bias', 'module.encoder.layers.2.bn1.running_mean', 'module.encoder.layers.2.bn1.running_var', 'module.encoder.layers.2.bn2.weight', 'module.encoder.layers.2.bn2.bias', 'module.encoder.layers.2.bn2.running_mean', 'module.encoder.layers.2.bn2.running_var', 'module.encoder.layers.3.conv3x1_1.weight', 'module.encoder.layers.3.conv3x1_1.bias', 'module.encoder.layers.3.conv1x3_1.weight', 'module.encoder.layers.3.conv1x3_1.bias', 'module.encoder.layers.3.conv3x1_2.weight', 'module.encoder.layers.3.conv3x1_2.bias', 'module.encoder.layers.3.conv1x3_2.weight', 'module.encoder.layers.3.conv1x3_2.bias', 'module.encoder.layers.3.bn1.weight', 'module.encoder.layers.3.bn1.bias', 'module.encoder.layers.3.bn1.running_mean', 'module.encoder.layers.3.bn1.running_var', 'module.encoder.layers.3.bn2.weight', 'module.encoder.layers.3.bn2.bias', 'module.encoder.layers.3.bn2.running_mean', 'module.encoder.layers.3.bn2.running_var', 'module.encoder.layers.4.conv3x1_1.weight', 'module.encoder.layers.4.conv3x1_1.bias', 'module.encoder.layers.4.conv1x3_1.weight', 'module.encoder.layers.4.conv1x3_1.bias', 'module.encoder.layers.4.conv3x1_2.weight', 'module.encoder.layers.4.conv3x1_2.bias', 'module.encoder.layers.4.conv1x3_2.weight', 'module.encoder.layers.4.conv1x3_2.bias', 'module.encoder.layers.4.bn1.weight', 'module.encoder.layers.4.bn1.bias', 'module.encoder.layers.4.bn1.running_mean', 'module.encoder.layers.4.bn1.running_var', 'module.encoder.layers.4.bn2.weight', 'module.encoder.layers.4.bn2.bias', 'module.encoder.layers.4.bn2.running_mean', 'module.encoder.layers.4.bn2.running_var', 'module.encoder.layers.5.conv3x1_1.weight', 'module.encoder.layers.5.conv3x1_1.bias', 'module.encoder.layers.5.conv1x3_1.weight', 'module.encoder.layers.5.conv1x3_1.bias', 'module.encoder.layers.5.conv3x1_2.weight', 'module.encoder.layers.5.conv3x1_2.bias', 'module.encoder.layers.5.conv1x3_2.weight', 'module.encoder.layers.5.conv1x3_2.bias', 'module.encoder.layers.5.bn1.weight', 'module.encoder.layers.5.bn1.bias', 'module.encoder.layers.5.bn1.running_mean', 'module.encoder.layers.5.bn1.running_var', 'module.encoder.layers.5.bn2.weight', 'module.encoder.layers.5.bn2.bias', 'module.encoder.layers.5.bn2.running_mean', 'module.encoder.layers.5.bn2.running_var', 'module.encoder.layers.6.conv.weight', 'module.encoder.layers.6.conv.bias', 'module.encoder.layers.6.bn.weight', 'module.encoder.layers.6.bn.bias', 'module.encoder.layers.6.bn.running_mean', 'module.encoder.layers.6.bn.running_var', 'module.encoder.layers.7.conv3x1_1.weight', 'module.encoder.layers.7.conv3x1_1.bias', 'module.encoder.layers.7.conv1x3_1.weight', 'module.encoder.layers.7.conv1x3_1.bias', 'module.encoder.layers.7.conv3x1_2.weight', 'module.encoder.layers.7.conv3x1_2.bias', 'module.encoder.layers.7.conv1x3_2.weight', 'module.encoder.layers.7.conv1x3_2.bias', 'module.encoder.layers.7.bn1.weight', 'module.encoder.layers.7.bn1.bias', 'module.encoder.layers.7.bn1.running_mean', 'module.encoder.layers.7.bn1.running_var', 'module.encoder.layers.7.bn2.weight', 'module.encoder.layers.7.bn2.bias', 'module.encoder.layers.7.bn2.running_mean', 'module.encoder.layers.7.bn2.running_var', 'module.encoder.layers.8.conv3x1_1.weight', 'module.encoder.layers.8.conv3x1_1.bias', 'module.encoder.layers.8.conv1x3_1.weight', 'module.encoder.layers.8.conv1x3_1.bias', 'module.encoder.layers.8.conv3x1_2.weight', 'module.encoder.layers.8.conv3x1_2.bias', 'module.encoder.layers.8.conv1x3_2.weight', 'module.encoder.layers.8.conv1x3_2.bias', 'module.encoder.layers.8.bn1.weight', 'module.encoder.layers.8.bn1.bias', 'module.encoder.layers.8.bn1.running_mean', 'module.encoder.layers.8.bn1.running_var', 'module.encoder.layers.8.bn2.weight', 'module.encoder.layers.8.bn2.bias', 'module.encoder.layers.8.bn2.running_mean', 'module.encoder.layers.8.bn2.running_var', 'module.encoder.layers.9.conv3x1_1.weight', 'module.encoder.layers.9.conv3x1_1.bias', 'module.encoder.layers.9.conv1x3_1.weight', 'module.encoder.layers.9.conv1x3_1.bias', 'module.encoder.layers.9.conv3x1_2.weight', 'module.encoder.layers.9.conv3x1_2.bias', 'module.encoder.layers.9.conv1x3_2.weight', 'module.encoder.layers.9.conv1x3_2.bias', 'module.encoder.layers.9.bn1.weight', 'module.encoder.layers.9.bn1.bias', 'module.encoder.layers.9.bn1.running_mean', 'module.encoder.layers.9.bn1.running_var', 'module.encoder.layers.9.bn2.weight', 'module.encoder.layers.9.bn2.bias', 'module.encoder.layers.9.bn2.running_mean', 'module.encoder.layers.9.bn2.running_var', 'module.encoder.layers.10.conv3x1_1.weight', 'module.encoder.layers.10.conv3x1_1.bias', 'module.encoder.layers.10.conv1x3_1.weight', 'module.encoder.layers.10.conv1x3_1.bias', 'module.encoder.layers.10.conv3x1_2.weight', 'module.encoder.layers.10.conv3x1_2.bias', 'module.encoder.layers.10.conv1x3_2.weight', 'module.encoder.layers.10.conv1x3_2.bias', 'module.encoder.layers.10.bn1.weight', 'module.encoder.layers.10.bn1.bias', 'module.encoder.layers.10.bn1.running_mean', 'module.encoder.layers.10.bn1.running_var', 'module.encoder.layers.10.bn2.weight', 'module.encoder.layers.10.bn2.bias', 'module.encoder.layers.10.bn2.running_mean', 'module.encoder.layers.10.bn2.running_var', 'module.encoder.layers.11.conv3x1_1.weight', 'module.encoder.layers.11.conv3x1_1.bias', 'module.encoder.layers.11.conv1x3_1.weight', 'module.encoder.layers.11.conv1x3_1.bias', 'module.encoder.layers.11.conv3x1_2.weight', 'module.encoder.layers.11.conv3x1_2.bias', 'module.encoder.layers.11.conv1x3_2.weight', 'module.encoder.layers.11.conv1x3_2.bias', 'module.encoder.layers.11.bn1.weight', 'module.encoder.layers.11.bn1.bias', 'module.encoder.layers.11.bn1.running_mean', 'module.encoder.layers.11.bn1.running_var', 'module.encoder.layers.11.bn2.weight', 'module.encoder.layers.11.bn2.bias', 'module.encoder.layers.11.bn2.running_mean', 'module.encoder.layers.11.bn2.running_var', 'module.encoder.layers.12.conv3x1_1.weight', 'module.encoder.layers.12.conv3x1_1.bias', 'module.encoder.layers.12.conv1x3_1.weight', 'module.encoder.layers.12.conv1x3_1.bias', 'module.encoder.layers.12.conv3x1_2.weight', 'module.encoder.layers.12.conv3x1_2.bias', 'module.encoder.layers.12.conv1x3_2.weight', 'module.encoder.layers.12.conv1x3_2.bias', 'module.encoder.layers.12.bn1.weight', 'module.encoder.layers.12.bn1.bias', 'module.encoder.layers.12.bn1.running_mean', 'module.encoder.layers.12.bn1.running_var', 'module.encoder.layers.12.bn2.weight', 'module.encoder.layers.12.bn2.bias', 'module.encoder.layers.12.bn2.running_mean', 'module.encoder.layers.12.bn2.running_var', 'module.encoder.layers.13.conv3x1_1.weight', 'module.encoder.layers.13.conv3x1_1.bias', 'module.encoder.layers.13.conv1x3_1.weight', 'module.encoder.layers.13.conv1x3_1.bias', 'module.encoder.layers.13.conv3x1_2.weight', 'module.encoder.layers.13.conv3x1_2.bias', 'module.encoder.layers.13.conv1x3_2.weight', 'module.encoder.layers.13.conv1x3_2.bias', 'module.encoder.layers.13.bn1.weight', 'module.encoder.layers.13.bn1.bias', 'module.encoder.layers.13.bn1.running_mean', 'module.encoder.layers.13.bn1.running_var', 'module.encoder.layers.13.bn2.weight', 'module.encoder.layers.13.bn2.bias', 'module.encoder.layers.13.bn2.running_mean', 'module.encoder.layers.13.bn2.running_var', 'module.encoder.layers.14.conv3x1_1.weight', 'module.encoder.layers.14.conv3x1_1.bias', 'module.encoder.layers.14.conv1x3_1.weight', 'module.encoder.layers.14.conv1x3_1.bias', 'module.encoder.layers.14.conv3x1_2.weight', 'module.encoder.layers.14.conv3x1_2.bias', 'module.encoder.layers.14.conv1x3_2.weight', 'module.encoder.layers.14.conv1x3_2.bias', 'module.encoder.layers.14.bn1.weight', 'module.encoder.layers.14.bn1.bias', 'module.encoder.layers.14.bn1.running_mean', 'module.encoder.layers.14.bn1.running_var', 'module.encoder.layers.14.bn2.weight', 'module.encoder.layers.14.bn2.bias', 'module.encoder.layers.14.bn2.running_mean', 'module.encoder.layers.14.bn2.running_var', 'module.decoder.layers.0.conv.weight', 'module.decoder.layers.0.conv.bias', 'module.decoder.layers.0.bn.weight', 'module.decoder.layers.0.bn.bias', 'module.decoder.layers.0.bn.running_mean', 'module.decoder.layers.0.bn.running_var', 'module.decoder.layers.1.conv3x1_1.weight', 'module.decoder.layers.1.conv3x1_1.bias', 'module.decoder.layers.1.conv1x3_1.weight', 'module.decoder.layers.1.conv1x3_1.bias', 'module.decoder.layers.1.bn1.weight', 'module.decoder.layers.1.bn1.bias', 'module.decoder.layers.1.bn1.running_mean', 'module.decoder.layers.1.bn1.running_var', 'module.decoder.layers.1.conv3x1_2.weight', 'module.decoder.layers.1.conv3x1_2.bias', 'module.decoder.layers.1.conv1x3_2.weight', 'module.decoder.layers.1.conv1x3_2.bias', 'module.decoder.layers.1.bn2.weight', 'module.decoder.layers.1.bn2.bias', 'module.decoder.layers.1.bn2.running_mean', 'module.decoder.layers.1.bn2.running_var', 'module.decoder.layers.2.conv3x1_1.weight', 'module.decoder.layers.2.conv3x1_1.bias', 'module.decoder.layers.2.conv1x3_1.weight', 'module.decoder.layers.2.conv1x3_1.bias', 'module.decoder.layers.2.bn1.weight', 'module.decoder.layers.2.bn1.bias', 'module.decoder.layers.2.bn1.running_mean', 'module.decoder.layers.2.bn1.running_var', 'module.decoder.layers.2.conv3x1_2.weight', 'module.decoder.layers.2.conv3x1_2.bias', 'module.decoder.layers.2.conv1x3_2.weight', 'module.decoder.layers.2.conv1x3_2.bias', 'module.decoder.layers.2.bn2.weight', 'module.decoder.layers.2.bn2.bias', 'module.decoder.layers.2.bn2.running_mean', 'module.decoder.layers.2.bn2.running_var', 'module.decoder.layers.3.conv.weight', 'module.decoder.layers.3.conv.bias', 'module.decoder.layers.3.bn.weight', 'module.decoder.layers.3.bn.bias', 'module.decoder.layers.3.bn.running_mean', 'module.decoder.layers.3.bn.running_var', 'module.decoder.layers.4.conv3x1_1.weight', 'module.decoder.layers.4.conv3x1_1.bias', 'module.decoder.layers.4.conv1x3_1.weight', 'module.decoder.layers.4.conv1x3_1.bias', 'module.decoder.layers.4.bn1.weight', 'module.decoder.layers.4.bn1.bias', 'module.decoder.layers.4.bn1.running_mean', 'module.decoder.layers.4.bn1.running_var', 'module.decoder.layers.4.conv3x1_2.weight', 'module.decoder.layers.4.conv3x1_2.bias', 'module.decoder.layers.4.conv1x3_2.weight', 'module.decoder.layers.4.conv1x3_2.bias', 'module.decoder.layers.4.bn2.weight', 'module.decoder.layers.4.bn2.bias', 'module.decoder.layers.4.bn2.running_mean', 'module.decoder.layers.4.bn2.running_var', 'module.decoder.layers.5.conv3x1_1.weight', 'module.decoder.layers.5.conv3x1_1.bias', 'module.decoder.layers.5.conv1x3_1.weight', 'module.decoder.layers.5.conv1x3_1.bias', 'module.decoder.layers.5.bn1.weight', 'module.decoder.layers.5.bn1.bias', 'module.decoder.layers.5.bn1.running_mean', 'module.decoder.layers.5.bn1.running_var', 'module.decoder.layers.5.conv3x1_2.weight', 'module.decoder.layers.5.conv3x1_2.bias', 'module.decoder.layers.5.conv1x3_2.weight', 'module.decoder.layers.5.conv1x3_2.bias', 'module.decoder.layers.5.bn2.weight', 'module.decoder.layers.5.bn2.bias', 'module.decoder.layers.5.bn2.running_mean', 'module.decoder.layers.5.bn2.running_var', 'module.decoder.output_conv.weight', 'module.decoder.output_conv.bias'])\n",
            "odict_keys(['encoder.initial_block.conv.weight', 'encoder.initial_block.conv.bias', 'encoder.initial_block.bn.weight', 'encoder.initial_block.bn.bias', 'encoder.initial_block.bn.running_mean', 'encoder.initial_block.bn.running_var', 'encoder.initial_block.bn.num_batches_tracked', 'encoder.layers.0.conv.weight', 'encoder.layers.0.conv.bias', 'encoder.layers.0.bn.weight', 'encoder.layers.0.bn.bias', 'encoder.layers.0.bn.running_mean', 'encoder.layers.0.bn.running_var', 'encoder.layers.0.bn.num_batches_tracked', 'encoder.layers.1.conv3x1_1.weight', 'encoder.layers.1.conv3x1_1.bias', 'encoder.layers.1.conv1x3_1.weight', 'encoder.layers.1.conv1x3_1.bias', 'encoder.layers.1.bn1.weight', 'encoder.layers.1.bn1.bias', 'encoder.layers.1.bn1.running_mean', 'encoder.layers.1.bn1.running_var', 'encoder.layers.1.bn1.num_batches_tracked', 'encoder.layers.1.conv3x1_2.weight', 'encoder.layers.1.conv3x1_2.bias', 'encoder.layers.1.conv1x3_2.weight', 'encoder.layers.1.conv1x3_2.bias', 'encoder.layers.1.bn2.weight', 'encoder.layers.1.bn2.bias', 'encoder.layers.1.bn2.running_mean', 'encoder.layers.1.bn2.running_var', 'encoder.layers.1.bn2.num_batches_tracked', 'encoder.layers.2.conv3x1_1.weight', 'encoder.layers.2.conv3x1_1.bias', 'encoder.layers.2.conv1x3_1.weight', 'encoder.layers.2.conv1x3_1.bias', 'encoder.layers.2.bn1.weight', 'encoder.layers.2.bn1.bias', 'encoder.layers.2.bn1.running_mean', 'encoder.layers.2.bn1.running_var', 'encoder.layers.2.bn1.num_batches_tracked', 'encoder.layers.2.conv3x1_2.weight', 'encoder.layers.2.conv3x1_2.bias', 'encoder.layers.2.conv1x3_2.weight', 'encoder.layers.2.conv1x3_2.bias', 'encoder.layers.2.bn2.weight', 'encoder.layers.2.bn2.bias', 'encoder.layers.2.bn2.running_mean', 'encoder.layers.2.bn2.running_var', 'encoder.layers.2.bn2.num_batches_tracked', 'encoder.layers.3.conv3x1_1.weight', 'encoder.layers.3.conv3x1_1.bias', 'encoder.layers.3.conv1x3_1.weight', 'encoder.layers.3.conv1x3_1.bias', 'encoder.layers.3.bn1.weight', 'encoder.layers.3.bn1.bias', 'encoder.layers.3.bn1.running_mean', 'encoder.layers.3.bn1.running_var', 'encoder.layers.3.bn1.num_batches_tracked', 'encoder.layers.3.conv3x1_2.weight', 'encoder.layers.3.conv3x1_2.bias', 'encoder.layers.3.conv1x3_2.weight', 'encoder.layers.3.conv1x3_2.bias', 'encoder.layers.3.bn2.weight', 'encoder.layers.3.bn2.bias', 'encoder.layers.3.bn2.running_mean', 'encoder.layers.3.bn2.running_var', 'encoder.layers.3.bn2.num_batches_tracked', 'encoder.layers.4.conv3x1_1.weight', 'encoder.layers.4.conv3x1_1.bias', 'encoder.layers.4.conv1x3_1.weight', 'encoder.layers.4.conv1x3_1.bias', 'encoder.layers.4.bn1.weight', 'encoder.layers.4.bn1.bias', 'encoder.layers.4.bn1.running_mean', 'encoder.layers.4.bn1.running_var', 'encoder.layers.4.bn1.num_batches_tracked', 'encoder.layers.4.conv3x1_2.weight', 'encoder.layers.4.conv3x1_2.bias', 'encoder.layers.4.conv1x3_2.weight', 'encoder.layers.4.conv1x3_2.bias', 'encoder.layers.4.bn2.weight', 'encoder.layers.4.bn2.bias', 'encoder.layers.4.bn2.running_mean', 'encoder.layers.4.bn2.running_var', 'encoder.layers.4.bn2.num_batches_tracked', 'encoder.layers.5.conv3x1_1.weight', 'encoder.layers.5.conv3x1_1.bias', 'encoder.layers.5.conv1x3_1.weight', 'encoder.layers.5.conv1x3_1.bias', 'encoder.layers.5.bn1.weight', 'encoder.layers.5.bn1.bias', 'encoder.layers.5.bn1.running_mean', 'encoder.layers.5.bn1.running_var', 'encoder.layers.5.bn1.num_batches_tracked', 'encoder.layers.5.conv3x1_2.weight', 'encoder.layers.5.conv3x1_2.bias', 'encoder.layers.5.conv1x3_2.weight', 'encoder.layers.5.conv1x3_2.bias', 'encoder.layers.5.bn2.weight', 'encoder.layers.5.bn2.bias', 'encoder.layers.5.bn2.running_mean', 'encoder.layers.5.bn2.running_var', 'encoder.layers.5.bn2.num_batches_tracked', 'encoder.layers.6.conv.weight', 'encoder.layers.6.conv.bias', 'encoder.layers.6.bn.weight', 'encoder.layers.6.bn.bias', 'encoder.layers.6.bn.running_mean', 'encoder.layers.6.bn.running_var', 'encoder.layers.6.bn.num_batches_tracked', 'encoder.layers.7.conv3x1_1.weight', 'encoder.layers.7.conv3x1_1.bias', 'encoder.layers.7.conv1x3_1.weight', 'encoder.layers.7.conv1x3_1.bias', 'encoder.layers.7.bn1.weight', 'encoder.layers.7.bn1.bias', 'encoder.layers.7.bn1.running_mean', 'encoder.layers.7.bn1.running_var', 'encoder.layers.7.bn1.num_batches_tracked', 'encoder.layers.7.conv3x1_2.weight', 'encoder.layers.7.conv3x1_2.bias', 'encoder.layers.7.conv1x3_2.weight', 'encoder.layers.7.conv1x3_2.bias', 'encoder.layers.7.bn2.weight', 'encoder.layers.7.bn2.bias', 'encoder.layers.7.bn2.running_mean', 'encoder.layers.7.bn2.running_var', 'encoder.layers.7.bn2.num_batches_tracked', 'encoder.layers.8.conv3x1_1.weight', 'encoder.layers.8.conv3x1_1.bias', 'encoder.layers.8.conv1x3_1.weight', 'encoder.layers.8.conv1x3_1.bias', 'encoder.layers.8.bn1.weight', 'encoder.layers.8.bn1.bias', 'encoder.layers.8.bn1.running_mean', 'encoder.layers.8.bn1.running_var', 'encoder.layers.8.bn1.num_batches_tracked', 'encoder.layers.8.conv3x1_2.weight', 'encoder.layers.8.conv3x1_2.bias', 'encoder.layers.8.conv1x3_2.weight', 'encoder.layers.8.conv1x3_2.bias', 'encoder.layers.8.bn2.weight', 'encoder.layers.8.bn2.bias', 'encoder.layers.8.bn2.running_mean', 'encoder.layers.8.bn2.running_var', 'encoder.layers.8.bn2.num_batches_tracked', 'encoder.layers.9.conv3x1_1.weight', 'encoder.layers.9.conv3x1_1.bias', 'encoder.layers.9.conv1x3_1.weight', 'encoder.layers.9.conv1x3_1.bias', 'encoder.layers.9.bn1.weight', 'encoder.layers.9.bn1.bias', 'encoder.layers.9.bn1.running_mean', 'encoder.layers.9.bn1.running_var', 'encoder.layers.9.bn1.num_batches_tracked', 'encoder.layers.9.conv3x1_2.weight', 'encoder.layers.9.conv3x1_2.bias', 'encoder.layers.9.conv1x3_2.weight', 'encoder.layers.9.conv1x3_2.bias', 'encoder.layers.9.bn2.weight', 'encoder.layers.9.bn2.bias', 'encoder.layers.9.bn2.running_mean', 'encoder.layers.9.bn2.running_var', 'encoder.layers.9.bn2.num_batches_tracked', 'encoder.layers.10.conv3x1_1.weight', 'encoder.layers.10.conv3x1_1.bias', 'encoder.layers.10.conv1x3_1.weight', 'encoder.layers.10.conv1x3_1.bias', 'encoder.layers.10.bn1.weight', 'encoder.layers.10.bn1.bias', 'encoder.layers.10.bn1.running_mean', 'encoder.layers.10.bn1.running_var', 'encoder.layers.10.bn1.num_batches_tracked', 'encoder.layers.10.conv3x1_2.weight', 'encoder.layers.10.conv3x1_2.bias', 'encoder.layers.10.conv1x3_2.weight', 'encoder.layers.10.conv1x3_2.bias', 'encoder.layers.10.bn2.weight', 'encoder.layers.10.bn2.bias', 'encoder.layers.10.bn2.running_mean', 'encoder.layers.10.bn2.running_var', 'encoder.layers.10.bn2.num_batches_tracked', 'encoder.layers.11.conv3x1_1.weight', 'encoder.layers.11.conv3x1_1.bias', 'encoder.layers.11.conv1x3_1.weight', 'encoder.layers.11.conv1x3_1.bias', 'encoder.layers.11.bn1.weight', 'encoder.layers.11.bn1.bias', 'encoder.layers.11.bn1.running_mean', 'encoder.layers.11.bn1.running_var', 'encoder.layers.11.bn1.num_batches_tracked', 'encoder.layers.11.conv3x1_2.weight', 'encoder.layers.11.conv3x1_2.bias', 'encoder.layers.11.conv1x3_2.weight', 'encoder.layers.11.conv1x3_2.bias', 'encoder.layers.11.bn2.weight', 'encoder.layers.11.bn2.bias', 'encoder.layers.11.bn2.running_mean', 'encoder.layers.11.bn2.running_var', 'encoder.layers.11.bn2.num_batches_tracked', 'encoder.layers.12.conv3x1_1.weight', 'encoder.layers.12.conv3x1_1.bias', 'encoder.layers.12.conv1x3_1.weight', 'encoder.layers.12.conv1x3_1.bias', 'encoder.layers.12.bn1.weight', 'encoder.layers.12.bn1.bias', 'encoder.layers.12.bn1.running_mean', 'encoder.layers.12.bn1.running_var', 'encoder.layers.12.bn1.num_batches_tracked', 'encoder.layers.12.conv3x1_2.weight', 'encoder.layers.12.conv3x1_2.bias', 'encoder.layers.12.conv1x3_2.weight', 'encoder.layers.12.conv1x3_2.bias', 'encoder.layers.12.bn2.weight', 'encoder.layers.12.bn2.bias', 'encoder.layers.12.bn2.running_mean', 'encoder.layers.12.bn2.running_var', 'encoder.layers.12.bn2.num_batches_tracked', 'encoder.layers.13.conv3x1_1.weight', 'encoder.layers.13.conv3x1_1.bias', 'encoder.layers.13.conv1x3_1.weight', 'encoder.layers.13.conv1x3_1.bias', 'encoder.layers.13.bn1.weight', 'encoder.layers.13.bn1.bias', 'encoder.layers.13.bn1.running_mean', 'encoder.layers.13.bn1.running_var', 'encoder.layers.13.bn1.num_batches_tracked', 'encoder.layers.13.conv3x1_2.weight', 'encoder.layers.13.conv3x1_2.bias', 'encoder.layers.13.conv1x3_2.weight', 'encoder.layers.13.conv1x3_2.bias', 'encoder.layers.13.bn2.weight', 'encoder.layers.13.bn2.bias', 'encoder.layers.13.bn2.running_mean', 'encoder.layers.13.bn2.running_var', 'encoder.layers.13.bn2.num_batches_tracked', 'encoder.layers.14.conv3x1_1.weight', 'encoder.layers.14.conv3x1_1.bias', 'encoder.layers.14.conv1x3_1.weight', 'encoder.layers.14.conv1x3_1.bias', 'encoder.layers.14.bn1.weight', 'encoder.layers.14.bn1.bias', 'encoder.layers.14.bn1.running_mean', 'encoder.layers.14.bn1.running_var', 'encoder.layers.14.bn1.num_batches_tracked', 'encoder.layers.14.conv3x1_2.weight', 'encoder.layers.14.conv3x1_2.bias', 'encoder.layers.14.conv1x3_2.weight', 'encoder.layers.14.conv1x3_2.bias', 'encoder.layers.14.bn2.weight', 'encoder.layers.14.bn2.bias', 'encoder.layers.14.bn2.running_mean', 'encoder.layers.14.bn2.running_var', 'encoder.layers.14.bn2.num_batches_tracked', 'encoder.output_conv.weight', 'encoder.output_conv.bias', 'decoder.layers.0.conv.weight', 'decoder.layers.0.conv.bias', 'decoder.layers.0.bn.weight', 'decoder.layers.0.bn.bias', 'decoder.layers.0.bn.running_mean', 'decoder.layers.0.bn.running_var', 'decoder.layers.0.bn.num_batches_tracked', 'decoder.layers.1.conv3x1_1.weight', 'decoder.layers.1.conv3x1_1.bias', 'decoder.layers.1.conv1x3_1.weight', 'decoder.layers.1.conv1x3_1.bias', 'decoder.layers.1.bn1.weight', 'decoder.layers.1.bn1.bias', 'decoder.layers.1.bn1.running_mean', 'decoder.layers.1.bn1.running_var', 'decoder.layers.1.bn1.num_batches_tracked', 'decoder.layers.1.conv3x1_2.weight', 'decoder.layers.1.conv3x1_2.bias', 'decoder.layers.1.conv1x3_2.weight', 'decoder.layers.1.conv1x3_2.bias', 'decoder.layers.1.bn2.weight', 'decoder.layers.1.bn2.bias', 'decoder.layers.1.bn2.running_mean', 'decoder.layers.1.bn2.running_var', 'decoder.layers.1.bn2.num_batches_tracked', 'decoder.layers.2.conv3x1_1.weight', 'decoder.layers.2.conv3x1_1.bias', 'decoder.layers.2.conv1x3_1.weight', 'decoder.layers.2.conv1x3_1.bias', 'decoder.layers.2.bn1.weight', 'decoder.layers.2.bn1.bias', 'decoder.layers.2.bn1.running_mean', 'decoder.layers.2.bn1.running_var', 'decoder.layers.2.bn1.num_batches_tracked', 'decoder.layers.2.conv3x1_2.weight', 'decoder.layers.2.conv3x1_2.bias', 'decoder.layers.2.conv1x3_2.weight', 'decoder.layers.2.conv1x3_2.bias', 'decoder.layers.2.bn2.weight', 'decoder.layers.2.bn2.bias', 'decoder.layers.2.bn2.running_mean', 'decoder.layers.2.bn2.running_var', 'decoder.layers.2.bn2.num_batches_tracked', 'decoder.layers.3.conv.weight', 'decoder.layers.3.conv.bias', 'decoder.layers.3.bn.weight', 'decoder.layers.3.bn.bias', 'decoder.layers.3.bn.running_mean', 'decoder.layers.3.bn.running_var', 'decoder.layers.3.bn.num_batches_tracked', 'decoder.layers.4.conv3x1_1.weight', 'decoder.layers.4.conv3x1_1.bias', 'decoder.layers.4.conv1x3_1.weight', 'decoder.layers.4.conv1x3_1.bias', 'decoder.layers.4.bn1.weight', 'decoder.layers.4.bn1.bias', 'decoder.layers.4.bn1.running_mean', 'decoder.layers.4.bn1.running_var', 'decoder.layers.4.bn1.num_batches_tracked', 'decoder.layers.4.conv3x1_2.weight', 'decoder.layers.4.conv3x1_2.bias', 'decoder.layers.4.conv1x3_2.weight', 'decoder.layers.4.conv1x3_2.bias', 'decoder.layers.4.bn2.weight', 'decoder.layers.4.bn2.bias', 'decoder.layers.4.bn2.running_mean', 'decoder.layers.4.bn2.running_var', 'decoder.layers.4.bn2.num_batches_tracked', 'decoder.layers.5.conv3x1_1.weight', 'decoder.layers.5.conv3x1_1.bias', 'decoder.layers.5.conv1x3_1.weight', 'decoder.layers.5.conv1x3_1.bias', 'decoder.layers.5.bn1.weight', 'decoder.layers.5.bn1.bias', 'decoder.layers.5.bn1.running_mean', 'decoder.layers.5.bn1.running_var', 'decoder.layers.5.bn1.num_batches_tracked', 'decoder.layers.5.conv3x1_2.weight', 'decoder.layers.5.conv3x1_2.bias', 'decoder.layers.5.conv1x3_2.weight', 'decoder.layers.5.conv1x3_2.bias', 'decoder.layers.5.bn2.weight', 'decoder.layers.5.bn2.bias', 'decoder.layers.5.bn2.running_mean', 'decoder.layers.5.bn2.running_var', 'decoder.layers.5.bn2.num_batches_tracked', 'decoder.output_conv.weight', 'decoder.output_conv.bias'])\n",
            "Import Model erfnet with weights erfnet_pretrained.pth to FineTune\n",
            "========== TRAINING ===========\n",
            "/content/cityscapes/leftImg8bit/train\n",
            "/content/cityscapes/leftImg8bit/val\n",
            "----- TRAINING - EPOCH 1 -----\n",
            "LEARNING RATE:  5e-05\n",
            "loss: 0.8898 (epoch: 1, step: 0) // Avg time/img: 0.3255 s\n",
            "loss: 1.234 (epoch: 1, step: 50) // Avg time/img: 0.0495 s\n",
            "loss: 1.208 (epoch: 1, step: 100) // Avg time/img: 0.0470 s\n",
            "loss: 1.209 (epoch: 1, step: 150) // Avg time/img: 0.0462 s\n",
            "loss: 1.19 (epoch: 1, step: 200) // Avg time/img: 0.0459 s\n",
            "loss: 1.188 (epoch: 1, step: 250) // Avg time/img: 0.0458 s\n",
            "loss: 1.185 (epoch: 1, step: 300) // Avg time/img: 0.0456 s\n",
            "loss: 1.169 (epoch: 1, step: 350) // Avg time/img: 0.0456 s\n",
            "loss: 1.169 (epoch: 1, step: 400) // Avg time/img: 0.0455 s\n",
            "loss: 1.16 (epoch: 1, step: 450) // Avg time/img: 0.0455 s\n",
            "----- VALIDATING - EPOCH 1 -----\n",
            "VAL loss: 1.152 (epoch: 1, step: 0) // Avg time/img: 0.0486 s\n",
            "VAL loss: 1.342 (epoch: 1, step: 50) // Avg time/img: 0.0338 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m72.19\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/erfnet_training_focal_loss/model-001.pth (epoch: 1)\n",
            "save: ../save/erfnet_training_focal_loss/model_best.pth (epoch: 1)\n",
            "----- TRAINING - EPOCH 2 -----\n",
            "LEARNING RATE:  4.774426908107499e-05\n",
            "loss: 1.701 (epoch: 2, step: 0) // Avg time/img: 0.0505 s\n",
            "loss: 1.016 (epoch: 2, step: 50) // Avg time/img: 0.0459 s\n",
            "loss: 1.004 (epoch: 2, step: 100) // Avg time/img: 0.0458 s\n",
            "loss: 1.011 (epoch: 2, step: 150) // Avg time/img: 0.0456 s\n",
            "loss: 1.006 (epoch: 2, step: 200) // Avg time/img: 0.0458 s\n",
            "loss: 0.9969 (epoch: 2, step: 250) // Avg time/img: 0.0459 s\n",
            "loss: 0.9928 (epoch: 2, step: 300) // Avg time/img: 0.0459 s\n",
            "loss: 0.9828 (epoch: 2, step: 350) // Avg time/img: 0.0459 s\n",
            "loss: 0.9711 (epoch: 2, step: 400) // Avg time/img: 0.0460 s\n",
            "loss: 0.9636 (epoch: 2, step: 450) // Avg time/img: 0.0461 s\n",
            "----- VALIDATING - EPOCH 2 -----\n",
            "VAL loss: 0.9424 (epoch: 2, step: 0) // Avg time/img: 0.0463 s\n",
            "VAL loss: 1.113 (epoch: 2, step: 50) // Avg time/img: 0.0341 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m71.81\u001b[0m %\n",
            "save: ../save/erfnet_training_focal_loss/model-002.pth (epoch: 2)\n",
            "----- TRAINING - EPOCH 3 -----\n",
            "LEARNING RATE:  4.547662880414811e-05\n",
            "loss: 0.7212 (epoch: 3, step: 0) // Avg time/img: 0.0504 s\n",
            "loss: 0.8354 (epoch: 3, step: 50) // Avg time/img: 0.0469 s\n",
            "loss: 0.8059 (epoch: 3, step: 100) // Avg time/img: 0.0468 s\n",
            "loss: 0.8033 (epoch: 3, step: 150) // Avg time/img: 0.0471 s\n",
            "loss: 0.8028 (epoch: 3, step: 200) // Avg time/img: 0.0470 s\n",
            "loss: 0.8009 (epoch: 3, step: 250) // Avg time/img: 0.0474 s\n",
            "loss: 0.7937 (epoch: 3, step: 300) // Avg time/img: 0.0477 s\n",
            "loss: 0.7847 (epoch: 3, step: 350) // Avg time/img: 0.0479 s\n",
            "loss: 0.7761 (epoch: 3, step: 400) // Avg time/img: 0.0480 s\n",
            "loss: 0.7713 (epoch: 3, step: 450) // Avg time/img: 0.0479 s\n",
            "----- VALIDATING - EPOCH 3 -----\n",
            "VAL loss: 0.774 (epoch: 3, step: 0) // Avg time/img: 0.0505 s\n",
            "VAL loss: 0.9109 (epoch: 3, step: 50) // Avg time/img: 0.0351 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m72.20\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/erfnet_training_focal_loss/model-003.pth (epoch: 3)\n",
            "save: ../save/erfnet_training_focal_loss/model_best.pth (epoch: 3)\n",
            "----- TRAINING - EPOCH 4 -----\n",
            "LEARNING RATE:  4.319634861514096e-05\n",
            "loss: 0.616 (epoch: 4, step: 0) // Avg time/img: 0.0644 s\n",
            "loss: 0.6356 (epoch: 4, step: 50) // Avg time/img: 0.0465 s\n",
            "loss: 0.6477 (epoch: 4, step: 100) // Avg time/img: 0.0469 s\n",
            "loss: 0.6538 (epoch: 4, step: 150) // Avg time/img: 0.0468 s\n",
            "loss: 0.6589 (epoch: 4, step: 200) // Avg time/img: 0.0471 s\n",
            "loss: 0.6507 (epoch: 4, step: 250) // Avg time/img: 0.0470 s\n",
            "loss: 0.6461 (epoch: 4, step: 300) // Avg time/img: 0.0471 s\n",
            "loss: 0.6281 (epoch: 4, step: 350) // Avg time/img: 0.0470 s\n",
            "loss: 0.6199 (epoch: 4, step: 400) // Avg time/img: 0.0472 s\n",
            "loss: 0.6182 (epoch: 4, step: 450) // Avg time/img: 0.0471 s\n",
            "----- VALIDATING - EPOCH 4 -----\n",
            "VAL loss: 0.6228 (epoch: 4, step: 0) // Avg time/img: 0.0465 s\n",
            "VAL loss: 0.745 (epoch: 4, step: 50) // Avg time/img: 0.0344 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m71.65\u001b[0m %\n",
            "save: ../save/erfnet_training_focal_loss/model-004.pth (epoch: 4)\n",
            "----- TRAINING - EPOCH 5 -----\n",
            "LEARNING RATE:  4.090260730254292e-05\n",
            "loss: 0.4657 (epoch: 5, step: 0) // Avg time/img: 0.0532 s\n",
            "loss: 0.5276 (epoch: 5, step: 50) // Avg time/img: 0.0472 s\n",
            "loss: 0.5289 (epoch: 5, step: 100) // Avg time/img: 0.0475 s\n",
            "loss: 0.5409 (epoch: 5, step: 150) // Avg time/img: 0.0473 s\n",
            "loss: 0.5328 (epoch: 5, step: 200) // Avg time/img: 0.0472 s\n",
            "loss: 0.5351 (epoch: 5, step: 250) // Avg time/img: 0.0470 s\n",
            "loss: 0.5301 (epoch: 5, step: 300) // Avg time/img: 0.0470 s\n",
            "loss: 0.5257 (epoch: 5, step: 350) // Avg time/img: 0.0469 s\n",
            "loss: 0.5196 (epoch: 5, step: 400) // Avg time/img: 0.0470 s\n",
            "loss: 0.519 (epoch: 5, step: 450) // Avg time/img: 0.0470 s\n",
            "----- VALIDATING - EPOCH 5 -----\n",
            "VAL loss: 0.5539 (epoch: 5, step: 0) // Avg time/img: 0.0493 s\n",
            "VAL loss: 0.665 (epoch: 5, step: 50) // Avg time/img: 0.0347 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m69.91\u001b[0m %\n",
            "save: ../save/erfnet_training_focal_loss/model-005.pth (epoch: 5)\n",
            "----- TRAINING - EPOCH 6 -----\n",
            "LEARNING RATE:  3.859447533617852e-05\n",
            "loss: 0.4165 (epoch: 6, step: 0) // Avg time/img: 0.0539 s\n",
            "loss: 0.5141 (epoch: 6, step: 50) // Avg time/img: 0.0467 s\n",
            "loss: 0.5019 (epoch: 6, step: 100) // Avg time/img: 0.0470 s\n",
            "loss: 0.4899 (epoch: 6, step: 150) // Avg time/img: 0.0466 s\n",
            "loss: 0.4777 (epoch: 6, step: 200) // Avg time/img: 0.0468 s\n",
            "loss: 0.4737 (epoch: 6, step: 250) // Avg time/img: 0.0467 s\n",
            "loss: 0.4698 (epoch: 6, step: 300) // Avg time/img: 0.0468 s\n",
            "loss: 0.4661 (epoch: 6, step: 350) // Avg time/img: 0.0470 s\n",
            "loss: 0.4636 (epoch: 6, step: 400) // Avg time/img: 0.0470 s\n",
            "loss: 0.4594 (epoch: 6, step: 450) // Avg time/img: 0.0473 s\n",
            "----- VALIDATING - EPOCH 6 -----\n",
            "VAL loss: 0.5128 (epoch: 6, step: 0) // Avg time/img: 0.0502 s\n",
            "VAL loss: 0.6238 (epoch: 6, step: 50) // Avg time/img: 0.0356 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m69.07\u001b[0m %\n",
            "save: ../save/erfnet_training_focal_loss/model-006.pth (epoch: 6)\n",
            "----- TRAINING - EPOCH 7 -----\n",
            "LEARNING RATE:  3.6270892346861e-05\n",
            "loss: 0.3477 (epoch: 7, step: 0) // Avg time/img: 0.0535 s\n",
            "loss: 0.4589 (epoch: 7, step: 50) // Avg time/img: 0.0467 s\n",
            "loss: 0.4558 (epoch: 7, step: 100) // Avg time/img: 0.0473 s\n",
            "loss: 0.4494 (epoch: 7, step: 150) // Avg time/img: 0.0472 s\n",
            "loss: 0.4431 (epoch: 7, step: 200) // Avg time/img: 0.0471 s\n",
            "loss: 0.4403 (epoch: 7, step: 250) // Avg time/img: 0.0471 s\n",
            "loss: 0.4344 (epoch: 7, step: 300) // Avg time/img: 0.0472 s\n",
            "loss: 0.4297 (epoch: 7, step: 350) // Avg time/img: 0.0472 s\n",
            "loss: 0.4278 (epoch: 7, step: 400) // Avg time/img: 0.0473 s\n",
            "loss: 0.4256 (epoch: 7, step: 450) // Avg time/img: 0.0472 s\n",
            "----- VALIDATING - EPOCH 7 -----\n",
            "VAL loss: 0.5099 (epoch: 7, step: 0) // Avg time/img: 0.0545 s\n",
            "VAL loss: 0.599 (epoch: 7, step: 50) // Avg time/img: 0.0344 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m68.56\u001b[0m %\n",
            "save: ../save/erfnet_training_focal_loss/model-007.pth (epoch: 7)\n",
            "----- TRAINING - EPOCH 8 -----\n",
            "LEARNING RATE:  3.393063796290625e-05\n",
            "loss: 0.2477 (epoch: 8, step: 0) // Avg time/img: 0.0552 s\n",
            "loss: 0.4132 (epoch: 8, step: 50) // Avg time/img: 0.0467 s\n",
            "loss: 0.4098 (epoch: 8, step: 100) // Avg time/img: 0.0464 s\n",
            "loss: 0.4061 (epoch: 8, step: 150) // Avg time/img: 0.0467 s\n",
            "loss: 0.4058 (epoch: 8, step: 200) // Avg time/img: 0.0467 s\n",
            "loss: 0.409 (epoch: 8, step: 250) // Avg time/img: 0.0468 s\n",
            "loss: 0.409 (epoch: 8, step: 300) // Avg time/img: 0.0467 s\n",
            "loss: 0.407 (epoch: 8, step: 350) // Avg time/img: 0.0468 s\n",
            "loss: 0.4064 (epoch: 8, step: 400) // Avg time/img: 0.0468 s\n",
            "loss: 0.4037 (epoch: 8, step: 450) // Avg time/img: 0.0469 s\n",
            "----- VALIDATING - EPOCH 8 -----\n",
            "VAL loss: 0.4708 (epoch: 8, step: 0) // Avg time/img: 0.0447 s\n",
            "VAL loss: 0.5627 (epoch: 8, step: 50) // Avg time/img: 0.0343 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m68.52\u001b[0m %\n",
            "save: ../save/erfnet_training_focal_loss/model-008.pth (epoch: 8)\n",
            "----- TRAINING - EPOCH 9 -----\n",
            "LEARNING RATE:  3.157229337446777e-05\n",
            "loss: 0.3547 (epoch: 9, step: 0) // Avg time/img: 0.0556 s\n",
            "loss: 0.3986 (epoch: 9, step: 50) // Avg time/img: 0.0463 s\n",
            "loss: 0.3984 (epoch: 9, step: 100) // Avg time/img: 0.0461 s\n",
            "loss: 0.3989 (epoch: 9, step: 150) // Avg time/img: 0.0464 s\n",
            "loss: 0.397 (epoch: 9, step: 200) // Avg time/img: 0.0464 s\n",
            "loss: 0.3944 (epoch: 9, step: 250) // Avg time/img: 0.0464 s\n",
            "loss: 0.3906 (epoch: 9, step: 300) // Avg time/img: 0.0465 s\n",
            "loss: 0.3895 (epoch: 9, step: 350) // Avg time/img: 0.0464 s\n",
            "loss: 0.3903 (epoch: 9, step: 400) // Avg time/img: 0.0464 s\n",
            "loss: 0.3894 (epoch: 9, step: 450) // Avg time/img: 0.0466 s\n",
            "----- VALIDATING - EPOCH 9 -----\n",
            "VAL loss: 0.4423 (epoch: 9, step: 0) // Avg time/img: 0.0446 s\n",
            "VAL loss: 0.5326 (epoch: 9, step: 50) // Avg time/img: 0.0356 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m68.82\u001b[0m %\n",
            "save: ../save/erfnet_training_focal_loss/model-009.pth (epoch: 9)\n",
            "----- TRAINING - EPOCH 10 -----\n",
            "LEARNING RATE:  2.9194189645999014e-05\n",
            "loss: 0.3467 (epoch: 10, step: 0) // Avg time/img: 0.0578 s\n",
            "loss: 0.3799 (epoch: 10, step: 50) // Avg time/img: 0.0469 s\n",
            "loss: 0.3782 (epoch: 10, step: 100) // Avg time/img: 0.0468 s\n",
            "loss: 0.3825 (epoch: 10, step: 150) // Avg time/img: 0.0471 s\n",
            "loss: 0.384 (epoch: 10, step: 200) // Avg time/img: 0.0470 s\n",
            "loss: 0.3815 (epoch: 10, step: 250) // Avg time/img: 0.0470 s\n",
            "loss: 0.3789 (epoch: 10, step: 300) // Avg time/img: 0.0469 s\n",
            "loss: 0.3749 (epoch: 10, step: 350) // Avg time/img: 0.0470 s\n",
            "loss: 0.3752 (epoch: 10, step: 400) // Avg time/img: 0.0469 s\n",
            "loss: 0.3765 (epoch: 10, step: 450) // Avg time/img: 0.0469 s\n",
            "----- VALIDATING - EPOCH 10 -----\n",
            "VAL loss: 0.4392 (epoch: 10, step: 0) // Avg time/img: 0.0485 s\n",
            "VAL loss: 0.5314 (epoch: 10, step: 50) // Avg time/img: 0.0344 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m69.09\u001b[0m %\n",
            "save: ../save/erfnet_training_focal_loss/model-010.pth (epoch: 10)\n",
            "----- TRAINING - EPOCH 11 -----\n",
            "LEARNING RATE:  2.679433656340733e-05\n",
            "loss: 0.3007 (epoch: 11, step: 0) // Avg time/img: 0.0611 s\n",
            "loss: 0.3743 (epoch: 11, step: 50) // Avg time/img: 0.0463 s\n",
            "loss: 0.3793 (epoch: 11, step: 100) // Avg time/img: 0.0469 s\n",
            "loss: 0.38 (epoch: 11, step: 150) // Avg time/img: 0.0467 s\n",
            "loss: 0.376 (epoch: 11, step: 200) // Avg time/img: 0.0467 s\n",
            "loss: 0.3711 (epoch: 11, step: 250) // Avg time/img: 0.0467 s\n",
            "loss: 0.3708 (epoch: 11, step: 300) // Avg time/img: 0.0467 s\n",
            "loss: 0.3703 (epoch: 11, step: 350) // Avg time/img: 0.0468 s\n",
            "loss: 0.3711 (epoch: 11, step: 400) // Avg time/img: 0.0468 s\n",
            "loss: 0.3705 (epoch: 11, step: 450) // Avg time/img: 0.0468 s\n",
            "----- VALIDATING - EPOCH 11 -----\n",
            "VAL loss: 0.4139 (epoch: 11, step: 0) // Avg time/img: 0.0459 s\n",
            "VAL loss: 0.5157 (epoch: 11, step: 50) // Avg time/img: 0.0344 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m69.41\u001b[0m %\n",
            "save: ../save/erfnet_training_focal_loss/model-011.pth (epoch: 11)\n",
            "----- TRAINING - EPOCH 12 -----\n",
            "LEARNING RATE:  2.437032195894977e-05\n",
            "loss: 0.316 (epoch: 12, step: 0) // Avg time/img: 0.0629 s\n",
            "loss: 0.3704 (epoch: 12, step: 50) // Avg time/img: 0.0471 s\n",
            "loss: 0.3638 (epoch: 12, step: 100) // Avg time/img: 0.0465 s\n",
            "loss: 0.3628 (epoch: 12, step: 150) // Avg time/img: 0.0466 s\n",
            "loss: 0.3653 (epoch: 12, step: 200) // Avg time/img: 0.0465 s\n",
            "loss: 0.3657 (epoch: 12, step: 250) // Avg time/img: 0.0466 s\n",
            "loss: 0.3631 (epoch: 12, step: 300) // Avg time/img: 0.0465 s\n",
            "loss: 0.3662 (epoch: 12, step: 350) // Avg time/img: 0.0466 s\n",
            "loss: 0.3667 (epoch: 12, step: 400) // Avg time/img: 0.0466 s\n",
            "loss: 0.3661 (epoch: 12, step: 450) // Avg time/img: 0.0467 s\n",
            "----- VALIDATING - EPOCH 12 -----\n",
            "VAL loss: 0.421 (epoch: 12, step: 0) // Avg time/img: 0.0510 s\n",
            "VAL loss: 0.5023 (epoch: 12, step: 50) // Avg time/img: 0.0363 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m69.33\u001b[0m %\n",
            "save: ../save/erfnet_training_focal_loss/model-012.pth (epoch: 12)\n",
            "----- TRAINING - EPOCH 13 -----\n",
            "LEARNING RATE:  2.191916452770435e-05\n",
            "loss: 0.3917 (epoch: 13, step: 0) // Avg time/img: 0.0540 s\n",
            "loss: 0.3655 (epoch: 13, step: 50) // Avg time/img: 0.0478 s\n",
            "loss: 0.3657 (epoch: 13, step: 100) // Avg time/img: 0.0476 s\n",
            "loss: 0.3627 (epoch: 13, step: 150) // Avg time/img: 0.0476 s\n",
            "loss: 0.3646 (epoch: 13, step: 200) // Avg time/img: 0.0477 s\n",
            "loss: 0.3629 (epoch: 13, step: 250) // Avg time/img: 0.0476 s\n",
            "loss: 0.3608 (epoch: 13, step: 300) // Avg time/img: 0.0475 s\n",
            "loss: 0.3609 (epoch: 13, step: 350) // Avg time/img: 0.0474 s\n",
            "loss: 0.3602 (epoch: 13, step: 400) // Avg time/img: 0.0473 s\n",
            "loss: 0.3603 (epoch: 13, step: 450) // Avg time/img: 0.0472 s\n",
            "----- VALIDATING - EPOCH 13 -----\n",
            "VAL loss: 0.4108 (epoch: 13, step: 0) // Avg time/img: 0.0499 s\n",
            "VAL loss: 0.4957 (epoch: 13, step: 50) // Avg time/img: 0.0346 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m69.34\u001b[0m %\n",
            "save: ../save/erfnet_training_focal_loss/model-013.pth (epoch: 13)\n",
            "----- TRAINING - EPOCH 14 -----\n",
            "LEARNING RATE:  1.9437089939938174e-05\n",
            "loss: 0.3779 (epoch: 14, step: 0) // Avg time/img: 0.0580 s\n",
            "loss: 0.3632 (epoch: 14, step: 50) // Avg time/img: 0.0470 s\n",
            "loss: 0.3619 (epoch: 14, step: 100) // Avg time/img: 0.0469 s\n",
            "loss: 0.367 (epoch: 14, step: 150) // Avg time/img: 0.0466 s\n",
            "loss: 0.3635 (epoch: 14, step: 200) // Avg time/img: 0.0467 s\n",
            "loss: 0.3611 (epoch: 14, step: 250) // Avg time/img: 0.0467 s\n",
            "loss: 0.3628 (epoch: 14, step: 300) // Avg time/img: 0.0467 s\n",
            "loss: 0.3616 (epoch: 14, step: 350) // Avg time/img: 0.0467 s\n",
            "loss: 0.3594 (epoch: 14, step: 400) // Avg time/img: 0.0468 s\n",
            "loss: 0.3573 (epoch: 14, step: 450) // Avg time/img: 0.0468 s\n",
            "----- VALIDATING - EPOCH 14 -----\n",
            "VAL loss: 0.4113 (epoch: 14, step: 0) // Avg time/img: 0.0494 s\n",
            "VAL loss: 0.4925 (epoch: 14, step: 50) // Avg time/img: 0.0352 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m70.05\u001b[0m %\n",
            "save: ../save/erfnet_training_focal_loss/model-014.pth (epoch: 14)\n",
            "----- TRAINING - EPOCH 15 -----\n",
            "LEARNING RATE:  1.6919173095082493e-05\n",
            "loss: 0.2982 (epoch: 15, step: 0) // Avg time/img: 0.0569 s\n",
            "loss: 0.359 (epoch: 15, step: 50) // Avg time/img: 0.0469 s\n",
            "loss: 0.3553 (epoch: 15, step: 100) // Avg time/img: 0.0467 s\n",
            "loss: 0.3651 (epoch: 15, step: 150) // Avg time/img: 0.0467 s\n",
            "loss: 0.361 (epoch: 15, step: 200) // Avg time/img: 0.0467 s\n",
            "loss: 0.3587 (epoch: 15, step: 250) // Avg time/img: 0.0467 s\n",
            "loss: 0.3584 (epoch: 15, step: 300) // Avg time/img: 0.0468 s\n",
            "loss: 0.3581 (epoch: 15, step: 350) // Avg time/img: 0.0467 s\n",
            "loss: 0.3572 (epoch: 15, step: 400) // Avg time/img: 0.0468 s\n",
            "loss: 0.3553 (epoch: 15, step: 450) // Avg time/img: 0.0467 s\n",
            "----- VALIDATING - EPOCH 15 -----\n",
            "VAL loss: 0.4225 (epoch: 15, step: 0) // Avg time/img: 0.0481 s\n",
            "VAL loss: 0.4985 (epoch: 15, step: 50) // Avg time/img: 0.0335 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m69.60\u001b[0m %\n",
            "save: ../save/erfnet_training_focal_loss/model-015.pth (epoch: 15)\n",
            "----- TRAINING - EPOCH 16 -----\n",
            "LEARNING RATE:  1.4358729437462937e-05\n",
            "loss: 0.3645 (epoch: 16, step: 0) // Avg time/img: 0.0453 s\n",
            "loss: 0.353 (epoch: 16, step: 50) // Avg time/img: 0.0473 s\n",
            "loss: 0.3509 (epoch: 16, step: 100) // Avg time/img: 0.0469 s\n",
            "loss: 0.3513 (epoch: 16, step: 150) // Avg time/img: 0.0472 s\n",
            "loss: 0.35 (epoch: 16, step: 200) // Avg time/img: 0.0473 s\n",
            "loss: 0.3487 (epoch: 16, step: 250) // Avg time/img: 0.0473 s\n",
            "loss: 0.3474 (epoch: 16, step: 300) // Avg time/img: 0.0474 s\n",
            "loss: 0.3482 (epoch: 16, step: 350) // Avg time/img: 0.0477 s\n",
            "loss: 0.3486 (epoch: 16, step: 400) // Avg time/img: 0.0478 s\n",
            "loss: 0.3499 (epoch: 16, step: 450) // Avg time/img: 0.0480 s\n",
            "----- VALIDATING - EPOCH 16 -----\n",
            "VAL loss: 0.4092 (epoch: 16, step: 0) // Avg time/img: 0.0463 s\n",
            "VAL loss: 0.4823 (epoch: 16, step: 50) // Avg time/img: 0.0348 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m69.83\u001b[0m %\n",
            "save: ../save/erfnet_training_focal_loss/model-016.pth (epoch: 16)\n",
            "----- TRAINING - EPOCH 17 -----\n",
            "LEARNING RATE:  1.1746189430880188e-05\n",
            "loss: 0.3241 (epoch: 17, step: 0) // Avg time/img: 0.0530 s\n",
            "loss: 0.3386 (epoch: 17, step: 50) // Avg time/img: 0.0475 s\n",
            "loss: 0.3379 (epoch: 17, step: 100) // Avg time/img: 0.0470 s\n",
            "loss: 0.3438 (epoch: 17, step: 150) // Avg time/img: 0.0471 s\n",
            "loss: 0.3383 (epoch: 17, step: 200) // Avg time/img: 0.0469 s\n",
            "loss: 0.341 (epoch: 17, step: 250) // Avg time/img: 0.0470 s\n",
            "loss: 0.345 (epoch: 17, step: 300) // Avg time/img: 0.0471 s\n",
            "loss: 0.3461 (epoch: 17, step: 350) // Avg time/img: 0.0472 s\n",
            "loss: 0.3483 (epoch: 17, step: 400) // Avg time/img: 0.0473 s\n",
            "loss: 0.348 (epoch: 17, step: 450) // Avg time/img: 0.0472 s\n",
            "----- VALIDATING - EPOCH 17 -----\n",
            "VAL loss: 0.4017 (epoch: 17, step: 0) // Avg time/img: 0.0530 s\n",
            "VAL loss: 0.4826 (epoch: 17, step: 50) // Avg time/img: 0.0342 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m70.03\u001b[0m %\n",
            "save: ../save/erfnet_training_focal_loss/model-017.pth (epoch: 17)\n",
            "----- TRAINING - EPOCH 18 -----\n",
            "LEARNING RATE:  9.066760365683729e-06\n",
            "loss: 0.3123 (epoch: 18, step: 0) // Avg time/img: 0.0519 s\n",
            "loss: 0.3497 (epoch: 18, step: 50) // Avg time/img: 0.0475 s\n",
            "loss: 0.3562 (epoch: 18, step: 100) // Avg time/img: 0.0472 s\n",
            "loss: 0.3535 (epoch: 18, step: 150) // Avg time/img: 0.0471 s\n",
            "loss: 0.3523 (epoch: 18, step: 200) // Avg time/img: 0.0470 s\n",
            "loss: 0.3519 (epoch: 18, step: 250) // Avg time/img: 0.0469 s\n",
            "loss: 0.3517 (epoch: 18, step: 300) // Avg time/img: 0.0468 s\n",
            "loss: 0.3509 (epoch: 18, step: 350) // Avg time/img: 0.0471 s\n",
            "loss: 0.3498 (epoch: 18, step: 400) // Avg time/img: 0.0473 s\n",
            "loss: 0.3499 (epoch: 18, step: 450) // Avg time/img: 0.0476 s\n",
            "----- VALIDATING - EPOCH 18 -----\n",
            "VAL loss: 0.4023 (epoch: 18, step: 0) // Avg time/img: 0.0527 s\n",
            "VAL loss: 0.483 (epoch: 18, step: 50) // Avg time/img: 0.0363 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m69.99\u001b[0m %\n",
            "save: ../save/erfnet_training_focal_loss/model-018.pth (epoch: 18)\n",
            "----- TRAINING - EPOCH 19 -----\n",
            "LEARNING RATE:  6.294627058970836e-06\n",
            "loss: 0.2718 (epoch: 19, step: 0) // Avg time/img: 0.0545 s\n",
            "loss: 0.3506 (epoch: 19, step: 50) // Avg time/img: 0.0475 s\n",
            "loss: 0.3437 (epoch: 19, step: 100) // Avg time/img: 0.0472 s\n",
            "loss: 0.3425 (epoch: 19, step: 150) // Avg time/img: 0.0474 s\n",
            "loss: 0.3446 (epoch: 19, step: 200) // Avg time/img: 0.0472 s\n",
            "loss: 0.3495 (epoch: 19, step: 250) // Avg time/img: 0.0472 s\n",
            "loss: 0.3508 (epoch: 19, step: 300) // Avg time/img: 0.0471 s\n",
            "loss: 0.3501 (epoch: 19, step: 350) // Avg time/img: 0.0471 s\n",
            "loss: 0.3497 (epoch: 19, step: 400) // Avg time/img: 0.0471 s\n",
            "loss: 0.3484 (epoch: 19, step: 450) // Avg time/img: 0.0471 s\n",
            "----- VALIDATING - EPOCH 19 -----\n",
            "VAL loss: 0.4041 (epoch: 19, step: 0) // Avg time/img: 0.0437 s\n",
            "VAL loss: 0.4803 (epoch: 19, step: 50) // Avg time/img: 0.0347 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m69.98\u001b[0m %\n",
            "save: ../save/erfnet_training_focal_loss/model-019.pth (epoch: 19)\n",
            "----- TRAINING - EPOCH 20 -----\n",
            "LEARNING RATE:  3.373207119183911e-06\n",
            "loss: 0.4666 (epoch: 20, step: 0) // Avg time/img: 0.0497 s\n",
            "loss: 0.3457 (epoch: 20, step: 50) // Avg time/img: 0.0458 s\n",
            "loss: 0.3409 (epoch: 20, step: 100) // Avg time/img: 0.0463 s\n",
            "loss: 0.3431 (epoch: 20, step: 150) // Avg time/img: 0.0465 s\n",
            "loss: 0.3445 (epoch: 20, step: 200) // Avg time/img: 0.0466 s\n",
            "loss: 0.3455 (epoch: 20, step: 250) // Avg time/img: 0.0467 s\n",
            "loss: 0.3461 (epoch: 20, step: 300) // Avg time/img: 0.0468 s\n",
            "loss: 0.3464 (epoch: 20, step: 350) // Avg time/img: 0.0468 s\n",
            "loss: 0.3469 (epoch: 20, step: 400) // Avg time/img: 0.0469 s\n",
            "loss: 0.3462 (epoch: 20, step: 450) // Avg time/img: 0.0469 s\n",
            "----- VALIDATING - EPOCH 20 -----\n",
            "VAL loss: 0.3865 (epoch: 20, step: 0) // Avg time/img: 0.0458 s\n",
            "VAL loss: 0.4719 (epoch: 20, step: 50) // Avg time/img: 0.0349 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m69.89\u001b[0m %\n",
            "save: ../save/erfnet_training_focal_loss/model-020.pth (epoch: 20)\n",
            "========== TRAINING FINISHED ===========\n",
            "Model saved in /content/AnomalySegmentation/save/erfnet_training_focal_loss\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_focal_loss/ (stored 0%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_focal_loss/model_best.pth (deflated 10%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_focal_loss/model-007.pth (deflated 10%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_focal_loss/model-015.pth (deflated 10%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_focal_loss/model-008.pth (deflated 10%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_focal_loss/model-004.pth (deflated 10%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_focal_loss/model-005.pth (deflated 10%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_focal_loss/model-002.pth (deflated 10%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_focal_loss/opts.txt (deflated 37%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_focal_loss/model.txt (deflated 92%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_focal_loss/model-014.pth (deflated 10%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_focal_loss/model-013.pth (deflated 10%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_focal_loss/model-012.pth (deflated 10%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_focal_loss/model-016.pth (deflated 10%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_focal_loss/model-011.pth (deflated 10%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_focal_loss/checkpoint.pth.tar (deflated 10%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_focal_loss/model-010.pth (deflated 10%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_focal_loss/model-020.pth (deflated 10%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_focal_loss/model_best.pth.tar (deflated 10%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_focal_loss/model-009.pth (deflated 10%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_focal_loss/model-003.pth (deflated 10%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_focal_loss/model-006.pth (deflated 10%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_focal_loss/automated_log.txt (deflated 64%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_focal_loss/model-019.pth (deflated 10%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_focal_loss/model-017.pth (deflated 10%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_focal_loss/model-018.pth (deflated 10%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_focal_loss/best.txt (stored 0%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_focal_loss/model-001.pth (deflated 10%)\n",
            "\n",
            "\n",
            "----- Fine-tuning with LogitNorm loss -----\n",
            "odict_keys(['module.encoder.initial_block.conv.weight', 'module.encoder.initial_block.conv.bias', 'module.encoder.initial_block.bn.weight', 'module.encoder.initial_block.bn.bias', 'module.encoder.initial_block.bn.running_mean', 'module.encoder.initial_block.bn.running_var', 'module.encoder.layers.0.conv.weight', 'module.encoder.layers.0.conv.bias', 'module.encoder.layers.0.bn.weight', 'module.encoder.layers.0.bn.bias', 'module.encoder.layers.0.bn.running_mean', 'module.encoder.layers.0.bn.running_var', 'module.encoder.layers.1.conv3x1_1.weight', 'module.encoder.layers.1.conv3x1_1.bias', 'module.encoder.layers.1.conv1x3_1.weight', 'module.encoder.layers.1.conv1x3_1.bias', 'module.encoder.layers.1.conv3x1_2.weight', 'module.encoder.layers.1.conv3x1_2.bias', 'module.encoder.layers.1.conv1x3_2.weight', 'module.encoder.layers.1.conv1x3_2.bias', 'module.encoder.layers.1.bn1.weight', 'module.encoder.layers.1.bn1.bias', 'module.encoder.layers.1.bn1.running_mean', 'module.encoder.layers.1.bn1.running_var', 'module.encoder.layers.1.bn2.weight', 'module.encoder.layers.1.bn2.bias', 'module.encoder.layers.1.bn2.running_mean', 'module.encoder.layers.1.bn2.running_var', 'module.encoder.layers.2.conv3x1_1.weight', 'module.encoder.layers.2.conv3x1_1.bias', 'module.encoder.layers.2.conv1x3_1.weight', 'module.encoder.layers.2.conv1x3_1.bias', 'module.encoder.layers.2.conv3x1_2.weight', 'module.encoder.layers.2.conv3x1_2.bias', 'module.encoder.layers.2.conv1x3_2.weight', 'module.encoder.layers.2.conv1x3_2.bias', 'module.encoder.layers.2.bn1.weight', 'module.encoder.layers.2.bn1.bias', 'module.encoder.layers.2.bn1.running_mean', 'module.encoder.layers.2.bn1.running_var', 'module.encoder.layers.2.bn2.weight', 'module.encoder.layers.2.bn2.bias', 'module.encoder.layers.2.bn2.running_mean', 'module.encoder.layers.2.bn2.running_var', 'module.encoder.layers.3.conv3x1_1.weight', 'module.encoder.layers.3.conv3x1_1.bias', 'module.encoder.layers.3.conv1x3_1.weight', 'module.encoder.layers.3.conv1x3_1.bias', 'module.encoder.layers.3.conv3x1_2.weight', 'module.encoder.layers.3.conv3x1_2.bias', 'module.encoder.layers.3.conv1x3_2.weight', 'module.encoder.layers.3.conv1x3_2.bias', 'module.encoder.layers.3.bn1.weight', 'module.encoder.layers.3.bn1.bias', 'module.encoder.layers.3.bn1.running_mean', 'module.encoder.layers.3.bn1.running_var', 'module.encoder.layers.3.bn2.weight', 'module.encoder.layers.3.bn2.bias', 'module.encoder.layers.3.bn2.running_mean', 'module.encoder.layers.3.bn2.running_var', 'module.encoder.layers.4.conv3x1_1.weight', 'module.encoder.layers.4.conv3x1_1.bias', 'module.encoder.layers.4.conv1x3_1.weight', 'module.encoder.layers.4.conv1x3_1.bias', 'module.encoder.layers.4.conv3x1_2.weight', 'module.encoder.layers.4.conv3x1_2.bias', 'module.encoder.layers.4.conv1x3_2.weight', 'module.encoder.layers.4.conv1x3_2.bias', 'module.encoder.layers.4.bn1.weight', 'module.encoder.layers.4.bn1.bias', 'module.encoder.layers.4.bn1.running_mean', 'module.encoder.layers.4.bn1.running_var', 'module.encoder.layers.4.bn2.weight', 'module.encoder.layers.4.bn2.bias', 'module.encoder.layers.4.bn2.running_mean', 'module.encoder.layers.4.bn2.running_var', 'module.encoder.layers.5.conv3x1_1.weight', 'module.encoder.layers.5.conv3x1_1.bias', 'module.encoder.layers.5.conv1x3_1.weight', 'module.encoder.layers.5.conv1x3_1.bias', 'module.encoder.layers.5.conv3x1_2.weight', 'module.encoder.layers.5.conv3x1_2.bias', 'module.encoder.layers.5.conv1x3_2.weight', 'module.encoder.layers.5.conv1x3_2.bias', 'module.encoder.layers.5.bn1.weight', 'module.encoder.layers.5.bn1.bias', 'module.encoder.layers.5.bn1.running_mean', 'module.encoder.layers.5.bn1.running_var', 'module.encoder.layers.5.bn2.weight', 'module.encoder.layers.5.bn2.bias', 'module.encoder.layers.5.bn2.running_mean', 'module.encoder.layers.5.bn2.running_var', 'module.encoder.layers.6.conv.weight', 'module.encoder.layers.6.conv.bias', 'module.encoder.layers.6.bn.weight', 'module.encoder.layers.6.bn.bias', 'module.encoder.layers.6.bn.running_mean', 'module.encoder.layers.6.bn.running_var', 'module.encoder.layers.7.conv3x1_1.weight', 'module.encoder.layers.7.conv3x1_1.bias', 'module.encoder.layers.7.conv1x3_1.weight', 'module.encoder.layers.7.conv1x3_1.bias', 'module.encoder.layers.7.conv3x1_2.weight', 'module.encoder.layers.7.conv3x1_2.bias', 'module.encoder.layers.7.conv1x3_2.weight', 'module.encoder.layers.7.conv1x3_2.bias', 'module.encoder.layers.7.bn1.weight', 'module.encoder.layers.7.bn1.bias', 'module.encoder.layers.7.bn1.running_mean', 'module.encoder.layers.7.bn1.running_var', 'module.encoder.layers.7.bn2.weight', 'module.encoder.layers.7.bn2.bias', 'module.encoder.layers.7.bn2.running_mean', 'module.encoder.layers.7.bn2.running_var', 'module.encoder.layers.8.conv3x1_1.weight', 'module.encoder.layers.8.conv3x1_1.bias', 'module.encoder.layers.8.conv1x3_1.weight', 'module.encoder.layers.8.conv1x3_1.bias', 'module.encoder.layers.8.conv3x1_2.weight', 'module.encoder.layers.8.conv3x1_2.bias', 'module.encoder.layers.8.conv1x3_2.weight', 'module.encoder.layers.8.conv1x3_2.bias', 'module.encoder.layers.8.bn1.weight', 'module.encoder.layers.8.bn1.bias', 'module.encoder.layers.8.bn1.running_mean', 'module.encoder.layers.8.bn1.running_var', 'module.encoder.layers.8.bn2.weight', 'module.encoder.layers.8.bn2.bias', 'module.encoder.layers.8.bn2.running_mean', 'module.encoder.layers.8.bn2.running_var', 'module.encoder.layers.9.conv3x1_1.weight', 'module.encoder.layers.9.conv3x1_1.bias', 'module.encoder.layers.9.conv1x3_1.weight', 'module.encoder.layers.9.conv1x3_1.bias', 'module.encoder.layers.9.conv3x1_2.weight', 'module.encoder.layers.9.conv3x1_2.bias', 'module.encoder.layers.9.conv1x3_2.weight', 'module.encoder.layers.9.conv1x3_2.bias', 'module.encoder.layers.9.bn1.weight', 'module.encoder.layers.9.bn1.bias', 'module.encoder.layers.9.bn1.running_mean', 'module.encoder.layers.9.bn1.running_var', 'module.encoder.layers.9.bn2.weight', 'module.encoder.layers.9.bn2.bias', 'module.encoder.layers.9.bn2.running_mean', 'module.encoder.layers.9.bn2.running_var', 'module.encoder.layers.10.conv3x1_1.weight', 'module.encoder.layers.10.conv3x1_1.bias', 'module.encoder.layers.10.conv1x3_1.weight', 'module.encoder.layers.10.conv1x3_1.bias', 'module.encoder.layers.10.conv3x1_2.weight', 'module.encoder.layers.10.conv3x1_2.bias', 'module.encoder.layers.10.conv1x3_2.weight', 'module.encoder.layers.10.conv1x3_2.bias', 'module.encoder.layers.10.bn1.weight', 'module.encoder.layers.10.bn1.bias', 'module.encoder.layers.10.bn1.running_mean', 'module.encoder.layers.10.bn1.running_var', 'module.encoder.layers.10.bn2.weight', 'module.encoder.layers.10.bn2.bias', 'module.encoder.layers.10.bn2.running_mean', 'module.encoder.layers.10.bn2.running_var', 'module.encoder.layers.11.conv3x1_1.weight', 'module.encoder.layers.11.conv3x1_1.bias', 'module.encoder.layers.11.conv1x3_1.weight', 'module.encoder.layers.11.conv1x3_1.bias', 'module.encoder.layers.11.conv3x1_2.weight', 'module.encoder.layers.11.conv3x1_2.bias', 'module.encoder.layers.11.conv1x3_2.weight', 'module.encoder.layers.11.conv1x3_2.bias', 'module.encoder.layers.11.bn1.weight', 'module.encoder.layers.11.bn1.bias', 'module.encoder.layers.11.bn1.running_mean', 'module.encoder.layers.11.bn1.running_var', 'module.encoder.layers.11.bn2.weight', 'module.encoder.layers.11.bn2.bias', 'module.encoder.layers.11.bn2.running_mean', 'module.encoder.layers.11.bn2.running_var', 'module.encoder.layers.12.conv3x1_1.weight', 'module.encoder.layers.12.conv3x1_1.bias', 'module.encoder.layers.12.conv1x3_1.weight', 'module.encoder.layers.12.conv1x3_1.bias', 'module.encoder.layers.12.conv3x1_2.weight', 'module.encoder.layers.12.conv3x1_2.bias', 'module.encoder.layers.12.conv1x3_2.weight', 'module.encoder.layers.12.conv1x3_2.bias', 'module.encoder.layers.12.bn1.weight', 'module.encoder.layers.12.bn1.bias', 'module.encoder.layers.12.bn1.running_mean', 'module.encoder.layers.12.bn1.running_var', 'module.encoder.layers.12.bn2.weight', 'module.encoder.layers.12.bn2.bias', 'module.encoder.layers.12.bn2.running_mean', 'module.encoder.layers.12.bn2.running_var', 'module.encoder.layers.13.conv3x1_1.weight', 'module.encoder.layers.13.conv3x1_1.bias', 'module.encoder.layers.13.conv1x3_1.weight', 'module.encoder.layers.13.conv1x3_1.bias', 'module.encoder.layers.13.conv3x1_2.weight', 'module.encoder.layers.13.conv3x1_2.bias', 'module.encoder.layers.13.conv1x3_2.weight', 'module.encoder.layers.13.conv1x3_2.bias', 'module.encoder.layers.13.bn1.weight', 'module.encoder.layers.13.bn1.bias', 'module.encoder.layers.13.bn1.running_mean', 'module.encoder.layers.13.bn1.running_var', 'module.encoder.layers.13.bn2.weight', 'module.encoder.layers.13.bn2.bias', 'module.encoder.layers.13.bn2.running_mean', 'module.encoder.layers.13.bn2.running_var', 'module.encoder.layers.14.conv3x1_1.weight', 'module.encoder.layers.14.conv3x1_1.bias', 'module.encoder.layers.14.conv1x3_1.weight', 'module.encoder.layers.14.conv1x3_1.bias', 'module.encoder.layers.14.conv3x1_2.weight', 'module.encoder.layers.14.conv3x1_2.bias', 'module.encoder.layers.14.conv1x3_2.weight', 'module.encoder.layers.14.conv1x3_2.bias', 'module.encoder.layers.14.bn1.weight', 'module.encoder.layers.14.bn1.bias', 'module.encoder.layers.14.bn1.running_mean', 'module.encoder.layers.14.bn1.running_var', 'module.encoder.layers.14.bn2.weight', 'module.encoder.layers.14.bn2.bias', 'module.encoder.layers.14.bn2.running_mean', 'module.encoder.layers.14.bn2.running_var', 'module.decoder.layers.0.conv.weight', 'module.decoder.layers.0.conv.bias', 'module.decoder.layers.0.bn.weight', 'module.decoder.layers.0.bn.bias', 'module.decoder.layers.0.bn.running_mean', 'module.decoder.layers.0.bn.running_var', 'module.decoder.layers.1.conv3x1_1.weight', 'module.decoder.layers.1.conv3x1_1.bias', 'module.decoder.layers.1.conv1x3_1.weight', 'module.decoder.layers.1.conv1x3_1.bias', 'module.decoder.layers.1.bn1.weight', 'module.decoder.layers.1.bn1.bias', 'module.decoder.layers.1.bn1.running_mean', 'module.decoder.layers.1.bn1.running_var', 'module.decoder.layers.1.conv3x1_2.weight', 'module.decoder.layers.1.conv3x1_2.bias', 'module.decoder.layers.1.conv1x3_2.weight', 'module.decoder.layers.1.conv1x3_2.bias', 'module.decoder.layers.1.bn2.weight', 'module.decoder.layers.1.bn2.bias', 'module.decoder.layers.1.bn2.running_mean', 'module.decoder.layers.1.bn2.running_var', 'module.decoder.layers.2.conv3x1_1.weight', 'module.decoder.layers.2.conv3x1_1.bias', 'module.decoder.layers.2.conv1x3_1.weight', 'module.decoder.layers.2.conv1x3_1.bias', 'module.decoder.layers.2.bn1.weight', 'module.decoder.layers.2.bn1.bias', 'module.decoder.layers.2.bn1.running_mean', 'module.decoder.layers.2.bn1.running_var', 'module.decoder.layers.2.conv3x1_2.weight', 'module.decoder.layers.2.conv3x1_2.bias', 'module.decoder.layers.2.conv1x3_2.weight', 'module.decoder.layers.2.conv1x3_2.bias', 'module.decoder.layers.2.bn2.weight', 'module.decoder.layers.2.bn2.bias', 'module.decoder.layers.2.bn2.running_mean', 'module.decoder.layers.2.bn2.running_var', 'module.decoder.layers.3.conv.weight', 'module.decoder.layers.3.conv.bias', 'module.decoder.layers.3.bn.weight', 'module.decoder.layers.3.bn.bias', 'module.decoder.layers.3.bn.running_mean', 'module.decoder.layers.3.bn.running_var', 'module.decoder.layers.4.conv3x1_1.weight', 'module.decoder.layers.4.conv3x1_1.bias', 'module.decoder.layers.4.conv1x3_1.weight', 'module.decoder.layers.4.conv1x3_1.bias', 'module.decoder.layers.4.bn1.weight', 'module.decoder.layers.4.bn1.bias', 'module.decoder.layers.4.bn1.running_mean', 'module.decoder.layers.4.bn1.running_var', 'module.decoder.layers.4.conv3x1_2.weight', 'module.decoder.layers.4.conv3x1_2.bias', 'module.decoder.layers.4.conv1x3_2.weight', 'module.decoder.layers.4.conv1x3_2.bias', 'module.decoder.layers.4.bn2.weight', 'module.decoder.layers.4.bn2.bias', 'module.decoder.layers.4.bn2.running_mean', 'module.decoder.layers.4.bn2.running_var', 'module.decoder.layers.5.conv3x1_1.weight', 'module.decoder.layers.5.conv3x1_1.bias', 'module.decoder.layers.5.conv1x3_1.weight', 'module.decoder.layers.5.conv1x3_1.bias', 'module.decoder.layers.5.bn1.weight', 'module.decoder.layers.5.bn1.bias', 'module.decoder.layers.5.bn1.running_mean', 'module.decoder.layers.5.bn1.running_var', 'module.decoder.layers.5.conv3x1_2.weight', 'module.decoder.layers.5.conv3x1_2.bias', 'module.decoder.layers.5.conv1x3_2.weight', 'module.decoder.layers.5.conv1x3_2.bias', 'module.decoder.layers.5.bn2.weight', 'module.decoder.layers.5.bn2.bias', 'module.decoder.layers.5.bn2.running_mean', 'module.decoder.layers.5.bn2.running_var', 'module.decoder.output_conv.weight', 'module.decoder.output_conv.bias'])\n",
            "odict_keys(['encoder.initial_block.conv.weight', 'encoder.initial_block.conv.bias', 'encoder.initial_block.bn.weight', 'encoder.initial_block.bn.bias', 'encoder.initial_block.bn.running_mean', 'encoder.initial_block.bn.running_var', 'encoder.initial_block.bn.num_batches_tracked', 'encoder.layers.0.conv.weight', 'encoder.layers.0.conv.bias', 'encoder.layers.0.bn.weight', 'encoder.layers.0.bn.bias', 'encoder.layers.0.bn.running_mean', 'encoder.layers.0.bn.running_var', 'encoder.layers.0.bn.num_batches_tracked', 'encoder.layers.1.conv3x1_1.weight', 'encoder.layers.1.conv3x1_1.bias', 'encoder.layers.1.conv1x3_1.weight', 'encoder.layers.1.conv1x3_1.bias', 'encoder.layers.1.bn1.weight', 'encoder.layers.1.bn1.bias', 'encoder.layers.1.bn1.running_mean', 'encoder.layers.1.bn1.running_var', 'encoder.layers.1.bn1.num_batches_tracked', 'encoder.layers.1.conv3x1_2.weight', 'encoder.layers.1.conv3x1_2.bias', 'encoder.layers.1.conv1x3_2.weight', 'encoder.layers.1.conv1x3_2.bias', 'encoder.layers.1.bn2.weight', 'encoder.layers.1.bn2.bias', 'encoder.layers.1.bn2.running_mean', 'encoder.layers.1.bn2.running_var', 'encoder.layers.1.bn2.num_batches_tracked', 'encoder.layers.2.conv3x1_1.weight', 'encoder.layers.2.conv3x1_1.bias', 'encoder.layers.2.conv1x3_1.weight', 'encoder.layers.2.conv1x3_1.bias', 'encoder.layers.2.bn1.weight', 'encoder.layers.2.bn1.bias', 'encoder.layers.2.bn1.running_mean', 'encoder.layers.2.bn1.running_var', 'encoder.layers.2.bn1.num_batches_tracked', 'encoder.layers.2.conv3x1_2.weight', 'encoder.layers.2.conv3x1_2.bias', 'encoder.layers.2.conv1x3_2.weight', 'encoder.layers.2.conv1x3_2.bias', 'encoder.layers.2.bn2.weight', 'encoder.layers.2.bn2.bias', 'encoder.layers.2.bn2.running_mean', 'encoder.layers.2.bn2.running_var', 'encoder.layers.2.bn2.num_batches_tracked', 'encoder.layers.3.conv3x1_1.weight', 'encoder.layers.3.conv3x1_1.bias', 'encoder.layers.3.conv1x3_1.weight', 'encoder.layers.3.conv1x3_1.bias', 'encoder.layers.3.bn1.weight', 'encoder.layers.3.bn1.bias', 'encoder.layers.3.bn1.running_mean', 'encoder.layers.3.bn1.running_var', 'encoder.layers.3.bn1.num_batches_tracked', 'encoder.layers.3.conv3x1_2.weight', 'encoder.layers.3.conv3x1_2.bias', 'encoder.layers.3.conv1x3_2.weight', 'encoder.layers.3.conv1x3_2.bias', 'encoder.layers.3.bn2.weight', 'encoder.layers.3.bn2.bias', 'encoder.layers.3.bn2.running_mean', 'encoder.layers.3.bn2.running_var', 'encoder.layers.3.bn2.num_batches_tracked', 'encoder.layers.4.conv3x1_1.weight', 'encoder.layers.4.conv3x1_1.bias', 'encoder.layers.4.conv1x3_1.weight', 'encoder.layers.4.conv1x3_1.bias', 'encoder.layers.4.bn1.weight', 'encoder.layers.4.bn1.bias', 'encoder.layers.4.bn1.running_mean', 'encoder.layers.4.bn1.running_var', 'encoder.layers.4.bn1.num_batches_tracked', 'encoder.layers.4.conv3x1_2.weight', 'encoder.layers.4.conv3x1_2.bias', 'encoder.layers.4.conv1x3_2.weight', 'encoder.layers.4.conv1x3_2.bias', 'encoder.layers.4.bn2.weight', 'encoder.layers.4.bn2.bias', 'encoder.layers.4.bn2.running_mean', 'encoder.layers.4.bn2.running_var', 'encoder.layers.4.bn2.num_batches_tracked', 'encoder.layers.5.conv3x1_1.weight', 'encoder.layers.5.conv3x1_1.bias', 'encoder.layers.5.conv1x3_1.weight', 'encoder.layers.5.conv1x3_1.bias', 'encoder.layers.5.bn1.weight', 'encoder.layers.5.bn1.bias', 'encoder.layers.5.bn1.running_mean', 'encoder.layers.5.bn1.running_var', 'encoder.layers.5.bn1.num_batches_tracked', 'encoder.layers.5.conv3x1_2.weight', 'encoder.layers.5.conv3x1_2.bias', 'encoder.layers.5.conv1x3_2.weight', 'encoder.layers.5.conv1x3_2.bias', 'encoder.layers.5.bn2.weight', 'encoder.layers.5.bn2.bias', 'encoder.layers.5.bn2.running_mean', 'encoder.layers.5.bn2.running_var', 'encoder.layers.5.bn2.num_batches_tracked', 'encoder.layers.6.conv.weight', 'encoder.layers.6.conv.bias', 'encoder.layers.6.bn.weight', 'encoder.layers.6.bn.bias', 'encoder.layers.6.bn.running_mean', 'encoder.layers.6.bn.running_var', 'encoder.layers.6.bn.num_batches_tracked', 'encoder.layers.7.conv3x1_1.weight', 'encoder.layers.7.conv3x1_1.bias', 'encoder.layers.7.conv1x3_1.weight', 'encoder.layers.7.conv1x3_1.bias', 'encoder.layers.7.bn1.weight', 'encoder.layers.7.bn1.bias', 'encoder.layers.7.bn1.running_mean', 'encoder.layers.7.bn1.running_var', 'encoder.layers.7.bn1.num_batches_tracked', 'encoder.layers.7.conv3x1_2.weight', 'encoder.layers.7.conv3x1_2.bias', 'encoder.layers.7.conv1x3_2.weight', 'encoder.layers.7.conv1x3_2.bias', 'encoder.layers.7.bn2.weight', 'encoder.layers.7.bn2.bias', 'encoder.layers.7.bn2.running_mean', 'encoder.layers.7.bn2.running_var', 'encoder.layers.7.bn2.num_batches_tracked', 'encoder.layers.8.conv3x1_1.weight', 'encoder.layers.8.conv3x1_1.bias', 'encoder.layers.8.conv1x3_1.weight', 'encoder.layers.8.conv1x3_1.bias', 'encoder.layers.8.bn1.weight', 'encoder.layers.8.bn1.bias', 'encoder.layers.8.bn1.running_mean', 'encoder.layers.8.bn1.running_var', 'encoder.layers.8.bn1.num_batches_tracked', 'encoder.layers.8.conv3x1_2.weight', 'encoder.layers.8.conv3x1_2.bias', 'encoder.layers.8.conv1x3_2.weight', 'encoder.layers.8.conv1x3_2.bias', 'encoder.layers.8.bn2.weight', 'encoder.layers.8.bn2.bias', 'encoder.layers.8.bn2.running_mean', 'encoder.layers.8.bn2.running_var', 'encoder.layers.8.bn2.num_batches_tracked', 'encoder.layers.9.conv3x1_1.weight', 'encoder.layers.9.conv3x1_1.bias', 'encoder.layers.9.conv1x3_1.weight', 'encoder.layers.9.conv1x3_1.bias', 'encoder.layers.9.bn1.weight', 'encoder.layers.9.bn1.bias', 'encoder.layers.9.bn1.running_mean', 'encoder.layers.9.bn1.running_var', 'encoder.layers.9.bn1.num_batches_tracked', 'encoder.layers.9.conv3x1_2.weight', 'encoder.layers.9.conv3x1_2.bias', 'encoder.layers.9.conv1x3_2.weight', 'encoder.layers.9.conv1x3_2.bias', 'encoder.layers.9.bn2.weight', 'encoder.layers.9.bn2.bias', 'encoder.layers.9.bn2.running_mean', 'encoder.layers.9.bn2.running_var', 'encoder.layers.9.bn2.num_batches_tracked', 'encoder.layers.10.conv3x1_1.weight', 'encoder.layers.10.conv3x1_1.bias', 'encoder.layers.10.conv1x3_1.weight', 'encoder.layers.10.conv1x3_1.bias', 'encoder.layers.10.bn1.weight', 'encoder.layers.10.bn1.bias', 'encoder.layers.10.bn1.running_mean', 'encoder.layers.10.bn1.running_var', 'encoder.layers.10.bn1.num_batches_tracked', 'encoder.layers.10.conv3x1_2.weight', 'encoder.layers.10.conv3x1_2.bias', 'encoder.layers.10.conv1x3_2.weight', 'encoder.layers.10.conv1x3_2.bias', 'encoder.layers.10.bn2.weight', 'encoder.layers.10.bn2.bias', 'encoder.layers.10.bn2.running_mean', 'encoder.layers.10.bn2.running_var', 'encoder.layers.10.bn2.num_batches_tracked', 'encoder.layers.11.conv3x1_1.weight', 'encoder.layers.11.conv3x1_1.bias', 'encoder.layers.11.conv1x3_1.weight', 'encoder.layers.11.conv1x3_1.bias', 'encoder.layers.11.bn1.weight', 'encoder.layers.11.bn1.bias', 'encoder.layers.11.bn1.running_mean', 'encoder.layers.11.bn1.running_var', 'encoder.layers.11.bn1.num_batches_tracked', 'encoder.layers.11.conv3x1_2.weight', 'encoder.layers.11.conv3x1_2.bias', 'encoder.layers.11.conv1x3_2.weight', 'encoder.layers.11.conv1x3_2.bias', 'encoder.layers.11.bn2.weight', 'encoder.layers.11.bn2.bias', 'encoder.layers.11.bn2.running_mean', 'encoder.layers.11.bn2.running_var', 'encoder.layers.11.bn2.num_batches_tracked', 'encoder.layers.12.conv3x1_1.weight', 'encoder.layers.12.conv3x1_1.bias', 'encoder.layers.12.conv1x3_1.weight', 'encoder.layers.12.conv1x3_1.bias', 'encoder.layers.12.bn1.weight', 'encoder.layers.12.bn1.bias', 'encoder.layers.12.bn1.running_mean', 'encoder.layers.12.bn1.running_var', 'encoder.layers.12.bn1.num_batches_tracked', 'encoder.layers.12.conv3x1_2.weight', 'encoder.layers.12.conv3x1_2.bias', 'encoder.layers.12.conv1x3_2.weight', 'encoder.layers.12.conv1x3_2.bias', 'encoder.layers.12.bn2.weight', 'encoder.layers.12.bn2.bias', 'encoder.layers.12.bn2.running_mean', 'encoder.layers.12.bn2.running_var', 'encoder.layers.12.bn2.num_batches_tracked', 'encoder.layers.13.conv3x1_1.weight', 'encoder.layers.13.conv3x1_1.bias', 'encoder.layers.13.conv1x3_1.weight', 'encoder.layers.13.conv1x3_1.bias', 'encoder.layers.13.bn1.weight', 'encoder.layers.13.bn1.bias', 'encoder.layers.13.bn1.running_mean', 'encoder.layers.13.bn1.running_var', 'encoder.layers.13.bn1.num_batches_tracked', 'encoder.layers.13.conv3x1_2.weight', 'encoder.layers.13.conv3x1_2.bias', 'encoder.layers.13.conv1x3_2.weight', 'encoder.layers.13.conv1x3_2.bias', 'encoder.layers.13.bn2.weight', 'encoder.layers.13.bn2.bias', 'encoder.layers.13.bn2.running_mean', 'encoder.layers.13.bn2.running_var', 'encoder.layers.13.bn2.num_batches_tracked', 'encoder.layers.14.conv3x1_1.weight', 'encoder.layers.14.conv3x1_1.bias', 'encoder.layers.14.conv1x3_1.weight', 'encoder.layers.14.conv1x3_1.bias', 'encoder.layers.14.bn1.weight', 'encoder.layers.14.bn1.bias', 'encoder.layers.14.bn1.running_mean', 'encoder.layers.14.bn1.running_var', 'encoder.layers.14.bn1.num_batches_tracked', 'encoder.layers.14.conv3x1_2.weight', 'encoder.layers.14.conv3x1_2.bias', 'encoder.layers.14.conv1x3_2.weight', 'encoder.layers.14.conv1x3_2.bias', 'encoder.layers.14.bn2.weight', 'encoder.layers.14.bn2.bias', 'encoder.layers.14.bn2.running_mean', 'encoder.layers.14.bn2.running_var', 'encoder.layers.14.bn2.num_batches_tracked', 'encoder.output_conv.weight', 'encoder.output_conv.bias', 'decoder.layers.0.conv.weight', 'decoder.layers.0.conv.bias', 'decoder.layers.0.bn.weight', 'decoder.layers.0.bn.bias', 'decoder.layers.0.bn.running_mean', 'decoder.layers.0.bn.running_var', 'decoder.layers.0.bn.num_batches_tracked', 'decoder.layers.1.conv3x1_1.weight', 'decoder.layers.1.conv3x1_1.bias', 'decoder.layers.1.conv1x3_1.weight', 'decoder.layers.1.conv1x3_1.bias', 'decoder.layers.1.bn1.weight', 'decoder.layers.1.bn1.bias', 'decoder.layers.1.bn1.running_mean', 'decoder.layers.1.bn1.running_var', 'decoder.layers.1.bn1.num_batches_tracked', 'decoder.layers.1.conv3x1_2.weight', 'decoder.layers.1.conv3x1_2.bias', 'decoder.layers.1.conv1x3_2.weight', 'decoder.layers.1.conv1x3_2.bias', 'decoder.layers.1.bn2.weight', 'decoder.layers.1.bn2.bias', 'decoder.layers.1.bn2.running_mean', 'decoder.layers.1.bn2.running_var', 'decoder.layers.1.bn2.num_batches_tracked', 'decoder.layers.2.conv3x1_1.weight', 'decoder.layers.2.conv3x1_1.bias', 'decoder.layers.2.conv1x3_1.weight', 'decoder.layers.2.conv1x3_1.bias', 'decoder.layers.2.bn1.weight', 'decoder.layers.2.bn1.bias', 'decoder.layers.2.bn1.running_mean', 'decoder.layers.2.bn1.running_var', 'decoder.layers.2.bn1.num_batches_tracked', 'decoder.layers.2.conv3x1_2.weight', 'decoder.layers.2.conv3x1_2.bias', 'decoder.layers.2.conv1x3_2.weight', 'decoder.layers.2.conv1x3_2.bias', 'decoder.layers.2.bn2.weight', 'decoder.layers.2.bn2.bias', 'decoder.layers.2.bn2.running_mean', 'decoder.layers.2.bn2.running_var', 'decoder.layers.2.bn2.num_batches_tracked', 'decoder.layers.3.conv.weight', 'decoder.layers.3.conv.bias', 'decoder.layers.3.bn.weight', 'decoder.layers.3.bn.bias', 'decoder.layers.3.bn.running_mean', 'decoder.layers.3.bn.running_var', 'decoder.layers.3.bn.num_batches_tracked', 'decoder.layers.4.conv3x1_1.weight', 'decoder.layers.4.conv3x1_1.bias', 'decoder.layers.4.conv1x3_1.weight', 'decoder.layers.4.conv1x3_1.bias', 'decoder.layers.4.bn1.weight', 'decoder.layers.4.bn1.bias', 'decoder.layers.4.bn1.running_mean', 'decoder.layers.4.bn1.running_var', 'decoder.layers.4.bn1.num_batches_tracked', 'decoder.layers.4.conv3x1_2.weight', 'decoder.layers.4.conv3x1_2.bias', 'decoder.layers.4.conv1x3_2.weight', 'decoder.layers.4.conv1x3_2.bias', 'decoder.layers.4.bn2.weight', 'decoder.layers.4.bn2.bias', 'decoder.layers.4.bn2.running_mean', 'decoder.layers.4.bn2.running_var', 'decoder.layers.4.bn2.num_batches_tracked', 'decoder.layers.5.conv3x1_1.weight', 'decoder.layers.5.conv3x1_1.bias', 'decoder.layers.5.conv1x3_1.weight', 'decoder.layers.5.conv1x3_1.bias', 'decoder.layers.5.bn1.weight', 'decoder.layers.5.bn1.bias', 'decoder.layers.5.bn1.running_mean', 'decoder.layers.5.bn1.running_var', 'decoder.layers.5.bn1.num_batches_tracked', 'decoder.layers.5.conv3x1_2.weight', 'decoder.layers.5.conv3x1_2.bias', 'decoder.layers.5.conv1x3_2.weight', 'decoder.layers.5.conv1x3_2.bias', 'decoder.layers.5.bn2.weight', 'decoder.layers.5.bn2.bias', 'decoder.layers.5.bn2.running_mean', 'decoder.layers.5.bn2.running_var', 'decoder.layers.5.bn2.num_batches_tracked', 'decoder.output_conv.weight', 'decoder.output_conv.bias'])\n",
            "Import Model erfnet with weights erfnet_pretrained.pth to FineTune\n",
            "========== TRAINING ===========\n",
            "/content/cityscapes/leftImg8bit/train\n",
            "/content/cityscapes/leftImg8bit/val\n",
            "----- TRAINING - EPOCH 1 -----\n",
            "LEARNING RATE:  5e-05\n",
            "loss: 2.943 (epoch: 1, step: 0) // Avg time/img: 0.5878 s\n",
            "loss: 2.941 (epoch: 1, step: 50) // Avg time/img: 0.0579 s\n",
            "loss: 2.941 (epoch: 1, step: 100) // Avg time/img: 0.0531 s\n",
            "loss: 2.94 (epoch: 1, step: 150) // Avg time/img: 0.0511 s\n",
            "loss: 2.94 (epoch: 1, step: 200) // Avg time/img: 0.0504 s\n",
            "loss: 2.94 (epoch: 1, step: 250) // Avg time/img: 0.0499 s\n",
            "loss: 2.94 (epoch: 1, step: 300) // Avg time/img: 0.0497 s\n",
            "loss: 2.94 (epoch: 1, step: 350) // Avg time/img: 0.0495 s\n",
            "loss: 2.94 (epoch: 1, step: 400) // Avg time/img: 0.0493 s\n",
            "loss: 2.94 (epoch: 1, step: 450) // Avg time/img: 0.0492 s\n",
            "----- VALIDATING - EPOCH 1 -----\n",
            "VAL loss: 2.942 (epoch: 1, step: 0) // Avg time/img: 0.0528 s\n",
            "VAL loss: 2.942 (epoch: 1, step: 50) // Avg time/img: 0.0350 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m71.89\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/erfnet_training_logitnorm_loss/model-001.pth (epoch: 1)\n",
            "save: ../save/erfnet_training_logitnorm_loss/model_best.pth (epoch: 1)\n",
            "----- TRAINING - EPOCH 2 -----\n",
            "LEARNING RATE:  4.774426908107499e-05\n",
            "loss: 2.939 (epoch: 2, step: 0) // Avg time/img: 0.0562 s\n",
            "loss: 2.939 (epoch: 2, step: 50) // Avg time/img: 0.0482 s\n",
            "loss: 2.939 (epoch: 2, step: 100) // Avg time/img: 0.0481 s\n",
            "loss: 2.939 (epoch: 2, step: 150) // Avg time/img: 0.0481 s\n",
            "loss: 2.939 (epoch: 2, step: 200) // Avg time/img: 0.0482 s\n",
            "loss: 2.939 (epoch: 2, step: 250) // Avg time/img: 0.0482 s\n",
            "loss: 2.939 (epoch: 2, step: 300) // Avg time/img: 0.0482 s\n",
            "loss: 2.939 (epoch: 2, step: 350) // Avg time/img: 0.0482 s\n",
            "loss: 2.939 (epoch: 2, step: 400) // Avg time/img: 0.0483 s\n",
            "loss: 2.939 (epoch: 2, step: 450) // Avg time/img: 0.0483 s\n",
            "----- VALIDATING - EPOCH 2 -----\n",
            "VAL loss: 2.941 (epoch: 2, step: 0) // Avg time/img: 0.0516 s\n",
            "VAL loss: 2.941 (epoch: 2, step: 50) // Avg time/img: 0.0347 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m71.45\u001b[0m %\n",
            "save: ../save/erfnet_training_logitnorm_loss/model-002.pth (epoch: 2)\n",
            "----- TRAINING - EPOCH 3 -----\n",
            "LEARNING RATE:  4.547662880414811e-05\n",
            "loss: 2.938 (epoch: 3, step: 0) // Avg time/img: 0.0529 s\n",
            "loss: 2.939 (epoch: 3, step: 50) // Avg time/img: 0.0479 s\n",
            "loss: 2.939 (epoch: 3, step: 100) // Avg time/img: 0.0482 s\n",
            "loss: 2.939 (epoch: 3, step: 150) // Avg time/img: 0.0483 s\n",
            "loss: 2.939 (epoch: 3, step: 200) // Avg time/img: 0.0482 s\n",
            "loss: 2.939 (epoch: 3, step: 250) // Avg time/img: 0.0482 s\n",
            "loss: 2.939 (epoch: 3, step: 300) // Avg time/img: 0.0484 s\n",
            "loss: 2.939 (epoch: 3, step: 350) // Avg time/img: 0.0484 s\n",
            "loss: 2.939 (epoch: 3, step: 400) // Avg time/img: 0.0484 s\n",
            "loss: 2.939 (epoch: 3, step: 450) // Avg time/img: 0.0484 s\n",
            "----- VALIDATING - EPOCH 3 -----\n",
            "VAL loss: 2.941 (epoch: 3, step: 0) // Avg time/img: 0.0498 s\n",
            "VAL loss: 2.941 (epoch: 3, step: 50) // Avg time/img: 0.0348 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m71.09\u001b[0m %\n",
            "save: ../save/erfnet_training_logitnorm_loss/model-003.pth (epoch: 3)\n",
            "----- TRAINING - EPOCH 4 -----\n",
            "LEARNING RATE:  4.319634861514096e-05\n",
            "loss: 2.937 (epoch: 4, step: 0) // Avg time/img: 0.0561 s\n",
            "loss: 2.939 (epoch: 4, step: 50) // Avg time/img: 0.0480 s\n",
            "loss: 2.939 (epoch: 4, step: 100) // Avg time/img: 0.0483 s\n",
            "loss: 2.938 (epoch: 4, step: 150) // Avg time/img: 0.0483 s\n",
            "loss: 2.938 (epoch: 4, step: 200) // Avg time/img: 0.0484 s\n",
            "loss: 2.938 (epoch: 4, step: 250) // Avg time/img: 0.0483 s\n",
            "loss: 2.938 (epoch: 4, step: 300) // Avg time/img: 0.0484 s\n",
            "loss: 2.938 (epoch: 4, step: 350) // Avg time/img: 0.0484 s\n",
            "loss: 2.938 (epoch: 4, step: 400) // Avg time/img: 0.0485 s\n",
            "loss: 2.938 (epoch: 4, step: 450) // Avg time/img: 0.0484 s\n",
            "----- VALIDATING - EPOCH 4 -----\n",
            "VAL loss: 2.94 (epoch: 4, step: 0) // Avg time/img: 0.0491 s\n",
            "VAL loss: 2.941 (epoch: 4, step: 50) // Avg time/img: 0.0353 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m70.79\u001b[0m %\n",
            "save: ../save/erfnet_training_logitnorm_loss/model-004.pth (epoch: 4)\n",
            "----- TRAINING - EPOCH 5 -----\n",
            "LEARNING RATE:  4.090260730254292e-05\n",
            "loss: 2.936 (epoch: 5, step: 0) // Avg time/img: 0.0573 s\n",
            "loss: 2.938 (epoch: 5, step: 50) // Avg time/img: 0.0487 s\n",
            "loss: 2.938 (epoch: 5, step: 100) // Avg time/img: 0.0486 s\n",
            "loss: 2.938 (epoch: 5, step: 150) // Avg time/img: 0.0483 s\n",
            "loss: 2.938 (epoch: 5, step: 200) // Avg time/img: 0.0484 s\n",
            "loss: 2.938 (epoch: 5, step: 250) // Avg time/img: 0.0483 s\n",
            "loss: 2.938 (epoch: 5, step: 300) // Avg time/img: 0.0483 s\n",
            "loss: 2.938 (epoch: 5, step: 350) // Avg time/img: 0.0482 s\n",
            "loss: 2.938 (epoch: 5, step: 400) // Avg time/img: 0.0483 s\n",
            "loss: 2.938 (epoch: 5, step: 450) // Avg time/img: 0.0483 s\n",
            "----- VALIDATING - EPOCH 5 -----\n",
            "VAL loss: 2.94 (epoch: 5, step: 0) // Avg time/img: 0.0586 s\n",
            "VAL loss: 2.94 (epoch: 5, step: 50) // Avg time/img: 0.0349 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m70.43\u001b[0m %\n",
            "save: ../save/erfnet_training_logitnorm_loss/model-005.pth (epoch: 5)\n",
            "----- TRAINING - EPOCH 6 -----\n",
            "LEARNING RATE:  3.859447533617852e-05\n",
            "loss: 2.936 (epoch: 6, step: 0) // Avg time/img: 0.0538 s\n",
            "loss: 2.937 (epoch: 6, step: 50) // Avg time/img: 0.0481 s\n",
            "loss: 2.937 (epoch: 6, step: 100) // Avg time/img: 0.0483 s\n",
            "loss: 2.937 (epoch: 6, step: 150) // Avg time/img: 0.0481 s\n",
            "loss: 2.937 (epoch: 6, step: 200) // Avg time/img: 0.0483 s\n",
            "loss: 2.937 (epoch: 6, step: 250) // Avg time/img: 0.0484 s\n",
            "loss: 2.937 (epoch: 6, step: 300) // Avg time/img: 0.0484 s\n",
            "loss: 2.937 (epoch: 6, step: 350) // Avg time/img: 0.0484 s\n",
            "loss: 2.937 (epoch: 6, step: 400) // Avg time/img: 0.0485 s\n",
            "loss: 2.937 (epoch: 6, step: 450) // Avg time/img: 0.0484 s\n",
            "----- VALIDATING - EPOCH 6 -----\n",
            "VAL loss: 2.938 (epoch: 6, step: 0) // Avg time/img: 0.0527 s\n",
            "VAL loss: 2.938 (epoch: 6, step: 50) // Avg time/img: 0.0349 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m69.99\u001b[0m %\n",
            "save: ../save/erfnet_training_logitnorm_loss/model-006.pth (epoch: 6)\n",
            "----- TRAINING - EPOCH 7 -----\n",
            "LEARNING RATE:  3.6270892346861e-05\n",
            "loss: 2.941 (epoch: 7, step: 0) // Avg time/img: 0.0559 s\n",
            "loss: 2.936 (epoch: 7, step: 50) // Avg time/img: 0.0482 s\n",
            "loss: 2.936 (epoch: 7, step: 100) // Avg time/img: 0.0483 s\n",
            "loss: 2.936 (epoch: 7, step: 150) // Avg time/img: 0.0481 s\n",
            "loss: 2.936 (epoch: 7, step: 200) // Avg time/img: 0.0482 s\n",
            "loss: 2.936 (epoch: 7, step: 250) // Avg time/img: 0.0482 s\n",
            "loss: 2.936 (epoch: 7, step: 300) // Avg time/img: 0.0482 s\n",
            "loss: 2.936 (epoch: 7, step: 350) // Avg time/img: 0.0483 s\n",
            "loss: 2.936 (epoch: 7, step: 400) // Avg time/img: 0.0483 s\n",
            "loss: 2.936 (epoch: 7, step: 450) // Avg time/img: 0.0483 s\n",
            "----- VALIDATING - EPOCH 7 -----\n",
            "VAL loss: 2.937 (epoch: 7, step: 0) // Avg time/img: 0.0477 s\n",
            "VAL loss: 2.937 (epoch: 7, step: 50) // Avg time/img: 0.0350 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m68.32\u001b[0m %\n",
            "save: ../save/erfnet_training_logitnorm_loss/model-007.pth (epoch: 7)\n",
            "----- TRAINING - EPOCH 8 -----\n",
            "LEARNING RATE:  3.393063796290625e-05\n",
            "loss: 2.934 (epoch: 8, step: 0) // Avg time/img: 0.0588 s\n",
            "loss: 2.935 (epoch: 8, step: 50) // Avg time/img: 0.0483 s\n",
            "loss: 2.935 (epoch: 8, step: 100) // Avg time/img: 0.0483 s\n",
            "loss: 2.935 (epoch: 8, step: 150) // Avg time/img: 0.0483 s\n",
            "loss: 2.935 (epoch: 8, step: 200) // Avg time/img: 0.0483 s\n",
            "loss: 2.935 (epoch: 8, step: 250) // Avg time/img: 0.0481 s\n",
            "loss: 2.935 (epoch: 8, step: 300) // Avg time/img: 0.0482 s\n",
            "loss: 2.935 (epoch: 8, step: 350) // Avg time/img: 0.0481 s\n",
            "loss: 2.935 (epoch: 8, step: 400) // Avg time/img: 0.0482 s\n",
            "loss: 2.935 (epoch: 8, step: 450) // Avg time/img: 0.0483 s\n",
            "----- VALIDATING - EPOCH 8 -----\n",
            "VAL loss: 2.936 (epoch: 8, step: 0) // Avg time/img: 0.0540 s\n",
            "VAL loss: 2.936 (epoch: 8, step: 50) // Avg time/img: 0.0348 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m66.61\u001b[0m %\n",
            "save: ../save/erfnet_training_logitnorm_loss/model-008.pth (epoch: 8)\n",
            "----- TRAINING - EPOCH 9 -----\n",
            "LEARNING RATE:  3.157229337446777e-05\n",
            "loss: 2.934 (epoch: 9, step: 0) // Avg time/img: 0.0593 s\n",
            "loss: 2.934 (epoch: 9, step: 50) // Avg time/img: 0.0481 s\n",
            "loss: 2.934 (epoch: 9, step: 100) // Avg time/img: 0.0477 s\n",
            "loss: 2.934 (epoch: 9, step: 150) // Avg time/img: 0.0479 s\n",
            "loss: 2.934 (epoch: 9, step: 200) // Avg time/img: 0.0479 s\n",
            "loss: 2.934 (epoch: 9, step: 250) // Avg time/img: 0.0480 s\n",
            "loss: 2.934 (epoch: 9, step: 300) // Avg time/img: 0.0480 s\n",
            "loss: 2.934 (epoch: 9, step: 350) // Avg time/img: 0.0481 s\n",
            "loss: 2.934 (epoch: 9, step: 400) // Avg time/img: 0.0481 s\n",
            "loss: 2.934 (epoch: 9, step: 450) // Avg time/img: 0.0482 s\n",
            "----- VALIDATING - EPOCH 9 -----\n",
            "VAL loss: 2.936 (epoch: 9, step: 0) // Avg time/img: 0.0495 s\n",
            "VAL loss: 2.935 (epoch: 9, step: 50) // Avg time/img: 0.0345 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m66.23\u001b[0m %\n",
            "save: ../save/erfnet_training_logitnorm_loss/model-009.pth (epoch: 9)\n",
            "----- TRAINING - EPOCH 10 -----\n",
            "LEARNING RATE:  2.9194189645999014e-05\n",
            "loss: 2.936 (epoch: 10, step: 0) // Avg time/img: 0.0536 s\n",
            "loss: 2.934 (epoch: 10, step: 50) // Avg time/img: 0.0483 s\n",
            "loss: 2.934 (epoch: 10, step: 100) // Avg time/img: 0.0482 s\n",
            "loss: 2.934 (epoch: 10, step: 150) // Avg time/img: 0.0481 s\n",
            "loss: 2.934 (epoch: 10, step: 200) // Avg time/img: 0.0480 s\n",
            "loss: 2.934 (epoch: 10, step: 250) // Avg time/img: 0.0480 s\n",
            "loss: 2.934 (epoch: 10, step: 300) // Avg time/img: 0.0480 s\n",
            "loss: 2.934 (epoch: 10, step: 350) // Avg time/img: 0.0480 s\n",
            "loss: 2.934 (epoch: 10, step: 400) // Avg time/img: 0.0481 s\n",
            "loss: 2.934 (epoch: 10, step: 450) // Avg time/img: 0.0481 s\n",
            "----- VALIDATING - EPOCH 10 -----\n",
            "VAL loss: 2.935 (epoch: 10, step: 0) // Avg time/img: 0.0509 s\n",
            "VAL loss: 2.935 (epoch: 10, step: 50) // Avg time/img: 0.0347 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m66.97\u001b[0m %\n",
            "save: ../save/erfnet_training_logitnorm_loss/model-010.pth (epoch: 10)\n",
            "----- TRAINING - EPOCH 11 -----\n",
            "LEARNING RATE:  2.679433656340733e-05\n",
            "loss: 2.932 (epoch: 11, step: 0) // Avg time/img: 0.0583 s\n",
            "loss: 2.934 (epoch: 11, step: 50) // Avg time/img: 0.0480 s\n",
            "loss: 2.934 (epoch: 11, step: 100) // Avg time/img: 0.0482 s\n",
            "loss: 2.934 (epoch: 11, step: 150) // Avg time/img: 0.0481 s\n",
            "loss: 2.934 (epoch: 11, step: 200) // Avg time/img: 0.0480 s\n",
            "loss: 2.934 (epoch: 11, step: 250) // Avg time/img: 0.0480 s\n",
            "loss: 2.933 (epoch: 11, step: 300) // Avg time/img: 0.0480 s\n",
            "loss: 2.933 (epoch: 11, step: 350) // Avg time/img: 0.0480 s\n",
            "loss: 2.933 (epoch: 11, step: 400) // Avg time/img: 0.0481 s\n",
            "loss: 2.933 (epoch: 11, step: 450) // Avg time/img: 0.0481 s\n",
            "----- VALIDATING - EPOCH 11 -----\n",
            "VAL loss: 2.935 (epoch: 11, step: 0) // Avg time/img: 0.0541 s\n",
            "VAL loss: 2.935 (epoch: 11, step: 50) // Avg time/img: 0.0351 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m67.43\u001b[0m %\n",
            "save: ../save/erfnet_training_logitnorm_loss/model-011.pth (epoch: 11)\n",
            "----- TRAINING - EPOCH 12 -----\n",
            "LEARNING RATE:  2.437032195894977e-05\n",
            "loss: 2.936 (epoch: 12, step: 0) // Avg time/img: 0.0631 s\n",
            "loss: 2.933 (epoch: 12, step: 50) // Avg time/img: 0.0482 s\n",
            "loss: 2.933 (epoch: 12, step: 100) // Avg time/img: 0.0478 s\n",
            "loss: 2.933 (epoch: 12, step: 150) // Avg time/img: 0.0480 s\n",
            "loss: 2.933 (epoch: 12, step: 200) // Avg time/img: 0.0479 s\n",
            "loss: 2.933 (epoch: 12, step: 250) // Avg time/img: 0.0482 s\n",
            "loss: 2.933 (epoch: 12, step: 300) // Avg time/img: 0.0482 s\n",
            "loss: 2.933 (epoch: 12, step: 350) // Avg time/img: 0.0482 s\n",
            "loss: 2.933 (epoch: 12, step: 400) // Avg time/img: 0.0482 s\n",
            "loss: 2.933 (epoch: 12, step: 450) // Avg time/img: 0.0483 s\n",
            "----- VALIDATING - EPOCH 12 -----\n",
            "VAL loss: 2.935 (epoch: 12, step: 0) // Avg time/img: 0.0455 s\n",
            "VAL loss: 2.934 (epoch: 12, step: 50) // Avg time/img: 0.0343 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m67.54\u001b[0m %\n",
            "save: ../save/erfnet_training_logitnorm_loss/model-012.pth (epoch: 12)\n",
            "----- TRAINING - EPOCH 13 -----\n",
            "LEARNING RATE:  2.191916452770435e-05\n",
            "loss: 2.934 (epoch: 13, step: 0) // Avg time/img: 0.0551 s\n",
            "loss: 2.933 (epoch: 13, step: 50) // Avg time/img: 0.0481 s\n",
            "loss: 2.933 (epoch: 13, step: 100) // Avg time/img: 0.0480 s\n",
            "loss: 2.933 (epoch: 13, step: 150) // Avg time/img: 0.0481 s\n",
            "loss: 2.933 (epoch: 13, step: 200) // Avg time/img: 0.0481 s\n",
            "loss: 2.933 (epoch: 13, step: 250) // Avg time/img: 0.0482 s\n",
            "loss: 2.933 (epoch: 13, step: 300) // Avg time/img: 0.0484 s\n",
            "loss: 2.933 (epoch: 13, step: 350) // Avg time/img: 0.0483 s\n",
            "loss: 2.933 (epoch: 13, step: 400) // Avg time/img: 0.0483 s\n",
            "loss: 2.933 (epoch: 13, step: 450) // Avg time/img: 0.0483 s\n",
            "----- VALIDATING - EPOCH 13 -----\n",
            "VAL loss: 2.935 (epoch: 13, step: 0) // Avg time/img: 0.0462 s\n",
            "VAL loss: 2.934 (epoch: 13, step: 50) // Avg time/img: 0.0349 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m67.58\u001b[0m %\n",
            "save: ../save/erfnet_training_logitnorm_loss/model-013.pth (epoch: 13)\n",
            "----- TRAINING - EPOCH 14 -----\n",
            "LEARNING RATE:  1.9437089939938174e-05\n",
            "loss: 2.934 (epoch: 14, step: 0) // Avg time/img: 0.0531 s\n",
            "loss: 2.933 (epoch: 14, step: 50) // Avg time/img: 0.0481 s\n",
            "loss: 2.933 (epoch: 14, step: 100) // Avg time/img: 0.0481 s\n",
            "loss: 2.933 (epoch: 14, step: 150) // Avg time/img: 0.0480 s\n",
            "loss: 2.933 (epoch: 14, step: 200) // Avg time/img: 0.0481 s\n",
            "loss: 2.933 (epoch: 14, step: 250) // Avg time/img: 0.0480 s\n",
            "loss: 2.933 (epoch: 14, step: 300) // Avg time/img: 0.0482 s\n",
            "loss: 2.933 (epoch: 14, step: 350) // Avg time/img: 0.0482 s\n",
            "loss: 2.933 (epoch: 14, step: 400) // Avg time/img: 0.0483 s\n",
            "loss: 2.933 (epoch: 14, step: 450) // Avg time/img: 0.0483 s\n",
            "----- VALIDATING - EPOCH 14 -----\n",
            "VAL loss: 2.935 (epoch: 14, step: 0) // Avg time/img: 0.0597 s\n",
            "VAL loss: 2.934 (epoch: 14, step: 50) // Avg time/img: 0.0353 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m67.08\u001b[0m %\n",
            "save: ../save/erfnet_training_logitnorm_loss/model-014.pth (epoch: 14)\n",
            "----- TRAINING - EPOCH 15 -----\n",
            "LEARNING RATE:  1.6919173095082493e-05\n",
            "loss: 2.932 (epoch: 15, step: 0) // Avg time/img: 0.0593 s\n",
            "loss: 2.933 (epoch: 15, step: 50) // Avg time/img: 0.0480 s\n",
            "loss: 2.933 (epoch: 15, step: 100) // Avg time/img: 0.0481 s\n",
            "loss: 2.933 (epoch: 15, step: 150) // Avg time/img: 0.0481 s\n",
            "loss: 2.933 (epoch: 15, step: 200) // Avg time/img: 0.0480 s\n",
            "loss: 2.933 (epoch: 15, step: 250) // Avg time/img: 0.0482 s\n",
            "loss: 2.933 (epoch: 15, step: 300) // Avg time/img: 0.0480 s\n",
            "loss: 2.933 (epoch: 15, step: 350) // Avg time/img: 0.0480 s\n",
            "loss: 2.933 (epoch: 15, step: 400) // Avg time/img: 0.0480 s\n",
            "loss: 2.933 (epoch: 15, step: 450) // Avg time/img: 0.0480 s\n",
            "----- VALIDATING - EPOCH 15 -----\n",
            "VAL loss: 2.935 (epoch: 15, step: 0) // Avg time/img: 0.0449 s\n",
            "VAL loss: 2.934 (epoch: 15, step: 50) // Avg time/img: 0.0348 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m67.39\u001b[0m %\n",
            "save: ../save/erfnet_training_logitnorm_loss/model-015.pth (epoch: 15)\n",
            "----- TRAINING - EPOCH 16 -----\n",
            "LEARNING RATE:  1.4358729437462937e-05\n",
            "loss: 2.936 (epoch: 16, step: 0) // Avg time/img: 0.0550 s\n",
            "loss: 2.933 (epoch: 16, step: 50) // Avg time/img: 0.0487 s\n",
            "loss: 2.933 (epoch: 16, step: 100) // Avg time/img: 0.0481 s\n",
            "loss: 2.933 (epoch: 16, step: 150) // Avg time/img: 0.0482 s\n",
            "loss: 2.933 (epoch: 16, step: 200) // Avg time/img: 0.0482 s\n",
            "loss: 2.933 (epoch: 16, step: 250) // Avg time/img: 0.0480 s\n",
            "loss: 2.933 (epoch: 16, step: 300) // Avg time/img: 0.0481 s\n",
            "loss: 2.933 (epoch: 16, step: 350) // Avg time/img: 0.0481 s\n",
            "loss: 2.933 (epoch: 16, step: 400) // Avg time/img: 0.0482 s\n",
            "loss: 2.933 (epoch: 16, step: 450) // Avg time/img: 0.0482 s\n",
            "----- VALIDATING - EPOCH 16 -----\n",
            "VAL loss: 2.935 (epoch: 16, step: 0) // Avg time/img: 0.0522 s\n",
            "VAL loss: 2.934 (epoch: 16, step: 50) // Avg time/img: 0.0349 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m67.19\u001b[0m %\n",
            "save: ../save/erfnet_training_logitnorm_loss/model-016.pth (epoch: 16)\n",
            "----- TRAINING - EPOCH 17 -----\n",
            "LEARNING RATE:  1.1746189430880188e-05\n",
            "loss: 2.933 (epoch: 17, step: 0) // Avg time/img: 0.0562 s\n",
            "loss: 2.933 (epoch: 17, step: 50) // Avg time/img: 0.0483 s\n",
            "loss: 2.933 (epoch: 17, step: 100) // Avg time/img: 0.0485 s\n",
            "loss: 2.933 (epoch: 17, step: 150) // Avg time/img: 0.0482 s\n",
            "loss: 2.933 (epoch: 17, step: 200) // Avg time/img: 0.0483 s\n",
            "loss: 2.933 (epoch: 17, step: 250) // Avg time/img: 0.0483 s\n",
            "loss: 2.933 (epoch: 17, step: 300) // Avg time/img: 0.0482 s\n",
            "loss: 2.933 (epoch: 17, step: 350) // Avg time/img: 0.0483 s\n",
            "loss: 2.933 (epoch: 17, step: 400) // Avg time/img: 0.0483 s\n",
            "loss: 2.933 (epoch: 17, step: 450) // Avg time/img: 0.0484 s\n",
            "----- VALIDATING - EPOCH 17 -----\n",
            "VAL loss: 2.935 (epoch: 17, step: 0) // Avg time/img: 0.0493 s\n",
            "VAL loss: 2.934 (epoch: 17, step: 50) // Avg time/img: 0.0351 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m67.09\u001b[0m %\n",
            "save: ../save/erfnet_training_logitnorm_loss/model-017.pth (epoch: 17)\n",
            "----- TRAINING - EPOCH 18 -----\n",
            "LEARNING RATE:  9.066760365683729e-06\n",
            "loss: 2.934 (epoch: 18, step: 0) // Avg time/img: 0.0539 s\n",
            "loss: 2.933 (epoch: 18, step: 50) // Avg time/img: 0.0484 s\n",
            "loss: 2.933 (epoch: 18, step: 100) // Avg time/img: 0.0481 s\n",
            "loss: 2.933 (epoch: 18, step: 150) // Avg time/img: 0.0480 s\n",
            "loss: 2.933 (epoch: 18, step: 200) // Avg time/img: 0.0480 s\n",
            "loss: 2.933 (epoch: 18, step: 250) // Avg time/img: 0.0479 s\n",
            "loss: 2.933 (epoch: 18, step: 300) // Avg time/img: 0.0479 s\n",
            "loss: 2.933 (epoch: 18, step: 350) // Avg time/img: 0.0479 s\n",
            "loss: 2.933 (epoch: 18, step: 400) // Avg time/img: 0.0480 s\n",
            "loss: 2.933 (epoch: 18, step: 450) // Avg time/img: 0.0480 s\n",
            "----- VALIDATING - EPOCH 18 -----\n",
            "VAL loss: 2.935 (epoch: 18, step: 0) // Avg time/img: 0.0581 s\n",
            "VAL loss: 2.934 (epoch: 18, step: 50) // Avg time/img: 0.0354 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m67.11\u001b[0m %\n",
            "save: ../save/erfnet_training_logitnorm_loss/model-018.pth (epoch: 18)\n",
            "----- TRAINING - EPOCH 19 -----\n",
            "LEARNING RATE:  6.294627058970836e-06\n",
            "loss: 2.933 (epoch: 19, step: 0) // Avg time/img: 0.0576 s\n",
            "loss: 2.933 (epoch: 19, step: 50) // Avg time/img: 0.0476 s\n",
            "loss: 2.933 (epoch: 19, step: 100) // Avg time/img: 0.0477 s\n",
            "loss: 2.933 (epoch: 19, step: 150) // Avg time/img: 0.0475 s\n",
            "loss: 2.933 (epoch: 19, step: 200) // Avg time/img: 0.0476 s\n",
            "loss: 2.933 (epoch: 19, step: 250) // Avg time/img: 0.0478 s\n",
            "loss: 2.933 (epoch: 19, step: 300) // Avg time/img: 0.0479 s\n",
            "loss: 2.933 (epoch: 19, step: 350) // Avg time/img: 0.0479 s\n",
            "loss: 2.933 (epoch: 19, step: 400) // Avg time/img: 0.0479 s\n",
            "loss: 2.933 (epoch: 19, step: 450) // Avg time/img: 0.0480 s\n",
            "----- VALIDATING - EPOCH 19 -----\n",
            "VAL loss: 2.935 (epoch: 19, step: 0) // Avg time/img: 0.0482 s\n",
            "VAL loss: 2.934 (epoch: 19, step: 50) // Avg time/img: 0.0350 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m67.07\u001b[0m %\n",
            "save: ../save/erfnet_training_logitnorm_loss/model-019.pth (epoch: 19)\n",
            "----- TRAINING - EPOCH 20 -----\n",
            "LEARNING RATE:  3.373207119183911e-06\n",
            "loss: 2.932 (epoch: 20, step: 0) // Avg time/img: 0.0556 s\n",
            "loss: 2.933 (epoch: 20, step: 50) // Avg time/img: 0.0485 s\n",
            "loss: 2.933 (epoch: 20, step: 100) // Avg time/img: 0.0483 s\n",
            "loss: 2.933 (epoch: 20, step: 150) // Avg time/img: 0.0483 s\n",
            "loss: 2.933 (epoch: 20, step: 200) // Avg time/img: 0.0483 s\n",
            "loss: 2.933 (epoch: 20, step: 250) // Avg time/img: 0.0484 s\n",
            "loss: 2.933 (epoch: 20, step: 300) // Avg time/img: 0.0485 s\n",
            "loss: 2.933 (epoch: 20, step: 350) // Avg time/img: 0.0485 s\n",
            "loss: 2.933 (epoch: 20, step: 400) // Avg time/img: 0.0485 s\n",
            "loss: 2.933 (epoch: 20, step: 450) // Avg time/img: 0.0485 s\n",
            "----- VALIDATING - EPOCH 20 -----\n",
            "VAL loss: 2.935 (epoch: 20, step: 0) // Avg time/img: 0.0530 s\n",
            "VAL loss: 2.934 (epoch: 20, step: 50) // Avg time/img: 0.0346 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m66.89\u001b[0m %\n",
            "save: ../save/erfnet_training_logitnorm_loss/model-020.pth (epoch: 20)\n",
            "========== TRAINING FINISHED ===========\n",
            "Model saved in /content/AnomalySegmentation/save/erfnet_training_logitnorm_loss\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_logitnorm_loss/ (stored 0%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_logitnorm_loss/model_best.pth (deflated 10%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_logitnorm_loss/model-007.pth (deflated 10%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_logitnorm_loss/model-015.pth (deflated 10%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_logitnorm_loss/model-008.pth (deflated 10%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_logitnorm_loss/model-004.pth (deflated 10%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_logitnorm_loss/model-005.pth (deflated 10%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_logitnorm_loss/model-002.pth (deflated 10%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_logitnorm_loss/opts.txt (deflated 37%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_logitnorm_loss/model.txt (deflated 92%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_logitnorm_loss/model-014.pth (deflated 10%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_logitnorm_loss/model-013.pth (deflated 10%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_logitnorm_loss/model-012.pth (deflated 10%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_logitnorm_loss/model-016.pth (deflated 10%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_logitnorm_loss/model-011.pth (deflated 10%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_logitnorm_loss/checkpoint.pth.tar (deflated 10%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_logitnorm_loss/model-010.pth (deflated 10%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_logitnorm_loss/model-020.pth (deflated 10%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_logitnorm_loss/model_best.pth.tar (deflated 10%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_logitnorm_loss/model-009.pth (deflated 10%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_logitnorm_loss/model-003.pth (deflated 10%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_logitnorm_loss/model-006.pth (deflated 10%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_logitnorm_loss/automated_log.txt (deflated 69%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_logitnorm_loss/model-019.pth (deflated 10%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_logitnorm_loss/model-017.pth (deflated 10%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_logitnorm_loss/model-018.pth (deflated 10%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_logitnorm_loss/best.txt (stored 0%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_logitnorm_loss/model-001.pth (deflated 10%)\n",
            "\n",
            "\n",
            "----- Fine-tuning with IsoMaxPlus loss -----\n",
            "odict_keys(['module.encoder.initial_block.conv.weight', 'module.encoder.initial_block.conv.bias', 'module.encoder.initial_block.bn.weight', 'module.encoder.initial_block.bn.bias', 'module.encoder.initial_block.bn.running_mean', 'module.encoder.initial_block.bn.running_var', 'module.encoder.layers.0.conv.weight', 'module.encoder.layers.0.conv.bias', 'module.encoder.layers.0.bn.weight', 'module.encoder.layers.0.bn.bias', 'module.encoder.layers.0.bn.running_mean', 'module.encoder.layers.0.bn.running_var', 'module.encoder.layers.1.conv3x1_1.weight', 'module.encoder.layers.1.conv3x1_1.bias', 'module.encoder.layers.1.conv1x3_1.weight', 'module.encoder.layers.1.conv1x3_1.bias', 'module.encoder.layers.1.conv3x1_2.weight', 'module.encoder.layers.1.conv3x1_2.bias', 'module.encoder.layers.1.conv1x3_2.weight', 'module.encoder.layers.1.conv1x3_2.bias', 'module.encoder.layers.1.bn1.weight', 'module.encoder.layers.1.bn1.bias', 'module.encoder.layers.1.bn1.running_mean', 'module.encoder.layers.1.bn1.running_var', 'module.encoder.layers.1.bn2.weight', 'module.encoder.layers.1.bn2.bias', 'module.encoder.layers.1.bn2.running_mean', 'module.encoder.layers.1.bn2.running_var', 'module.encoder.layers.2.conv3x1_1.weight', 'module.encoder.layers.2.conv3x1_1.bias', 'module.encoder.layers.2.conv1x3_1.weight', 'module.encoder.layers.2.conv1x3_1.bias', 'module.encoder.layers.2.conv3x1_2.weight', 'module.encoder.layers.2.conv3x1_2.bias', 'module.encoder.layers.2.conv1x3_2.weight', 'module.encoder.layers.2.conv1x3_2.bias', 'module.encoder.layers.2.bn1.weight', 'module.encoder.layers.2.bn1.bias', 'module.encoder.layers.2.bn1.running_mean', 'module.encoder.layers.2.bn1.running_var', 'module.encoder.layers.2.bn2.weight', 'module.encoder.layers.2.bn2.bias', 'module.encoder.layers.2.bn2.running_mean', 'module.encoder.layers.2.bn2.running_var', 'module.encoder.layers.3.conv3x1_1.weight', 'module.encoder.layers.3.conv3x1_1.bias', 'module.encoder.layers.3.conv1x3_1.weight', 'module.encoder.layers.3.conv1x3_1.bias', 'module.encoder.layers.3.conv3x1_2.weight', 'module.encoder.layers.3.conv3x1_2.bias', 'module.encoder.layers.3.conv1x3_2.weight', 'module.encoder.layers.3.conv1x3_2.bias', 'module.encoder.layers.3.bn1.weight', 'module.encoder.layers.3.bn1.bias', 'module.encoder.layers.3.bn1.running_mean', 'module.encoder.layers.3.bn1.running_var', 'module.encoder.layers.3.bn2.weight', 'module.encoder.layers.3.bn2.bias', 'module.encoder.layers.3.bn2.running_mean', 'module.encoder.layers.3.bn2.running_var', 'module.encoder.layers.4.conv3x1_1.weight', 'module.encoder.layers.4.conv3x1_1.bias', 'module.encoder.layers.4.conv1x3_1.weight', 'module.encoder.layers.4.conv1x3_1.bias', 'module.encoder.layers.4.conv3x1_2.weight', 'module.encoder.layers.4.conv3x1_2.bias', 'module.encoder.layers.4.conv1x3_2.weight', 'module.encoder.layers.4.conv1x3_2.bias', 'module.encoder.layers.4.bn1.weight', 'module.encoder.layers.4.bn1.bias', 'module.encoder.layers.4.bn1.running_mean', 'module.encoder.layers.4.bn1.running_var', 'module.encoder.layers.4.bn2.weight', 'module.encoder.layers.4.bn2.bias', 'module.encoder.layers.4.bn2.running_mean', 'module.encoder.layers.4.bn2.running_var', 'module.encoder.layers.5.conv3x1_1.weight', 'module.encoder.layers.5.conv3x1_1.bias', 'module.encoder.layers.5.conv1x3_1.weight', 'module.encoder.layers.5.conv1x3_1.bias', 'module.encoder.layers.5.conv3x1_2.weight', 'module.encoder.layers.5.conv3x1_2.bias', 'module.encoder.layers.5.conv1x3_2.weight', 'module.encoder.layers.5.conv1x3_2.bias', 'module.encoder.layers.5.bn1.weight', 'module.encoder.layers.5.bn1.bias', 'module.encoder.layers.5.bn1.running_mean', 'module.encoder.layers.5.bn1.running_var', 'module.encoder.layers.5.bn2.weight', 'module.encoder.layers.5.bn2.bias', 'module.encoder.layers.5.bn2.running_mean', 'module.encoder.layers.5.bn2.running_var', 'module.encoder.layers.6.conv.weight', 'module.encoder.layers.6.conv.bias', 'module.encoder.layers.6.bn.weight', 'module.encoder.layers.6.bn.bias', 'module.encoder.layers.6.bn.running_mean', 'module.encoder.layers.6.bn.running_var', 'module.encoder.layers.7.conv3x1_1.weight', 'module.encoder.layers.7.conv3x1_1.bias', 'module.encoder.layers.7.conv1x3_1.weight', 'module.encoder.layers.7.conv1x3_1.bias', 'module.encoder.layers.7.conv3x1_2.weight', 'module.encoder.layers.7.conv3x1_2.bias', 'module.encoder.layers.7.conv1x3_2.weight', 'module.encoder.layers.7.conv1x3_2.bias', 'module.encoder.layers.7.bn1.weight', 'module.encoder.layers.7.bn1.bias', 'module.encoder.layers.7.bn1.running_mean', 'module.encoder.layers.7.bn1.running_var', 'module.encoder.layers.7.bn2.weight', 'module.encoder.layers.7.bn2.bias', 'module.encoder.layers.7.bn2.running_mean', 'module.encoder.layers.7.bn2.running_var', 'module.encoder.layers.8.conv3x1_1.weight', 'module.encoder.layers.8.conv3x1_1.bias', 'module.encoder.layers.8.conv1x3_1.weight', 'module.encoder.layers.8.conv1x3_1.bias', 'module.encoder.layers.8.conv3x1_2.weight', 'module.encoder.layers.8.conv3x1_2.bias', 'module.encoder.layers.8.conv1x3_2.weight', 'module.encoder.layers.8.conv1x3_2.bias', 'module.encoder.layers.8.bn1.weight', 'module.encoder.layers.8.bn1.bias', 'module.encoder.layers.8.bn1.running_mean', 'module.encoder.layers.8.bn1.running_var', 'module.encoder.layers.8.bn2.weight', 'module.encoder.layers.8.bn2.bias', 'module.encoder.layers.8.bn2.running_mean', 'module.encoder.layers.8.bn2.running_var', 'module.encoder.layers.9.conv3x1_1.weight', 'module.encoder.layers.9.conv3x1_1.bias', 'module.encoder.layers.9.conv1x3_1.weight', 'module.encoder.layers.9.conv1x3_1.bias', 'module.encoder.layers.9.conv3x1_2.weight', 'module.encoder.layers.9.conv3x1_2.bias', 'module.encoder.layers.9.conv1x3_2.weight', 'module.encoder.layers.9.conv1x3_2.bias', 'module.encoder.layers.9.bn1.weight', 'module.encoder.layers.9.bn1.bias', 'module.encoder.layers.9.bn1.running_mean', 'module.encoder.layers.9.bn1.running_var', 'module.encoder.layers.9.bn2.weight', 'module.encoder.layers.9.bn2.bias', 'module.encoder.layers.9.bn2.running_mean', 'module.encoder.layers.9.bn2.running_var', 'module.encoder.layers.10.conv3x1_1.weight', 'module.encoder.layers.10.conv3x1_1.bias', 'module.encoder.layers.10.conv1x3_1.weight', 'module.encoder.layers.10.conv1x3_1.bias', 'module.encoder.layers.10.conv3x1_2.weight', 'module.encoder.layers.10.conv3x1_2.bias', 'module.encoder.layers.10.conv1x3_2.weight', 'module.encoder.layers.10.conv1x3_2.bias', 'module.encoder.layers.10.bn1.weight', 'module.encoder.layers.10.bn1.bias', 'module.encoder.layers.10.bn1.running_mean', 'module.encoder.layers.10.bn1.running_var', 'module.encoder.layers.10.bn2.weight', 'module.encoder.layers.10.bn2.bias', 'module.encoder.layers.10.bn2.running_mean', 'module.encoder.layers.10.bn2.running_var', 'module.encoder.layers.11.conv3x1_1.weight', 'module.encoder.layers.11.conv3x1_1.bias', 'module.encoder.layers.11.conv1x3_1.weight', 'module.encoder.layers.11.conv1x3_1.bias', 'module.encoder.layers.11.conv3x1_2.weight', 'module.encoder.layers.11.conv3x1_2.bias', 'module.encoder.layers.11.conv1x3_2.weight', 'module.encoder.layers.11.conv1x3_2.bias', 'module.encoder.layers.11.bn1.weight', 'module.encoder.layers.11.bn1.bias', 'module.encoder.layers.11.bn1.running_mean', 'module.encoder.layers.11.bn1.running_var', 'module.encoder.layers.11.bn2.weight', 'module.encoder.layers.11.bn2.bias', 'module.encoder.layers.11.bn2.running_mean', 'module.encoder.layers.11.bn2.running_var', 'module.encoder.layers.12.conv3x1_1.weight', 'module.encoder.layers.12.conv3x1_1.bias', 'module.encoder.layers.12.conv1x3_1.weight', 'module.encoder.layers.12.conv1x3_1.bias', 'module.encoder.layers.12.conv3x1_2.weight', 'module.encoder.layers.12.conv3x1_2.bias', 'module.encoder.layers.12.conv1x3_2.weight', 'module.encoder.layers.12.conv1x3_2.bias', 'module.encoder.layers.12.bn1.weight', 'module.encoder.layers.12.bn1.bias', 'module.encoder.layers.12.bn1.running_mean', 'module.encoder.layers.12.bn1.running_var', 'module.encoder.layers.12.bn2.weight', 'module.encoder.layers.12.bn2.bias', 'module.encoder.layers.12.bn2.running_mean', 'module.encoder.layers.12.bn2.running_var', 'module.encoder.layers.13.conv3x1_1.weight', 'module.encoder.layers.13.conv3x1_1.bias', 'module.encoder.layers.13.conv1x3_1.weight', 'module.encoder.layers.13.conv1x3_1.bias', 'module.encoder.layers.13.conv3x1_2.weight', 'module.encoder.layers.13.conv3x1_2.bias', 'module.encoder.layers.13.conv1x3_2.weight', 'module.encoder.layers.13.conv1x3_2.bias', 'module.encoder.layers.13.bn1.weight', 'module.encoder.layers.13.bn1.bias', 'module.encoder.layers.13.bn1.running_mean', 'module.encoder.layers.13.bn1.running_var', 'module.encoder.layers.13.bn2.weight', 'module.encoder.layers.13.bn2.bias', 'module.encoder.layers.13.bn2.running_mean', 'module.encoder.layers.13.bn2.running_var', 'module.encoder.layers.14.conv3x1_1.weight', 'module.encoder.layers.14.conv3x1_1.bias', 'module.encoder.layers.14.conv1x3_1.weight', 'module.encoder.layers.14.conv1x3_1.bias', 'module.encoder.layers.14.conv3x1_2.weight', 'module.encoder.layers.14.conv3x1_2.bias', 'module.encoder.layers.14.conv1x3_2.weight', 'module.encoder.layers.14.conv1x3_2.bias', 'module.encoder.layers.14.bn1.weight', 'module.encoder.layers.14.bn1.bias', 'module.encoder.layers.14.bn1.running_mean', 'module.encoder.layers.14.bn1.running_var', 'module.encoder.layers.14.bn2.weight', 'module.encoder.layers.14.bn2.bias', 'module.encoder.layers.14.bn2.running_mean', 'module.encoder.layers.14.bn2.running_var', 'module.decoder.layers.0.conv.weight', 'module.decoder.layers.0.conv.bias', 'module.decoder.layers.0.bn.weight', 'module.decoder.layers.0.bn.bias', 'module.decoder.layers.0.bn.running_mean', 'module.decoder.layers.0.bn.running_var', 'module.decoder.layers.1.conv3x1_1.weight', 'module.decoder.layers.1.conv3x1_1.bias', 'module.decoder.layers.1.conv1x3_1.weight', 'module.decoder.layers.1.conv1x3_1.bias', 'module.decoder.layers.1.bn1.weight', 'module.decoder.layers.1.bn1.bias', 'module.decoder.layers.1.bn1.running_mean', 'module.decoder.layers.1.bn1.running_var', 'module.decoder.layers.1.conv3x1_2.weight', 'module.decoder.layers.1.conv3x1_2.bias', 'module.decoder.layers.1.conv1x3_2.weight', 'module.decoder.layers.1.conv1x3_2.bias', 'module.decoder.layers.1.bn2.weight', 'module.decoder.layers.1.bn2.bias', 'module.decoder.layers.1.bn2.running_mean', 'module.decoder.layers.1.bn2.running_var', 'module.decoder.layers.2.conv3x1_1.weight', 'module.decoder.layers.2.conv3x1_1.bias', 'module.decoder.layers.2.conv1x3_1.weight', 'module.decoder.layers.2.conv1x3_1.bias', 'module.decoder.layers.2.bn1.weight', 'module.decoder.layers.2.bn1.bias', 'module.decoder.layers.2.bn1.running_mean', 'module.decoder.layers.2.bn1.running_var', 'module.decoder.layers.2.conv3x1_2.weight', 'module.decoder.layers.2.conv3x1_2.bias', 'module.decoder.layers.2.conv1x3_2.weight', 'module.decoder.layers.2.conv1x3_2.bias', 'module.decoder.layers.2.bn2.weight', 'module.decoder.layers.2.bn2.bias', 'module.decoder.layers.2.bn2.running_mean', 'module.decoder.layers.2.bn2.running_var', 'module.decoder.layers.3.conv.weight', 'module.decoder.layers.3.conv.bias', 'module.decoder.layers.3.bn.weight', 'module.decoder.layers.3.bn.bias', 'module.decoder.layers.3.bn.running_mean', 'module.decoder.layers.3.bn.running_var', 'module.decoder.layers.4.conv3x1_1.weight', 'module.decoder.layers.4.conv3x1_1.bias', 'module.decoder.layers.4.conv1x3_1.weight', 'module.decoder.layers.4.conv1x3_1.bias', 'module.decoder.layers.4.bn1.weight', 'module.decoder.layers.4.bn1.bias', 'module.decoder.layers.4.bn1.running_mean', 'module.decoder.layers.4.bn1.running_var', 'module.decoder.layers.4.conv3x1_2.weight', 'module.decoder.layers.4.conv3x1_2.bias', 'module.decoder.layers.4.conv1x3_2.weight', 'module.decoder.layers.4.conv1x3_2.bias', 'module.decoder.layers.4.bn2.weight', 'module.decoder.layers.4.bn2.bias', 'module.decoder.layers.4.bn2.running_mean', 'module.decoder.layers.4.bn2.running_var', 'module.decoder.layers.5.conv3x1_1.weight', 'module.decoder.layers.5.conv3x1_1.bias', 'module.decoder.layers.5.conv1x3_1.weight', 'module.decoder.layers.5.conv1x3_1.bias', 'module.decoder.layers.5.bn1.weight', 'module.decoder.layers.5.bn1.bias', 'module.decoder.layers.5.bn1.running_mean', 'module.decoder.layers.5.bn1.running_var', 'module.decoder.layers.5.conv3x1_2.weight', 'module.decoder.layers.5.conv3x1_2.bias', 'module.decoder.layers.5.conv1x3_2.weight', 'module.decoder.layers.5.conv1x3_2.bias', 'module.decoder.layers.5.bn2.weight', 'module.decoder.layers.5.bn2.bias', 'module.decoder.layers.5.bn2.running_mean', 'module.decoder.layers.5.bn2.running_var', 'module.decoder.output_conv.weight', 'module.decoder.output_conv.bias'])\n",
            "odict_keys(['encoder.initial_block.conv.weight', 'encoder.initial_block.conv.bias', 'encoder.initial_block.bn.weight', 'encoder.initial_block.bn.bias', 'encoder.initial_block.bn.running_mean', 'encoder.initial_block.bn.running_var', 'encoder.initial_block.bn.num_batches_tracked', 'encoder.layers.0.conv.weight', 'encoder.layers.0.conv.bias', 'encoder.layers.0.bn.weight', 'encoder.layers.0.bn.bias', 'encoder.layers.0.bn.running_mean', 'encoder.layers.0.bn.running_var', 'encoder.layers.0.bn.num_batches_tracked', 'encoder.layers.1.conv3x1_1.weight', 'encoder.layers.1.conv3x1_1.bias', 'encoder.layers.1.conv1x3_1.weight', 'encoder.layers.1.conv1x3_1.bias', 'encoder.layers.1.bn1.weight', 'encoder.layers.1.bn1.bias', 'encoder.layers.1.bn1.running_mean', 'encoder.layers.1.bn1.running_var', 'encoder.layers.1.bn1.num_batches_tracked', 'encoder.layers.1.conv3x1_2.weight', 'encoder.layers.1.conv3x1_2.bias', 'encoder.layers.1.conv1x3_2.weight', 'encoder.layers.1.conv1x3_2.bias', 'encoder.layers.1.bn2.weight', 'encoder.layers.1.bn2.bias', 'encoder.layers.1.bn2.running_mean', 'encoder.layers.1.bn2.running_var', 'encoder.layers.1.bn2.num_batches_tracked', 'encoder.layers.2.conv3x1_1.weight', 'encoder.layers.2.conv3x1_1.bias', 'encoder.layers.2.conv1x3_1.weight', 'encoder.layers.2.conv1x3_1.bias', 'encoder.layers.2.bn1.weight', 'encoder.layers.2.bn1.bias', 'encoder.layers.2.bn1.running_mean', 'encoder.layers.2.bn1.running_var', 'encoder.layers.2.bn1.num_batches_tracked', 'encoder.layers.2.conv3x1_2.weight', 'encoder.layers.2.conv3x1_2.bias', 'encoder.layers.2.conv1x3_2.weight', 'encoder.layers.2.conv1x3_2.bias', 'encoder.layers.2.bn2.weight', 'encoder.layers.2.bn2.bias', 'encoder.layers.2.bn2.running_mean', 'encoder.layers.2.bn2.running_var', 'encoder.layers.2.bn2.num_batches_tracked', 'encoder.layers.3.conv3x1_1.weight', 'encoder.layers.3.conv3x1_1.bias', 'encoder.layers.3.conv1x3_1.weight', 'encoder.layers.3.conv1x3_1.bias', 'encoder.layers.3.bn1.weight', 'encoder.layers.3.bn1.bias', 'encoder.layers.3.bn1.running_mean', 'encoder.layers.3.bn1.running_var', 'encoder.layers.3.bn1.num_batches_tracked', 'encoder.layers.3.conv3x1_2.weight', 'encoder.layers.3.conv3x1_2.bias', 'encoder.layers.3.conv1x3_2.weight', 'encoder.layers.3.conv1x3_2.bias', 'encoder.layers.3.bn2.weight', 'encoder.layers.3.bn2.bias', 'encoder.layers.3.bn2.running_mean', 'encoder.layers.3.bn2.running_var', 'encoder.layers.3.bn2.num_batches_tracked', 'encoder.layers.4.conv3x1_1.weight', 'encoder.layers.4.conv3x1_1.bias', 'encoder.layers.4.conv1x3_1.weight', 'encoder.layers.4.conv1x3_1.bias', 'encoder.layers.4.bn1.weight', 'encoder.layers.4.bn1.bias', 'encoder.layers.4.bn1.running_mean', 'encoder.layers.4.bn1.running_var', 'encoder.layers.4.bn1.num_batches_tracked', 'encoder.layers.4.conv3x1_2.weight', 'encoder.layers.4.conv3x1_2.bias', 'encoder.layers.4.conv1x3_2.weight', 'encoder.layers.4.conv1x3_2.bias', 'encoder.layers.4.bn2.weight', 'encoder.layers.4.bn2.bias', 'encoder.layers.4.bn2.running_mean', 'encoder.layers.4.bn2.running_var', 'encoder.layers.4.bn2.num_batches_tracked', 'encoder.layers.5.conv3x1_1.weight', 'encoder.layers.5.conv3x1_1.bias', 'encoder.layers.5.conv1x3_1.weight', 'encoder.layers.5.conv1x3_1.bias', 'encoder.layers.5.bn1.weight', 'encoder.layers.5.bn1.bias', 'encoder.layers.5.bn1.running_mean', 'encoder.layers.5.bn1.running_var', 'encoder.layers.5.bn1.num_batches_tracked', 'encoder.layers.5.conv3x1_2.weight', 'encoder.layers.5.conv3x1_2.bias', 'encoder.layers.5.conv1x3_2.weight', 'encoder.layers.5.conv1x3_2.bias', 'encoder.layers.5.bn2.weight', 'encoder.layers.5.bn2.bias', 'encoder.layers.5.bn2.running_mean', 'encoder.layers.5.bn2.running_var', 'encoder.layers.5.bn2.num_batches_tracked', 'encoder.layers.6.conv.weight', 'encoder.layers.6.conv.bias', 'encoder.layers.6.bn.weight', 'encoder.layers.6.bn.bias', 'encoder.layers.6.bn.running_mean', 'encoder.layers.6.bn.running_var', 'encoder.layers.6.bn.num_batches_tracked', 'encoder.layers.7.conv3x1_1.weight', 'encoder.layers.7.conv3x1_1.bias', 'encoder.layers.7.conv1x3_1.weight', 'encoder.layers.7.conv1x3_1.bias', 'encoder.layers.7.bn1.weight', 'encoder.layers.7.bn1.bias', 'encoder.layers.7.bn1.running_mean', 'encoder.layers.7.bn1.running_var', 'encoder.layers.7.bn1.num_batches_tracked', 'encoder.layers.7.conv3x1_2.weight', 'encoder.layers.7.conv3x1_2.bias', 'encoder.layers.7.conv1x3_2.weight', 'encoder.layers.7.conv1x3_2.bias', 'encoder.layers.7.bn2.weight', 'encoder.layers.7.bn2.bias', 'encoder.layers.7.bn2.running_mean', 'encoder.layers.7.bn2.running_var', 'encoder.layers.7.bn2.num_batches_tracked', 'encoder.layers.8.conv3x1_1.weight', 'encoder.layers.8.conv3x1_1.bias', 'encoder.layers.8.conv1x3_1.weight', 'encoder.layers.8.conv1x3_1.bias', 'encoder.layers.8.bn1.weight', 'encoder.layers.8.bn1.bias', 'encoder.layers.8.bn1.running_mean', 'encoder.layers.8.bn1.running_var', 'encoder.layers.8.bn1.num_batches_tracked', 'encoder.layers.8.conv3x1_2.weight', 'encoder.layers.8.conv3x1_2.bias', 'encoder.layers.8.conv1x3_2.weight', 'encoder.layers.8.conv1x3_2.bias', 'encoder.layers.8.bn2.weight', 'encoder.layers.8.bn2.bias', 'encoder.layers.8.bn2.running_mean', 'encoder.layers.8.bn2.running_var', 'encoder.layers.8.bn2.num_batches_tracked', 'encoder.layers.9.conv3x1_1.weight', 'encoder.layers.9.conv3x1_1.bias', 'encoder.layers.9.conv1x3_1.weight', 'encoder.layers.9.conv1x3_1.bias', 'encoder.layers.9.bn1.weight', 'encoder.layers.9.bn1.bias', 'encoder.layers.9.bn1.running_mean', 'encoder.layers.9.bn1.running_var', 'encoder.layers.9.bn1.num_batches_tracked', 'encoder.layers.9.conv3x1_2.weight', 'encoder.layers.9.conv3x1_2.bias', 'encoder.layers.9.conv1x3_2.weight', 'encoder.layers.9.conv1x3_2.bias', 'encoder.layers.9.bn2.weight', 'encoder.layers.9.bn2.bias', 'encoder.layers.9.bn2.running_mean', 'encoder.layers.9.bn2.running_var', 'encoder.layers.9.bn2.num_batches_tracked', 'encoder.layers.10.conv3x1_1.weight', 'encoder.layers.10.conv3x1_1.bias', 'encoder.layers.10.conv1x3_1.weight', 'encoder.layers.10.conv1x3_1.bias', 'encoder.layers.10.bn1.weight', 'encoder.layers.10.bn1.bias', 'encoder.layers.10.bn1.running_mean', 'encoder.layers.10.bn1.running_var', 'encoder.layers.10.bn1.num_batches_tracked', 'encoder.layers.10.conv3x1_2.weight', 'encoder.layers.10.conv3x1_2.bias', 'encoder.layers.10.conv1x3_2.weight', 'encoder.layers.10.conv1x3_2.bias', 'encoder.layers.10.bn2.weight', 'encoder.layers.10.bn2.bias', 'encoder.layers.10.bn2.running_mean', 'encoder.layers.10.bn2.running_var', 'encoder.layers.10.bn2.num_batches_tracked', 'encoder.layers.11.conv3x1_1.weight', 'encoder.layers.11.conv3x1_1.bias', 'encoder.layers.11.conv1x3_1.weight', 'encoder.layers.11.conv1x3_1.bias', 'encoder.layers.11.bn1.weight', 'encoder.layers.11.bn1.bias', 'encoder.layers.11.bn1.running_mean', 'encoder.layers.11.bn1.running_var', 'encoder.layers.11.bn1.num_batches_tracked', 'encoder.layers.11.conv3x1_2.weight', 'encoder.layers.11.conv3x1_2.bias', 'encoder.layers.11.conv1x3_2.weight', 'encoder.layers.11.conv1x3_2.bias', 'encoder.layers.11.bn2.weight', 'encoder.layers.11.bn2.bias', 'encoder.layers.11.bn2.running_mean', 'encoder.layers.11.bn2.running_var', 'encoder.layers.11.bn2.num_batches_tracked', 'encoder.layers.12.conv3x1_1.weight', 'encoder.layers.12.conv3x1_1.bias', 'encoder.layers.12.conv1x3_1.weight', 'encoder.layers.12.conv1x3_1.bias', 'encoder.layers.12.bn1.weight', 'encoder.layers.12.bn1.bias', 'encoder.layers.12.bn1.running_mean', 'encoder.layers.12.bn1.running_var', 'encoder.layers.12.bn1.num_batches_tracked', 'encoder.layers.12.conv3x1_2.weight', 'encoder.layers.12.conv3x1_2.bias', 'encoder.layers.12.conv1x3_2.weight', 'encoder.layers.12.conv1x3_2.bias', 'encoder.layers.12.bn2.weight', 'encoder.layers.12.bn2.bias', 'encoder.layers.12.bn2.running_mean', 'encoder.layers.12.bn2.running_var', 'encoder.layers.12.bn2.num_batches_tracked', 'encoder.layers.13.conv3x1_1.weight', 'encoder.layers.13.conv3x1_1.bias', 'encoder.layers.13.conv1x3_1.weight', 'encoder.layers.13.conv1x3_1.bias', 'encoder.layers.13.bn1.weight', 'encoder.layers.13.bn1.bias', 'encoder.layers.13.bn1.running_mean', 'encoder.layers.13.bn1.running_var', 'encoder.layers.13.bn1.num_batches_tracked', 'encoder.layers.13.conv3x1_2.weight', 'encoder.layers.13.conv3x1_2.bias', 'encoder.layers.13.conv1x3_2.weight', 'encoder.layers.13.conv1x3_2.bias', 'encoder.layers.13.bn2.weight', 'encoder.layers.13.bn2.bias', 'encoder.layers.13.bn2.running_mean', 'encoder.layers.13.bn2.running_var', 'encoder.layers.13.bn2.num_batches_tracked', 'encoder.layers.14.conv3x1_1.weight', 'encoder.layers.14.conv3x1_1.bias', 'encoder.layers.14.conv1x3_1.weight', 'encoder.layers.14.conv1x3_1.bias', 'encoder.layers.14.bn1.weight', 'encoder.layers.14.bn1.bias', 'encoder.layers.14.bn1.running_mean', 'encoder.layers.14.bn1.running_var', 'encoder.layers.14.bn1.num_batches_tracked', 'encoder.layers.14.conv3x1_2.weight', 'encoder.layers.14.conv3x1_2.bias', 'encoder.layers.14.conv1x3_2.weight', 'encoder.layers.14.conv1x3_2.bias', 'encoder.layers.14.bn2.weight', 'encoder.layers.14.bn2.bias', 'encoder.layers.14.bn2.running_mean', 'encoder.layers.14.bn2.running_var', 'encoder.layers.14.bn2.num_batches_tracked', 'encoder.output_conv.weight', 'encoder.output_conv.bias', 'decoder.loss_first_part.prototypes', 'decoder.loss_first_part.distance_scale', 'decoder.layers.0.conv.weight', 'decoder.layers.0.conv.bias', 'decoder.layers.0.bn.weight', 'decoder.layers.0.bn.bias', 'decoder.layers.0.bn.running_mean', 'decoder.layers.0.bn.running_var', 'decoder.layers.0.bn.num_batches_tracked', 'decoder.layers.1.conv3x1_1.weight', 'decoder.layers.1.conv3x1_1.bias', 'decoder.layers.1.conv1x3_1.weight', 'decoder.layers.1.conv1x3_1.bias', 'decoder.layers.1.bn1.weight', 'decoder.layers.1.bn1.bias', 'decoder.layers.1.bn1.running_mean', 'decoder.layers.1.bn1.running_var', 'decoder.layers.1.bn1.num_batches_tracked', 'decoder.layers.1.conv3x1_2.weight', 'decoder.layers.1.conv3x1_2.bias', 'decoder.layers.1.conv1x3_2.weight', 'decoder.layers.1.conv1x3_2.bias', 'decoder.layers.1.bn2.weight', 'decoder.layers.1.bn2.bias', 'decoder.layers.1.bn2.running_mean', 'decoder.layers.1.bn2.running_var', 'decoder.layers.1.bn2.num_batches_tracked', 'decoder.layers.2.conv3x1_1.weight', 'decoder.layers.2.conv3x1_1.bias', 'decoder.layers.2.conv1x3_1.weight', 'decoder.layers.2.conv1x3_1.bias', 'decoder.layers.2.bn1.weight', 'decoder.layers.2.bn1.bias', 'decoder.layers.2.bn1.running_mean', 'decoder.layers.2.bn1.running_var', 'decoder.layers.2.bn1.num_batches_tracked', 'decoder.layers.2.conv3x1_2.weight', 'decoder.layers.2.conv3x1_2.bias', 'decoder.layers.2.conv1x3_2.weight', 'decoder.layers.2.conv1x3_2.bias', 'decoder.layers.2.bn2.weight', 'decoder.layers.2.bn2.bias', 'decoder.layers.2.bn2.running_mean', 'decoder.layers.2.bn2.running_var', 'decoder.layers.2.bn2.num_batches_tracked', 'decoder.layers.3.conv.weight', 'decoder.layers.3.conv.bias', 'decoder.layers.3.bn.weight', 'decoder.layers.3.bn.bias', 'decoder.layers.3.bn.running_mean', 'decoder.layers.3.bn.running_var', 'decoder.layers.3.bn.num_batches_tracked', 'decoder.layers.4.conv3x1_1.weight', 'decoder.layers.4.conv3x1_1.bias', 'decoder.layers.4.conv1x3_1.weight', 'decoder.layers.4.conv1x3_1.bias', 'decoder.layers.4.bn1.weight', 'decoder.layers.4.bn1.bias', 'decoder.layers.4.bn1.running_mean', 'decoder.layers.4.bn1.running_var', 'decoder.layers.4.bn1.num_batches_tracked', 'decoder.layers.4.conv3x1_2.weight', 'decoder.layers.4.conv3x1_2.bias', 'decoder.layers.4.conv1x3_2.weight', 'decoder.layers.4.conv1x3_2.bias', 'decoder.layers.4.bn2.weight', 'decoder.layers.4.bn2.bias', 'decoder.layers.4.bn2.running_mean', 'decoder.layers.4.bn2.running_var', 'decoder.layers.4.bn2.num_batches_tracked', 'decoder.layers.5.conv3x1_1.weight', 'decoder.layers.5.conv3x1_1.bias', 'decoder.layers.5.conv1x3_1.weight', 'decoder.layers.5.conv1x3_1.bias', 'decoder.layers.5.bn1.weight', 'decoder.layers.5.bn1.bias', 'decoder.layers.5.bn1.running_mean', 'decoder.layers.5.bn1.running_var', 'decoder.layers.5.bn1.num_batches_tracked', 'decoder.layers.5.conv3x1_2.weight', 'decoder.layers.5.conv3x1_2.bias', 'decoder.layers.5.conv1x3_2.weight', 'decoder.layers.5.conv1x3_2.bias', 'decoder.layers.5.bn2.weight', 'decoder.layers.5.bn2.bias', 'decoder.layers.5.bn2.running_mean', 'decoder.layers.5.bn2.running_var', 'decoder.layers.5.bn2.num_batches_tracked', 'decoder.output_conv.weight', 'decoder.output_conv.bias'])\n",
            "Size mismatch for decoder.output_conv.weight: torch.Size([16, 16, 1, 1]) vs torch.Size([16, 20, 2, 2])\n",
            "Size mismatch for decoder.output_conv.bias: torch.Size([16]) vs torch.Size([20])\n",
            "Import Model erfnet_isomaxplus with weights erfnet_pretrained.pth to FineTune\n",
            "========== TRAINING ===========\n",
            "/content/cityscapes/leftImg8bit/train\n",
            "/content/cityscapes/leftImg8bit/val\n",
            "----- TRAINING - EPOCH 1 -----\n",
            "LEARNING RATE:  5e-05\n",
            "loss: 5.576 (epoch: 1, step: 0) // Avg time/img: 0.9179 s\n",
            "loss: 5.586 (epoch: 1, step: 50) // Avg time/img: 0.1128 s\n",
            "loss: 5.534 (epoch: 1, step: 100) // Avg time/img: 0.1064 s\n",
            "loss: 5.48 (epoch: 1, step: 150) // Avg time/img: 0.1047 s\n",
            "loss: 5.419 (epoch: 1, step: 200) // Avg time/img: 0.1034 s\n",
            "loss: 5.359 (epoch: 1, step: 250) // Avg time/img: 0.1024 s\n",
            "loss: 5.297 (epoch: 1, step: 300) // Avg time/img: 0.1016 s\n",
            "loss: 5.23 (epoch: 1, step: 350) // Avg time/img: 0.1013 s\n",
            "loss: 5.163 (epoch: 1, step: 400) // Avg time/img: 0.1010 s\n",
            "loss: 5.099 (epoch: 1, step: 450) // Avg time/img: 0.1011 s\n",
            "----- VALIDATING - EPOCH 1 -----\n",
            "VAL loss: 4.168 (epoch: 1, step: 0) // Avg time/img: 0.0568 s\n",
            "VAL loss: 4.233 (epoch: 1, step: 50) // Avg time/img: 0.0409 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m0.96\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/erfnet_training_isomaxplus_loss/model-001.pth (epoch: 1)\n",
            "save: ../save/erfnet_training_isomaxplus_loss/model_best.pth (epoch: 1)\n",
            "----- TRAINING - EPOCH 2 -----\n",
            "LEARNING RATE:  4.774426908107499e-05\n",
            "loss: 4.423 (epoch: 2, step: 0) // Avg time/img: 0.1619 s\n",
            "loss: 4.21 (epoch: 2, step: 50) // Avg time/img: 0.1019 s\n",
            "loss: 4.136 (epoch: 2, step: 100) // Avg time/img: 0.1017 s\n",
            "loss: 4.054 (epoch: 2, step: 150) // Avg time/img: 0.1008 s\n",
            "loss: 3.969 (epoch: 2, step: 200) // Avg time/img: 0.1006 s\n",
            "loss: 3.89 (epoch: 2, step: 250) // Avg time/img: 0.1004 s\n",
            "loss: 3.802 (epoch: 2, step: 300) // Avg time/img: 0.1003 s\n",
            "loss: 3.711 (epoch: 2, step: 350) // Avg time/img: 0.1002 s\n",
            "loss: 3.626 (epoch: 2, step: 400) // Avg time/img: 0.1002 s\n",
            "loss: 3.542 (epoch: 2, step: 450) // Avg time/img: 0.1001 s\n",
            "----- VALIDATING - EPOCH 2 -----\n",
            "VAL loss: 2.387 (epoch: 2, step: 0) // Avg time/img: 0.0572 s\n",
            "VAL loss: 2.624 (epoch: 2, step: 50) // Avg time/img: 0.0408 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m10.39\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/erfnet_training_isomaxplus_loss/model-002.pth (epoch: 2)\n",
            "save: ../save/erfnet_training_isomaxplus_loss/model_best.pth (epoch: 2)\n",
            "----- TRAINING - EPOCH 3 -----\n",
            "LEARNING RATE:  4.547662880414811e-05\n",
            "loss: 2.496 (epoch: 3, step: 0) // Avg time/img: 0.1282 s\n",
            "loss: 2.549 (epoch: 3, step: 50) // Avg time/img: 0.1002 s\n",
            "loss: 2.489 (epoch: 3, step: 100) // Avg time/img: 0.1003 s\n",
            "loss: 2.427 (epoch: 3, step: 150) // Avg time/img: 0.1003 s\n",
            "loss: 2.375 (epoch: 3, step: 200) // Avg time/img: 0.1007 s\n",
            "loss: 2.322 (epoch: 3, step: 250) // Avg time/img: 0.1005 s\n",
            "loss: 2.276 (epoch: 3, step: 300) // Avg time/img: 0.1004 s\n",
            "loss: 2.227 (epoch: 3, step: 350) // Avg time/img: 0.1004 s\n",
            "loss: 2.183 (epoch: 3, step: 400) // Avg time/img: 0.1003 s\n",
            "loss: 2.141 (epoch: 3, step: 450) // Avg time/img: 0.1006 s\n",
            "----- VALIDATING - EPOCH 3 -----\n",
            "VAL loss: 1.487 (epoch: 3, step: 0) // Avg time/img: 0.0634 s\n",
            "VAL loss: 1.772 (epoch: 3, step: 50) // Avg time/img: 0.0410 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m17.12\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/erfnet_training_isomaxplus_loss/model-003.pth (epoch: 3)\n",
            "save: ../save/erfnet_training_isomaxplus_loss/model_best.pth (epoch: 3)\n",
            "----- TRAINING - EPOCH 4 -----\n",
            "LEARNING RATE:  4.319634861514096e-05\n",
            "loss: 1.764 (epoch: 4, step: 0) // Avg time/img: 0.1183 s\n",
            "loss: 1.673 (epoch: 4, step: 50) // Avg time/img: 0.1016 s\n",
            "loss: 1.66 (epoch: 4, step: 100) // Avg time/img: 0.1000 s\n",
            "loss: 1.638 (epoch: 4, step: 150) // Avg time/img: 0.1008 s\n",
            "loss: 1.616 (epoch: 4, step: 200) // Avg time/img: 0.1008 s\n",
            "loss: 1.595 (epoch: 4, step: 250) // Avg time/img: 0.1004 s\n",
            "loss: 1.576 (epoch: 4, step: 300) // Avg time/img: 0.1003 s\n",
            "loss: 1.56 (epoch: 4, step: 350) // Avg time/img: 0.1005 s\n",
            "loss: 1.544 (epoch: 4, step: 400) // Avg time/img: 0.1004 s\n",
            "loss: 1.526 (epoch: 4, step: 450) // Avg time/img: 0.1004 s\n",
            "----- VALIDATING - EPOCH 4 -----\n",
            "VAL loss: 1.168 (epoch: 4, step: 0) // Avg time/img: 0.0532 s\n",
            "VAL loss: 1.435 (epoch: 4, step: 50) // Avg time/img: 0.0418 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m21.19\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/erfnet_training_isomaxplus_loss/model-004.pth (epoch: 4)\n",
            "save: ../save/erfnet_training_isomaxplus_loss/model_best.pth (epoch: 4)\n",
            "----- TRAINING - EPOCH 5 -----\n",
            "LEARNING RATE:  4.090260730254292e-05\n",
            "loss: 1.727 (epoch: 5, step: 0) // Avg time/img: 0.1210 s\n",
            "loss: 1.336 (epoch: 5, step: 50) // Avg time/img: 0.0972 s\n",
            "loss: 1.317 (epoch: 5, step: 100) // Avg time/img: 0.0992 s\n",
            "loss: 1.31 (epoch: 5, step: 150) // Avg time/img: 0.0991 s\n",
            "loss: 1.308 (epoch: 5, step: 200) // Avg time/img: 0.0986 s\n",
            "loss: 1.299 (epoch: 5, step: 250) // Avg time/img: 0.0988 s\n",
            "loss: 1.292 (epoch: 5, step: 300) // Avg time/img: 0.0992 s\n",
            "loss: 1.278 (epoch: 5, step: 350) // Avg time/img: 0.0989 s\n",
            "loss: 1.267 (epoch: 5, step: 400) // Avg time/img: 0.0990 s\n",
            "loss: 1.259 (epoch: 5, step: 450) // Avg time/img: 0.0991 s\n",
            "----- VALIDATING - EPOCH 5 -----\n",
            "VAL loss: 1.028 (epoch: 5, step: 0) // Avg time/img: 0.0566 s\n",
            "VAL loss: 1.289 (epoch: 5, step: 50) // Avg time/img: 0.0408 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m25.61\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/erfnet_training_isomaxplus_loss/model-005.pth (epoch: 5)\n",
            "save: ../save/erfnet_training_isomaxplus_loss/model_best.pth (epoch: 5)\n",
            "----- TRAINING - EPOCH 6 -----\n",
            "LEARNING RATE:  3.859447533617852e-05\n",
            "loss: 1.374 (epoch: 6, step: 0) // Avg time/img: 0.1099 s\n",
            "loss: 1.158 (epoch: 6, step: 50) // Avg time/img: 0.1007 s\n",
            "loss: 1.155 (epoch: 6, step: 100) // Avg time/img: 0.1004 s\n",
            "loss: 1.14 (epoch: 6, step: 150) // Avg time/img: 0.0999 s\n",
            "loss: 1.137 (epoch: 6, step: 200) // Avg time/img: 0.1002 s\n",
            "loss: 1.129 (epoch: 6, step: 250) // Avg time/img: 0.1006 s\n",
            "loss: 1.123 (epoch: 6, step: 300) // Avg time/img: 0.1000 s\n",
            "loss: 1.118 (epoch: 6, step: 350) // Avg time/img: 0.1001 s\n",
            "loss: 1.115 (epoch: 6, step: 400) // Avg time/img: 0.0999 s\n",
            "loss: 1.116 (epoch: 6, step: 450) // Avg time/img: 0.1001 s\n",
            "----- VALIDATING - EPOCH 6 -----\n",
            "VAL loss: 0.9108 (epoch: 6, step: 0) // Avg time/img: 0.0563 s\n",
            "VAL loss: 1.166 (epoch: 6, step: 50) // Avg time/img: 0.0408 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m26.34\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/erfnet_training_isomaxplus_loss/model-006.pth (epoch: 6)\n",
            "save: ../save/erfnet_training_isomaxplus_loss/model_best.pth (epoch: 6)\n",
            "----- TRAINING - EPOCH 7 -----\n",
            "LEARNING RATE:  3.6270892346861e-05\n",
            "loss: 0.9215 (epoch: 7, step: 0) // Avg time/img: 0.1302 s\n",
            "loss: 1.05 (epoch: 7, step: 50) // Avg time/img: 0.1024 s\n",
            "loss: 1.031 (epoch: 7, step: 100) // Avg time/img: 0.1012 s\n",
            "loss: 1.051 (epoch: 7, step: 150) // Avg time/img: 0.1014 s\n",
            "loss: 1.044 (epoch: 7, step: 200) // Avg time/img: 0.1004 s\n",
            "loss: 1.041 (epoch: 7, step: 250) // Avg time/img: 0.0997 s\n",
            "loss: 1.038 (epoch: 7, step: 300) // Avg time/img: 0.1000 s\n",
            "loss: 1.033 (epoch: 7, step: 350) // Avg time/img: 0.1001 s\n",
            "loss: 1.03 (epoch: 7, step: 400) // Avg time/img: 0.1001 s\n",
            "loss: 1.025 (epoch: 7, step: 450) // Avg time/img: 0.1001 s\n",
            "----- VALIDATING - EPOCH 7 -----\n",
            "VAL loss: 0.8476 (epoch: 7, step: 0) // Avg time/img: 0.0535 s\n",
            "VAL loss: 1.097 (epoch: 7, step: 50) // Avg time/img: 0.0409 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m26.80\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/erfnet_training_isomaxplus_loss/model-007.pth (epoch: 7)\n",
            "save: ../save/erfnet_training_isomaxplus_loss/model_best.pth (epoch: 7)\n",
            "----- TRAINING - EPOCH 8 -----\n",
            "LEARNING RATE:  3.393063796290625e-05\n",
            "loss: 1.027 (epoch: 8, step: 0) // Avg time/img: 0.1106 s\n",
            "loss: 0.9933 (epoch: 8, step: 50) // Avg time/img: 0.0983 s\n",
            "loss: 0.9976 (epoch: 8, step: 100) // Avg time/img: 0.0988 s\n",
            "loss: 0.9948 (epoch: 8, step: 150) // Avg time/img: 0.0992 s\n",
            "loss: 0.9849 (epoch: 8, step: 200) // Avg time/img: 0.0994 s\n",
            "loss: 0.9822 (epoch: 8, step: 250) // Avg time/img: 0.0996 s\n",
            "loss: 0.9702 (epoch: 8, step: 300) // Avg time/img: 0.0998 s\n",
            "loss: 0.9649 (epoch: 8, step: 350) // Avg time/img: 0.1012 s\n",
            "loss: 0.9641 (epoch: 8, step: 400) // Avg time/img: 0.1033 s\n",
            "loss: 0.964 (epoch: 8, step: 450) // Avg time/img: 0.1041 s\n",
            "----- VALIDATING - EPOCH 8 -----\n",
            "VAL loss: 0.8218 (epoch: 8, step: 0) // Avg time/img: 0.0525 s\n",
            "VAL loss: 1.061 (epoch: 8, step: 50) // Avg time/img: 0.0407 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m27.13\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/erfnet_training_isomaxplus_loss/model-008.pth (epoch: 8)\n",
            "save: ../save/erfnet_training_isomaxplus_loss/model_best.pth (epoch: 8)\n",
            "----- TRAINING - EPOCH 9 -----\n",
            "LEARNING RATE:  3.157229337446777e-05\n",
            "loss: 0.7967 (epoch: 9, step: 0) // Avg time/img: 0.1161 s\n",
            "loss: 0.9008 (epoch: 9, step: 50) // Avg time/img: 0.1029 s\n",
            "loss: 0.9177 (epoch: 9, step: 100) // Avg time/img: 0.1011 s\n",
            "loss: 0.9207 (epoch: 9, step: 150) // Avg time/img: 0.1009 s\n",
            "loss: 0.9166 (epoch: 9, step: 200) // Avg time/img: 0.1007 s\n",
            "loss: 0.9207 (epoch: 9, step: 250) // Avg time/img: 0.1000 s\n",
            "loss: 0.9152 (epoch: 9, step: 300) // Avg time/img: 0.0998 s\n",
            "loss: 0.912 (epoch: 9, step: 350) // Avg time/img: 0.0997 s\n",
            "loss: 0.9099 (epoch: 9, step: 400) // Avg time/img: 0.0994 s\n",
            "loss: 0.9102 (epoch: 9, step: 450) // Avg time/img: 0.0997 s\n",
            "----- VALIDATING - EPOCH 9 -----\n",
            "VAL loss: 0.7639 (epoch: 9, step: 0) // Avg time/img: 0.0544 s\n",
            "VAL loss: 0.9982 (epoch: 9, step: 50) // Avg time/img: 0.0410 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m27.40\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/erfnet_training_isomaxplus_loss/model-009.pth (epoch: 9)\n",
            "save: ../save/erfnet_training_isomaxplus_loss/model_best.pth (epoch: 9)\n",
            "----- TRAINING - EPOCH 10 -----\n",
            "LEARNING RATE:  2.9194189645999014e-05\n",
            "loss: 1.666 (epoch: 10, step: 0) // Avg time/img: 0.1341 s\n",
            "loss: 0.9275 (epoch: 10, step: 50) // Avg time/img: 0.0993 s\n",
            "loss: 0.8985 (epoch: 10, step: 100) // Avg time/img: 0.1009 s\n",
            "loss: 0.8856 (epoch: 10, step: 150) // Avg time/img: 0.1010 s\n",
            "loss: 0.8876 (epoch: 10, step: 200) // Avg time/img: 0.1005 s\n",
            "loss: 0.8839 (epoch: 10, step: 250) // Avg time/img: 0.1010 s\n",
            "loss: 0.8842 (epoch: 10, step: 300) // Avg time/img: 0.1004 s\n",
            "loss: 0.8797 (epoch: 10, step: 350) // Avg time/img: 0.1004 s\n",
            "loss: 0.8749 (epoch: 10, step: 400) // Avg time/img: 0.1006 s\n",
            "loss: 0.871 (epoch: 10, step: 450) // Avg time/img: 0.1005 s\n",
            "----- VALIDATING - EPOCH 10 -----\n",
            "VAL loss: 0.7415 (epoch: 10, step: 0) // Avg time/img: 0.0573 s\n",
            "VAL loss: 0.974 (epoch: 10, step: 50) // Avg time/img: 0.0408 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m28.07\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/erfnet_training_isomaxplus_loss/model-010.pth (epoch: 10)\n",
            "save: ../save/erfnet_training_isomaxplus_loss/model_best.pth (epoch: 10)\n",
            "----- TRAINING - EPOCH 11 -----\n",
            "LEARNING RATE:  2.679433656340733e-05\n",
            "loss: 0.7937 (epoch: 11, step: 0) // Avg time/img: 0.1178 s\n",
            "loss: 0.8408 (epoch: 11, step: 50) // Avg time/img: 0.1008 s\n",
            "loss: 0.8463 (epoch: 11, step: 100) // Avg time/img: 0.0996 s\n",
            "loss: 0.8484 (epoch: 11, step: 150) // Avg time/img: 0.0997 s\n",
            "loss: 0.8498 (epoch: 11, step: 200) // Avg time/img: 0.1001 s\n",
            "loss: 0.8522 (epoch: 11, step: 250) // Avg time/img: 0.0999 s\n",
            "loss: 0.8483 (epoch: 11, step: 300) // Avg time/img: 0.0999 s\n",
            "loss: 0.842 (epoch: 11, step: 350) // Avg time/img: 0.1000 s\n",
            "loss: 0.8376 (epoch: 11, step: 400) // Avg time/img: 0.0998 s\n",
            "loss: 0.8368 (epoch: 11, step: 450) // Avg time/img: 0.0999 s\n",
            "----- VALIDATING - EPOCH 11 -----\n",
            "VAL loss: 0.7212 (epoch: 11, step: 0) // Avg time/img: 0.0587 s\n",
            "VAL loss: 0.9473 (epoch: 11, step: 50) // Avg time/img: 0.0415 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m28.53\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/erfnet_training_isomaxplus_loss/model-011.pth (epoch: 11)\n",
            "save: ../save/erfnet_training_isomaxplus_loss/model_best.pth (epoch: 11)\n",
            "----- TRAINING - EPOCH 12 -----\n",
            "LEARNING RATE:  2.437032195894977e-05\n",
            "loss: 0.5979 (epoch: 12, step: 0) // Avg time/img: 0.1156 s\n",
            "loss: 0.8109 (epoch: 12, step: 50) // Avg time/img: 0.0997 s\n",
            "loss: 0.8085 (epoch: 12, step: 100) // Avg time/img: 0.1003 s\n",
            "loss: 0.821 (epoch: 12, step: 150) // Avg time/img: 0.1005 s\n",
            "loss: 0.8137 (epoch: 12, step: 200) // Avg time/img: 0.1000 s\n",
            "loss: 0.8134 (epoch: 12, step: 250) // Avg time/img: 0.1003 s\n",
            "loss: 0.8116 (epoch: 12, step: 300) // Avg time/img: 0.1001 s\n",
            "loss: 0.8096 (epoch: 12, step: 350) // Avg time/img: 0.0999 s\n",
            "loss: 0.8098 (epoch: 12, step: 400) // Avg time/img: 0.1001 s\n",
            "loss: 0.8084 (epoch: 12, step: 450) // Avg time/img: 0.1001 s\n",
            "----- VALIDATING - EPOCH 12 -----\n",
            "VAL loss: 0.6999 (epoch: 12, step: 0) // Avg time/img: 0.0562 s\n",
            "VAL loss: 0.9212 (epoch: 12, step: 50) // Avg time/img: 0.0416 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m28.96\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/erfnet_training_isomaxplus_loss/model-012.pth (epoch: 12)\n",
            "save: ../save/erfnet_training_isomaxplus_loss/model_best.pth (epoch: 12)\n",
            "----- TRAINING - EPOCH 13 -----\n",
            "LEARNING RATE:  2.191916452770435e-05\n",
            "loss: 0.6637 (epoch: 13, step: 0) // Avg time/img: 0.1687 s\n",
            "loss: 0.7712 (epoch: 13, step: 50) // Avg time/img: 0.1013 s\n",
            "loss: 0.7714 (epoch: 13, step: 100) // Avg time/img: 0.1004 s\n",
            "loss: 0.7768 (epoch: 13, step: 150) // Avg time/img: 0.0998 s\n",
            "loss: 0.7749 (epoch: 13, step: 200) // Avg time/img: 0.1004 s\n",
            "loss: 0.7807 (epoch: 13, step: 250) // Avg time/img: 0.1004 s\n",
            "loss: 0.7808 (epoch: 13, step: 300) // Avg time/img: 0.1001 s\n",
            "loss: 0.7807 (epoch: 13, step: 350) // Avg time/img: 0.1004 s\n",
            "loss: 0.7838 (epoch: 13, step: 400) // Avg time/img: 0.1007 s\n",
            "loss: 0.7835 (epoch: 13, step: 450) // Avg time/img: 0.1003 s\n",
            "----- VALIDATING - EPOCH 13 -----\n",
            "VAL loss: 0.6575 (epoch: 13, step: 0) // Avg time/img: 0.0507 s\n",
            "VAL loss: 0.8829 (epoch: 13, step: 50) // Avg time/img: 0.0405 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m29.49\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/erfnet_training_isomaxplus_loss/model-013.pth (epoch: 13)\n",
            "save: ../save/erfnet_training_isomaxplus_loss/model_best.pth (epoch: 13)\n",
            "----- TRAINING - EPOCH 14 -----\n",
            "LEARNING RATE:  1.9437089939938174e-05\n",
            "loss: 0.7319 (epoch: 14, step: 0) // Avg time/img: 0.1149 s\n",
            "loss: 0.7985 (epoch: 14, step: 50) // Avg time/img: 0.1012 s\n",
            "loss: 0.7976 (epoch: 14, step: 100) // Avg time/img: 0.0995 s\n",
            "loss: 0.7778 (epoch: 14, step: 150) // Avg time/img: 0.0994 s\n",
            "loss: 0.7706 (epoch: 14, step: 200) // Avg time/img: 0.0996 s\n",
            "loss: 0.7722 (epoch: 14, step: 250) // Avg time/img: 0.0993 s\n",
            "loss: 0.7691 (epoch: 14, step: 300) // Avg time/img: 0.0997 s\n",
            "loss: 0.7662 (epoch: 14, step: 350) // Avg time/img: 0.0996 s\n",
            "loss: 0.7652 (epoch: 14, step: 400) // Avg time/img: 0.0992 s\n",
            "loss: 0.7667 (epoch: 14, step: 450) // Avg time/img: 0.0994 s\n",
            "----- VALIDATING - EPOCH 14 -----\n",
            "VAL loss: 0.6366 (epoch: 14, step: 0) // Avg time/img: 0.0607 s\n",
            "VAL loss: 0.8532 (epoch: 14, step: 50) // Avg time/img: 0.0406 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m29.97\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/erfnet_training_isomaxplus_loss/model-014.pth (epoch: 14)\n",
            "save: ../save/erfnet_training_isomaxplus_loss/model_best.pth (epoch: 14)\n",
            "----- TRAINING - EPOCH 15 -----\n",
            "LEARNING RATE:  1.6919173095082493e-05\n",
            "loss: 0.7383 (epoch: 15, step: 0) // Avg time/img: 0.1103 s\n",
            "loss: 0.7497 (epoch: 15, step: 50) // Avg time/img: 0.0998 s\n",
            "loss: 0.7387 (epoch: 15, step: 100) // Avg time/img: 0.0993 s\n",
            "loss: 0.742 (epoch: 15, step: 150) // Avg time/img: 0.0994 s\n",
            "loss: 0.7542 (epoch: 15, step: 200) // Avg time/img: 0.0988 s\n",
            "loss: 0.7496 (epoch: 15, step: 250) // Avg time/img: 0.0993 s\n",
            "loss: 0.7487 (epoch: 15, step: 300) // Avg time/img: 0.0997 s\n",
            "loss: 0.7498 (epoch: 15, step: 350) // Avg time/img: 0.0995 s\n",
            "loss: 0.752 (epoch: 15, step: 400) // Avg time/img: 0.0997 s\n",
            "loss: 0.7531 (epoch: 15, step: 450) // Avg time/img: 0.0997 s\n",
            "----- VALIDATING - EPOCH 15 -----\n",
            "VAL loss: 0.6428 (epoch: 15, step: 0) // Avg time/img: 0.0533 s\n",
            "VAL loss: 0.8524 (epoch: 15, step: 50) // Avg time/img: 0.0410 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m30.35\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/erfnet_training_isomaxplus_loss/model-015.pth (epoch: 15)\n",
            "save: ../save/erfnet_training_isomaxplus_loss/model_best.pth (epoch: 15)\n",
            "----- TRAINING - EPOCH 16 -----\n",
            "LEARNING RATE:  1.4358729437462937e-05\n",
            "loss: 0.7049 (epoch: 16, step: 0) // Avg time/img: 0.1315 s\n",
            "loss: 0.7369 (epoch: 16, step: 50) // Avg time/img: 0.1003 s\n",
            "loss: 0.7455 (epoch: 16, step: 100) // Avg time/img: 0.0971 s\n",
            "loss: 0.7326 (epoch: 16, step: 150) // Avg time/img: 0.0974 s\n",
            "loss: 0.7375 (epoch: 16, step: 200) // Avg time/img: 0.0983 s\n",
            "loss: 0.7427 (epoch: 16, step: 250) // Avg time/img: 0.0980 s\n",
            "loss: 0.7392 (epoch: 16, step: 300) // Avg time/img: 0.0982 s\n",
            "loss: 0.7392 (epoch: 16, step: 350) // Avg time/img: 0.0986 s\n",
            "loss: 0.7409 (epoch: 16, step: 400) // Avg time/img: 0.0987 s\n",
            "loss: 0.7408 (epoch: 16, step: 450) // Avg time/img: 0.0992 s\n",
            "----- VALIDATING - EPOCH 16 -----\n",
            "VAL loss: 0.629 (epoch: 16, step: 0) // Avg time/img: 0.0535 s\n",
            "VAL loss: 0.8345 (epoch: 16, step: 50) // Avg time/img: 0.0408 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m30.52\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/erfnet_training_isomaxplus_loss/model-016.pth (epoch: 16)\n",
            "save: ../save/erfnet_training_isomaxplus_loss/model_best.pth (epoch: 16)\n",
            "----- TRAINING - EPOCH 17 -----\n",
            "LEARNING RATE:  1.1746189430880188e-05\n",
            "loss: 0.7328 (epoch: 17, step: 0) // Avg time/img: 0.1164 s\n",
            "loss: 0.7492 (epoch: 17, step: 50) // Avg time/img: 0.1020 s\n",
            "loss: 0.7384 (epoch: 17, step: 100) // Avg time/img: 0.0997 s\n",
            "loss: 0.7329 (epoch: 17, step: 150) // Avg time/img: 0.1005 s\n",
            "loss: 0.7334 (epoch: 17, step: 200) // Avg time/img: 0.1004 s\n",
            "loss: 0.737 (epoch: 17, step: 250) // Avg time/img: 0.1002 s\n",
            "loss: 0.7322 (epoch: 17, step: 300) // Avg time/img: 0.1002 s\n",
            "loss: 0.7369 (epoch: 17, step: 350) // Avg time/img: 0.1001 s\n",
            "loss: 0.7341 (epoch: 17, step: 400) // Avg time/img: 0.1003 s\n",
            "loss: 0.7301 (epoch: 17, step: 450) // Avg time/img: 0.1004 s\n",
            "----- VALIDATING - EPOCH 17 -----\n",
            "VAL loss: 0.6156 (epoch: 17, step: 0) // Avg time/img: 0.0560 s\n",
            "VAL loss: 0.8224 (epoch: 17, step: 50) // Avg time/img: 0.0417 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m30.85\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/erfnet_training_isomaxplus_loss/model-017.pth (epoch: 17)\n",
            "save: ../save/erfnet_training_isomaxplus_loss/model_best.pth (epoch: 17)\n",
            "----- TRAINING - EPOCH 18 -----\n",
            "LEARNING RATE:  9.066760365683729e-06\n",
            "loss: 0.84 (epoch: 18, step: 0) // Avg time/img: 0.1167 s\n",
            "loss: 0.7256 (epoch: 18, step: 50) // Avg time/img: 0.0985 s\n",
            "loss: 0.7218 (epoch: 18, step: 100) // Avg time/img: 0.1005 s\n",
            "loss: 0.7245 (epoch: 18, step: 150) // Avg time/img: 0.1008 s\n",
            "loss: 0.7244 (epoch: 18, step: 200) // Avg time/img: 0.1011 s\n",
            "loss: 0.7235 (epoch: 18, step: 250) // Avg time/img: 0.1013 s\n",
            "loss: 0.7226 (epoch: 18, step: 300) // Avg time/img: 0.1007 s\n",
            "loss: 0.7242 (epoch: 18, step: 350) // Avg time/img: 0.1005 s\n",
            "loss: 0.7252 (epoch: 18, step: 400) // Avg time/img: 0.1005 s\n",
            "loss: 0.7204 (epoch: 18, step: 450) // Avg time/img: 0.1002 s\n",
            "----- VALIDATING - EPOCH 18 -----\n",
            "VAL loss: 0.6384 (epoch: 18, step: 0) // Avg time/img: 0.0602 s\n",
            "VAL loss: 0.8405 (epoch: 18, step: 50) // Avg time/img: 0.0417 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m31.23\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/erfnet_training_isomaxplus_loss/model-018.pth (epoch: 18)\n",
            "save: ../save/erfnet_training_isomaxplus_loss/model_best.pth (epoch: 18)\n",
            "----- TRAINING - EPOCH 19 -----\n",
            "LEARNING RATE:  6.294627058970836e-06\n",
            "loss: 0.6308 (epoch: 19, step: 0) // Avg time/img: 0.1128 s\n",
            "loss: 0.7237 (epoch: 19, step: 50) // Avg time/img: 0.1001 s\n",
            "loss: 0.7241 (epoch: 19, step: 100) // Avg time/img: 0.1001 s\n",
            "loss: 0.7278 (epoch: 19, step: 150) // Avg time/img: 0.1007 s\n",
            "loss: 0.723 (epoch: 19, step: 200) // Avg time/img: 0.1005 s\n",
            "loss: 0.7205 (epoch: 19, step: 250) // Avg time/img: 0.1002 s\n",
            "loss: 0.7196 (epoch: 19, step: 300) // Avg time/img: 0.1000 s\n",
            "loss: 0.7187 (epoch: 19, step: 350) // Avg time/img: 0.0998 s\n",
            "loss: 0.7167 (epoch: 19, step: 400) // Avg time/img: 0.0995 s\n",
            "loss: 0.7187 (epoch: 19, step: 450) // Avg time/img: 0.0994 s\n",
            "----- VALIDATING - EPOCH 19 -----\n",
            "VAL loss: 0.6233 (epoch: 19, step: 0) // Avg time/img: 0.0624 s\n",
            "VAL loss: 0.8262 (epoch: 19, step: 50) // Avg time/img: 0.0413 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m31.34\u001b[0m %\n",
            "Saving model as best\n",
            "save: ../save/erfnet_training_isomaxplus_loss/model-019.pth (epoch: 19)\n",
            "save: ../save/erfnet_training_isomaxplus_loss/model_best.pth (epoch: 19)\n",
            "----- TRAINING - EPOCH 20 -----\n",
            "LEARNING RATE:  3.373207119183911e-06\n",
            "loss: 0.6882 (epoch: 20, step: 0) // Avg time/img: 0.1174 s\n",
            "loss: 0.7242 (epoch: 20, step: 50) // Avg time/img: 0.1009 s\n",
            "loss: 0.7215 (epoch: 20, step: 100) // Avg time/img: 0.0983 s\n",
            "loss: 0.7149 (epoch: 20, step: 150) // Avg time/img: 0.0985 s\n",
            "loss: 0.7152 (epoch: 20, step: 200) // Avg time/img: 0.0986 s\n",
            "loss: 0.7144 (epoch: 20, step: 250) // Avg time/img: 0.0988 s\n",
            "loss: 0.7153 (epoch: 20, step: 300) // Avg time/img: 0.0988 s\n",
            "loss: 0.7155 (epoch: 20, step: 350) // Avg time/img: 0.0991 s\n",
            "loss: 0.7154 (epoch: 20, step: 400) // Avg time/img: 0.0993 s\n",
            "loss: 0.7133 (epoch: 20, step: 450) // Avg time/img: 0.0993 s\n",
            "----- VALIDATING - EPOCH 20 -----\n",
            "VAL loss: 0.6154 (epoch: 20, step: 0) // Avg time/img: 0.0518 s\n",
            "VAL loss: 0.8187 (epoch: 20, step: 50) // Avg time/img: 0.0415 s\n",
            "EPOCH IoU on VAL set:  \u001b[0m31.25\u001b[0m %\n",
            "save: ../save/erfnet_training_isomaxplus_loss/model-020.pth (epoch: 20)\n",
            "========== TRAINING FINISHED ===========\n",
            "Model saved in /content/AnomalySegmentation/save/erfnet_training_isomaxplus_loss\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_isomaxplus_loss/ (stored 0%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_isomaxplus_loss/model_best.pth (deflated 10%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_isomaxplus_loss/model-007.pth (deflated 10%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_isomaxplus_loss/model-015.pth (deflated 10%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_isomaxplus_loss/model-008.pth (deflated 10%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_isomaxplus_loss/model-004.pth (deflated 10%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_isomaxplus_loss/model-005.pth (deflated 10%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_isomaxplus_loss/model-002.pth (deflated 10%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_isomaxplus_loss/opts.txt (deflated 38%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_isomaxplus_loss/model.txt (deflated 92%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_isomaxplus_loss/model-014.pth (deflated 10%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_isomaxplus_loss/model-013.pth (deflated 10%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_isomaxplus_loss/model-012.pth (deflated 10%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_isomaxplus_loss/model-016.pth (deflated 10%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_isomaxplus_loss/model-011.pth (deflated 10%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_isomaxplus_loss/checkpoint.pth.tar (deflated 10%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_isomaxplus_loss/model-010.pth (deflated 10%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_isomaxplus_loss/model-020.pth (deflated 10%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_isomaxplus_loss/model_best.pth.tar (deflated 10%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_isomaxplus_loss/model-009.pth (deflated 10%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_isomaxplus_loss/model-003.pth (deflated 10%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_isomaxplus_loss/model-006.pth (deflated 10%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_isomaxplus_loss/automated_log.txt (deflated 63%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_isomaxplus_loss/model-019.pth (deflated 10%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_isomaxplus_loss/model-017.pth (deflated 10%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_isomaxplus_loss/model-018.pth (deflated 10%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_isomaxplus_loss/best.txt (stored 0%)\n",
            "  adding: content/AnomalySegmentation/save/erfnet_training_isomaxplus_loss/model-001.pth (deflated 10%)\n"
          ]
        }
      ],
      "source": [
        "# Fine tune ERFNET with different losses\n",
        "\n",
        "losses = [\"Focal\", \"LogitNorm\", \"IsoMaxPlus\"]\n",
        "models = [\"erfnet\", \"erfnet\", \"erfnet_isomaxplus\"]\n",
        "savedirs = [\"erfnet_training_focal_loss\", \"erfnet_training_logitnorm_loss\", \"erfnet_training_isomaxplus_loss\"]\n",
        "epochs = 20\n",
        "\n",
        "# Base directory of the project\n",
        "base_dir = \"/content/AnomalySegmentation/train\"\n",
        "# Dataset directory\n",
        "data_dir = \"/content/cityscapes\"\n",
        "pretrained_weights = \"erfnet_pretrained.pth\"\n",
        "\n",
        "# Loop to execute fine-tuning\n",
        "for loss, model, savedir in zip(losses, models, savedirs):\n",
        "    print(f\"\\n\\n----- Fine-tuning with {loss} loss -----\")\n",
        "    !cd {base_dir} && python -W ignore main.py --savedir {savedir} --loss {loss} --datadir {data_dir} --model {model} --cuda --num-epochs=20 --epochs-save=1 --FineTune --decoder --loadWeights={pretrained_weights}\n",
        "    print(f\"Model saved in /content/AnomalySegmentation/save/{savedir}\")\n",
        "    # zip folder\n",
        "    !zip -r save_{savedir}.zip /content/AnomalySegmentation/save/{savedir}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- TODO TODO TODO TODO ---------- Fine tune ERFNET with IsoMaxPlus\n",
        "\n",
        "losses = [\"IsoMaxPlus\"]\n",
        "models = [\"erfnet_isomaxplus\"]\n",
        "savedirs = [\"erfnet_training_isomaxplus_loss\"]\n",
        "epochs = 20\n",
        "\n",
        "# Base directory of the project\n",
        "base_dir = \"/content/AnomalySegmentation/train\"\n",
        "# Dataset directory\n",
        "data_dir = \"/content/cityscapes\"\n",
        "pretrained_weights = \"erfnet_pretrained.pth\"\n",
        "\n",
        "# Loop to execute fine-tuning\n",
        "for loss, model, savedir in zip(losses, models, savedirs):\n",
        "    print(f\"\\n\\n----- Fine-tuning with {loss} loss -----\")\n",
        "    !cd {base_dir} && python -W ignore main.py --savedir {savedir} --loss {loss} --datadir {data_dir} --model {model} --cuda --num-epochs=20 --epochs-save=1 --FineTune --decoder --loadWeights={pretrained_weights}\n",
        "    print(f\"Model saved in /content/AnomalySegmentation/save/{savedir}\")\n",
        "    # zip folder\n",
        "    !zip -r save_{savedir}.zip /content/AnomalySegmentation/save/{savedir}"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sEgYYkO_sGc",
        "outputId": "fd085276-dfb0-4280-8da3-7d0d2c6cbb3f"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "----- Fine-tuning with IsoMaxPlus loss -----\n",
            "odict_keys(['module.encoder.initial_block.conv.weight', 'module.encoder.initial_block.conv.bias', 'module.encoder.initial_block.bn.weight', 'module.encoder.initial_block.bn.bias', 'module.encoder.initial_block.bn.running_mean', 'module.encoder.initial_block.bn.running_var', 'module.encoder.layers.0.conv.weight', 'module.encoder.layers.0.conv.bias', 'module.encoder.layers.0.bn.weight', 'module.encoder.layers.0.bn.bias', 'module.encoder.layers.0.bn.running_mean', 'module.encoder.layers.0.bn.running_var', 'module.encoder.layers.1.conv3x1_1.weight', 'module.encoder.layers.1.conv3x1_1.bias', 'module.encoder.layers.1.conv1x3_1.weight', 'module.encoder.layers.1.conv1x3_1.bias', 'module.encoder.layers.1.conv3x1_2.weight', 'module.encoder.layers.1.conv3x1_2.bias', 'module.encoder.layers.1.conv1x3_2.weight', 'module.encoder.layers.1.conv1x3_2.bias', 'module.encoder.layers.1.bn1.weight', 'module.encoder.layers.1.bn1.bias', 'module.encoder.layers.1.bn1.running_mean', 'module.encoder.layers.1.bn1.running_var', 'module.encoder.layers.1.bn2.weight', 'module.encoder.layers.1.bn2.bias', 'module.encoder.layers.1.bn2.running_mean', 'module.encoder.layers.1.bn2.running_var', 'module.encoder.layers.2.conv3x1_1.weight', 'module.encoder.layers.2.conv3x1_1.bias', 'module.encoder.layers.2.conv1x3_1.weight', 'module.encoder.layers.2.conv1x3_1.bias', 'module.encoder.layers.2.conv3x1_2.weight', 'module.encoder.layers.2.conv3x1_2.bias', 'module.encoder.layers.2.conv1x3_2.weight', 'module.encoder.layers.2.conv1x3_2.bias', 'module.encoder.layers.2.bn1.weight', 'module.encoder.layers.2.bn1.bias', 'module.encoder.layers.2.bn1.running_mean', 'module.encoder.layers.2.bn1.running_var', 'module.encoder.layers.2.bn2.weight', 'module.encoder.layers.2.bn2.bias', 'module.encoder.layers.2.bn2.running_mean', 'module.encoder.layers.2.bn2.running_var', 'module.encoder.layers.3.conv3x1_1.weight', 'module.encoder.layers.3.conv3x1_1.bias', 'module.encoder.layers.3.conv1x3_1.weight', 'module.encoder.layers.3.conv1x3_1.bias', 'module.encoder.layers.3.conv3x1_2.weight', 'module.encoder.layers.3.conv3x1_2.bias', 'module.encoder.layers.3.conv1x3_2.weight', 'module.encoder.layers.3.conv1x3_2.bias', 'module.encoder.layers.3.bn1.weight', 'module.encoder.layers.3.bn1.bias', 'module.encoder.layers.3.bn1.running_mean', 'module.encoder.layers.3.bn1.running_var', 'module.encoder.layers.3.bn2.weight', 'module.encoder.layers.3.bn2.bias', 'module.encoder.layers.3.bn2.running_mean', 'module.encoder.layers.3.bn2.running_var', 'module.encoder.layers.4.conv3x1_1.weight', 'module.encoder.layers.4.conv3x1_1.bias', 'module.encoder.layers.4.conv1x3_1.weight', 'module.encoder.layers.4.conv1x3_1.bias', 'module.encoder.layers.4.conv3x1_2.weight', 'module.encoder.layers.4.conv3x1_2.bias', 'module.encoder.layers.4.conv1x3_2.weight', 'module.encoder.layers.4.conv1x3_2.bias', 'module.encoder.layers.4.bn1.weight', 'module.encoder.layers.4.bn1.bias', 'module.encoder.layers.4.bn1.running_mean', 'module.encoder.layers.4.bn1.running_var', 'module.encoder.layers.4.bn2.weight', 'module.encoder.layers.4.bn2.bias', 'module.encoder.layers.4.bn2.running_mean', 'module.encoder.layers.4.bn2.running_var', 'module.encoder.layers.5.conv3x1_1.weight', 'module.encoder.layers.5.conv3x1_1.bias', 'module.encoder.layers.5.conv1x3_1.weight', 'module.encoder.layers.5.conv1x3_1.bias', 'module.encoder.layers.5.conv3x1_2.weight', 'module.encoder.layers.5.conv3x1_2.bias', 'module.encoder.layers.5.conv1x3_2.weight', 'module.encoder.layers.5.conv1x3_2.bias', 'module.encoder.layers.5.bn1.weight', 'module.encoder.layers.5.bn1.bias', 'module.encoder.layers.5.bn1.running_mean', 'module.encoder.layers.5.bn1.running_var', 'module.encoder.layers.5.bn2.weight', 'module.encoder.layers.5.bn2.bias', 'module.encoder.layers.5.bn2.running_mean', 'module.encoder.layers.5.bn2.running_var', 'module.encoder.layers.6.conv.weight', 'module.encoder.layers.6.conv.bias', 'module.encoder.layers.6.bn.weight', 'module.encoder.layers.6.bn.bias', 'module.encoder.layers.6.bn.running_mean', 'module.encoder.layers.6.bn.running_var', 'module.encoder.layers.7.conv3x1_1.weight', 'module.encoder.layers.7.conv3x1_1.bias', 'module.encoder.layers.7.conv1x3_1.weight', 'module.encoder.layers.7.conv1x3_1.bias', 'module.encoder.layers.7.conv3x1_2.weight', 'module.encoder.layers.7.conv3x1_2.bias', 'module.encoder.layers.7.conv1x3_2.weight', 'module.encoder.layers.7.conv1x3_2.bias', 'module.encoder.layers.7.bn1.weight', 'module.encoder.layers.7.bn1.bias', 'module.encoder.layers.7.bn1.running_mean', 'module.encoder.layers.7.bn1.running_var', 'module.encoder.layers.7.bn2.weight', 'module.encoder.layers.7.bn2.bias', 'module.encoder.layers.7.bn2.running_mean', 'module.encoder.layers.7.bn2.running_var', 'module.encoder.layers.8.conv3x1_1.weight', 'module.encoder.layers.8.conv3x1_1.bias', 'module.encoder.layers.8.conv1x3_1.weight', 'module.encoder.layers.8.conv1x3_1.bias', 'module.encoder.layers.8.conv3x1_2.weight', 'module.encoder.layers.8.conv3x1_2.bias', 'module.encoder.layers.8.conv1x3_2.weight', 'module.encoder.layers.8.conv1x3_2.bias', 'module.encoder.layers.8.bn1.weight', 'module.encoder.layers.8.bn1.bias', 'module.encoder.layers.8.bn1.running_mean', 'module.encoder.layers.8.bn1.running_var', 'module.encoder.layers.8.bn2.weight', 'module.encoder.layers.8.bn2.bias', 'module.encoder.layers.8.bn2.running_mean', 'module.encoder.layers.8.bn2.running_var', 'module.encoder.layers.9.conv3x1_1.weight', 'module.encoder.layers.9.conv3x1_1.bias', 'module.encoder.layers.9.conv1x3_1.weight', 'module.encoder.layers.9.conv1x3_1.bias', 'module.encoder.layers.9.conv3x1_2.weight', 'module.encoder.layers.9.conv3x1_2.bias', 'module.encoder.layers.9.conv1x3_2.weight', 'module.encoder.layers.9.conv1x3_2.bias', 'module.encoder.layers.9.bn1.weight', 'module.encoder.layers.9.bn1.bias', 'module.encoder.layers.9.bn1.running_mean', 'module.encoder.layers.9.bn1.running_var', 'module.encoder.layers.9.bn2.weight', 'module.encoder.layers.9.bn2.bias', 'module.encoder.layers.9.bn2.running_mean', 'module.encoder.layers.9.bn2.running_var', 'module.encoder.layers.10.conv3x1_1.weight', 'module.encoder.layers.10.conv3x1_1.bias', 'module.encoder.layers.10.conv1x3_1.weight', 'module.encoder.layers.10.conv1x3_1.bias', 'module.encoder.layers.10.conv3x1_2.weight', 'module.encoder.layers.10.conv3x1_2.bias', 'module.encoder.layers.10.conv1x3_2.weight', 'module.encoder.layers.10.conv1x3_2.bias', 'module.encoder.layers.10.bn1.weight', 'module.encoder.layers.10.bn1.bias', 'module.encoder.layers.10.bn1.running_mean', 'module.encoder.layers.10.bn1.running_var', 'module.encoder.layers.10.bn2.weight', 'module.encoder.layers.10.bn2.bias', 'module.encoder.layers.10.bn2.running_mean', 'module.encoder.layers.10.bn2.running_var', 'module.encoder.layers.11.conv3x1_1.weight', 'module.encoder.layers.11.conv3x1_1.bias', 'module.encoder.layers.11.conv1x3_1.weight', 'module.encoder.layers.11.conv1x3_1.bias', 'module.encoder.layers.11.conv3x1_2.weight', 'module.encoder.layers.11.conv3x1_2.bias', 'module.encoder.layers.11.conv1x3_2.weight', 'module.encoder.layers.11.conv1x3_2.bias', 'module.encoder.layers.11.bn1.weight', 'module.encoder.layers.11.bn1.bias', 'module.encoder.layers.11.bn1.running_mean', 'module.encoder.layers.11.bn1.running_var', 'module.encoder.layers.11.bn2.weight', 'module.encoder.layers.11.bn2.bias', 'module.encoder.layers.11.bn2.running_mean', 'module.encoder.layers.11.bn2.running_var', 'module.encoder.layers.12.conv3x1_1.weight', 'module.encoder.layers.12.conv3x1_1.bias', 'module.encoder.layers.12.conv1x3_1.weight', 'module.encoder.layers.12.conv1x3_1.bias', 'module.encoder.layers.12.conv3x1_2.weight', 'module.encoder.layers.12.conv3x1_2.bias', 'module.encoder.layers.12.conv1x3_2.weight', 'module.encoder.layers.12.conv1x3_2.bias', 'module.encoder.layers.12.bn1.weight', 'module.encoder.layers.12.bn1.bias', 'module.encoder.layers.12.bn1.running_mean', 'module.encoder.layers.12.bn1.running_var', 'module.encoder.layers.12.bn2.weight', 'module.encoder.layers.12.bn2.bias', 'module.encoder.layers.12.bn2.running_mean', 'module.encoder.layers.12.bn2.running_var', 'module.encoder.layers.13.conv3x1_1.weight', 'module.encoder.layers.13.conv3x1_1.bias', 'module.encoder.layers.13.conv1x3_1.weight', 'module.encoder.layers.13.conv1x3_1.bias', 'module.encoder.layers.13.conv3x1_2.weight', 'module.encoder.layers.13.conv3x1_2.bias', 'module.encoder.layers.13.conv1x3_2.weight', 'module.encoder.layers.13.conv1x3_2.bias', 'module.encoder.layers.13.bn1.weight', 'module.encoder.layers.13.bn1.bias', 'module.encoder.layers.13.bn1.running_mean', 'module.encoder.layers.13.bn1.running_var', 'module.encoder.layers.13.bn2.weight', 'module.encoder.layers.13.bn2.bias', 'module.encoder.layers.13.bn2.running_mean', 'module.encoder.layers.13.bn2.running_var', 'module.encoder.layers.14.conv3x1_1.weight', 'module.encoder.layers.14.conv3x1_1.bias', 'module.encoder.layers.14.conv1x3_1.weight', 'module.encoder.layers.14.conv1x3_1.bias', 'module.encoder.layers.14.conv3x1_2.weight', 'module.encoder.layers.14.conv3x1_2.bias', 'module.encoder.layers.14.conv1x3_2.weight', 'module.encoder.layers.14.conv1x3_2.bias', 'module.encoder.layers.14.bn1.weight', 'module.encoder.layers.14.bn1.bias', 'module.encoder.layers.14.bn1.running_mean', 'module.encoder.layers.14.bn1.running_var', 'module.encoder.layers.14.bn2.weight', 'module.encoder.layers.14.bn2.bias', 'module.encoder.layers.14.bn2.running_mean', 'module.encoder.layers.14.bn2.running_var', 'module.decoder.layers.0.conv.weight', 'module.decoder.layers.0.conv.bias', 'module.decoder.layers.0.bn.weight', 'module.decoder.layers.0.bn.bias', 'module.decoder.layers.0.bn.running_mean', 'module.decoder.layers.0.bn.running_var', 'module.decoder.layers.1.conv3x1_1.weight', 'module.decoder.layers.1.conv3x1_1.bias', 'module.decoder.layers.1.conv1x3_1.weight', 'module.decoder.layers.1.conv1x3_1.bias', 'module.decoder.layers.1.bn1.weight', 'module.decoder.layers.1.bn1.bias', 'module.decoder.layers.1.bn1.running_mean', 'module.decoder.layers.1.bn1.running_var', 'module.decoder.layers.1.conv3x1_2.weight', 'module.decoder.layers.1.conv3x1_2.bias', 'module.decoder.layers.1.conv1x3_2.weight', 'module.decoder.layers.1.conv1x3_2.bias', 'module.decoder.layers.1.bn2.weight', 'module.decoder.layers.1.bn2.bias', 'module.decoder.layers.1.bn2.running_mean', 'module.decoder.layers.1.bn2.running_var', 'module.decoder.layers.2.conv3x1_1.weight', 'module.decoder.layers.2.conv3x1_1.bias', 'module.decoder.layers.2.conv1x3_1.weight', 'module.decoder.layers.2.conv1x3_1.bias', 'module.decoder.layers.2.bn1.weight', 'module.decoder.layers.2.bn1.bias', 'module.decoder.layers.2.bn1.running_mean', 'module.decoder.layers.2.bn1.running_var', 'module.decoder.layers.2.conv3x1_2.weight', 'module.decoder.layers.2.conv3x1_2.bias', 'module.decoder.layers.2.conv1x3_2.weight', 'module.decoder.layers.2.conv1x3_2.bias', 'module.decoder.layers.2.bn2.weight', 'module.decoder.layers.2.bn2.bias', 'module.decoder.layers.2.bn2.running_mean', 'module.decoder.layers.2.bn2.running_var', 'module.decoder.layers.3.conv.weight', 'module.decoder.layers.3.conv.bias', 'module.decoder.layers.3.bn.weight', 'module.decoder.layers.3.bn.bias', 'module.decoder.layers.3.bn.running_mean', 'module.decoder.layers.3.bn.running_var', 'module.decoder.layers.4.conv3x1_1.weight', 'module.decoder.layers.4.conv3x1_1.bias', 'module.decoder.layers.4.conv1x3_1.weight', 'module.decoder.layers.4.conv1x3_1.bias', 'module.decoder.layers.4.bn1.weight', 'module.decoder.layers.4.bn1.bias', 'module.decoder.layers.4.bn1.running_mean', 'module.decoder.layers.4.bn1.running_var', 'module.decoder.layers.4.conv3x1_2.weight', 'module.decoder.layers.4.conv3x1_2.bias', 'module.decoder.layers.4.conv1x3_2.weight', 'module.decoder.layers.4.conv1x3_2.bias', 'module.decoder.layers.4.bn2.weight', 'module.decoder.layers.4.bn2.bias', 'module.decoder.layers.4.bn2.running_mean', 'module.decoder.layers.4.bn2.running_var', 'module.decoder.layers.5.conv3x1_1.weight', 'module.decoder.layers.5.conv3x1_1.bias', 'module.decoder.layers.5.conv1x3_1.weight', 'module.decoder.layers.5.conv1x3_1.bias', 'module.decoder.layers.5.bn1.weight', 'module.decoder.layers.5.bn1.bias', 'module.decoder.layers.5.bn1.running_mean', 'module.decoder.layers.5.bn1.running_var', 'module.decoder.layers.5.conv3x1_2.weight', 'module.decoder.layers.5.conv3x1_2.bias', 'module.decoder.layers.5.conv1x3_2.weight', 'module.decoder.layers.5.conv1x3_2.bias', 'module.decoder.layers.5.bn2.weight', 'module.decoder.layers.5.bn2.bias', 'module.decoder.layers.5.bn2.running_mean', 'module.decoder.layers.5.bn2.running_var', 'module.decoder.output_conv.weight', 'module.decoder.output_conv.bias'])\n",
            "odict_keys(['encoder.initial_block.conv.weight', 'encoder.initial_block.conv.bias', 'encoder.initial_block.bn.weight', 'encoder.initial_block.bn.bias', 'encoder.initial_block.bn.running_mean', 'encoder.initial_block.bn.running_var', 'encoder.initial_block.bn.num_batches_tracked', 'encoder.layers.0.conv.weight', 'encoder.layers.0.conv.bias', 'encoder.layers.0.bn.weight', 'encoder.layers.0.bn.bias', 'encoder.layers.0.bn.running_mean', 'encoder.layers.0.bn.running_var', 'encoder.layers.0.bn.num_batches_tracked', 'encoder.layers.1.conv3x1_1.weight', 'encoder.layers.1.conv3x1_1.bias', 'encoder.layers.1.conv1x3_1.weight', 'encoder.layers.1.conv1x3_1.bias', 'encoder.layers.1.bn1.weight', 'encoder.layers.1.bn1.bias', 'encoder.layers.1.bn1.running_mean', 'encoder.layers.1.bn1.running_var', 'encoder.layers.1.bn1.num_batches_tracked', 'encoder.layers.1.conv3x1_2.weight', 'encoder.layers.1.conv3x1_2.bias', 'encoder.layers.1.conv1x3_2.weight', 'encoder.layers.1.conv1x3_2.bias', 'encoder.layers.1.bn2.weight', 'encoder.layers.1.bn2.bias', 'encoder.layers.1.bn2.running_mean', 'encoder.layers.1.bn2.running_var', 'encoder.layers.1.bn2.num_batches_tracked', 'encoder.layers.2.conv3x1_1.weight', 'encoder.layers.2.conv3x1_1.bias', 'encoder.layers.2.conv1x3_1.weight', 'encoder.layers.2.conv1x3_1.bias', 'encoder.layers.2.bn1.weight', 'encoder.layers.2.bn1.bias', 'encoder.layers.2.bn1.running_mean', 'encoder.layers.2.bn1.running_var', 'encoder.layers.2.bn1.num_batches_tracked', 'encoder.layers.2.conv3x1_2.weight', 'encoder.layers.2.conv3x1_2.bias', 'encoder.layers.2.conv1x3_2.weight', 'encoder.layers.2.conv1x3_2.bias', 'encoder.layers.2.bn2.weight', 'encoder.layers.2.bn2.bias', 'encoder.layers.2.bn2.running_mean', 'encoder.layers.2.bn2.running_var', 'encoder.layers.2.bn2.num_batches_tracked', 'encoder.layers.3.conv3x1_1.weight', 'encoder.layers.3.conv3x1_1.bias', 'encoder.layers.3.conv1x3_1.weight', 'encoder.layers.3.conv1x3_1.bias', 'encoder.layers.3.bn1.weight', 'encoder.layers.3.bn1.bias', 'encoder.layers.3.bn1.running_mean', 'encoder.layers.3.bn1.running_var', 'encoder.layers.3.bn1.num_batches_tracked', 'encoder.layers.3.conv3x1_2.weight', 'encoder.layers.3.conv3x1_2.bias', 'encoder.layers.3.conv1x3_2.weight', 'encoder.layers.3.conv1x3_2.bias', 'encoder.layers.3.bn2.weight', 'encoder.layers.3.bn2.bias', 'encoder.layers.3.bn2.running_mean', 'encoder.layers.3.bn2.running_var', 'encoder.layers.3.bn2.num_batches_tracked', 'encoder.layers.4.conv3x1_1.weight', 'encoder.layers.4.conv3x1_1.bias', 'encoder.layers.4.conv1x3_1.weight', 'encoder.layers.4.conv1x3_1.bias', 'encoder.layers.4.bn1.weight', 'encoder.layers.4.bn1.bias', 'encoder.layers.4.bn1.running_mean', 'encoder.layers.4.bn1.running_var', 'encoder.layers.4.bn1.num_batches_tracked', 'encoder.layers.4.conv3x1_2.weight', 'encoder.layers.4.conv3x1_2.bias', 'encoder.layers.4.conv1x3_2.weight', 'encoder.layers.4.conv1x3_2.bias', 'encoder.layers.4.bn2.weight', 'encoder.layers.4.bn2.bias', 'encoder.layers.4.bn2.running_mean', 'encoder.layers.4.bn2.running_var', 'encoder.layers.4.bn2.num_batches_tracked', 'encoder.layers.5.conv3x1_1.weight', 'encoder.layers.5.conv3x1_1.bias', 'encoder.layers.5.conv1x3_1.weight', 'encoder.layers.5.conv1x3_1.bias', 'encoder.layers.5.bn1.weight', 'encoder.layers.5.bn1.bias', 'encoder.layers.5.bn1.running_mean', 'encoder.layers.5.bn1.running_var', 'encoder.layers.5.bn1.num_batches_tracked', 'encoder.layers.5.conv3x1_2.weight', 'encoder.layers.5.conv3x1_2.bias', 'encoder.layers.5.conv1x3_2.weight', 'encoder.layers.5.conv1x3_2.bias', 'encoder.layers.5.bn2.weight', 'encoder.layers.5.bn2.bias', 'encoder.layers.5.bn2.running_mean', 'encoder.layers.5.bn2.running_var', 'encoder.layers.5.bn2.num_batches_tracked', 'encoder.layers.6.conv.weight', 'encoder.layers.6.conv.bias', 'encoder.layers.6.bn.weight', 'encoder.layers.6.bn.bias', 'encoder.layers.6.bn.running_mean', 'encoder.layers.6.bn.running_var', 'encoder.layers.6.bn.num_batches_tracked', 'encoder.layers.7.conv3x1_1.weight', 'encoder.layers.7.conv3x1_1.bias', 'encoder.layers.7.conv1x3_1.weight', 'encoder.layers.7.conv1x3_1.bias', 'encoder.layers.7.bn1.weight', 'encoder.layers.7.bn1.bias', 'encoder.layers.7.bn1.running_mean', 'encoder.layers.7.bn1.running_var', 'encoder.layers.7.bn1.num_batches_tracked', 'encoder.layers.7.conv3x1_2.weight', 'encoder.layers.7.conv3x1_2.bias', 'encoder.layers.7.conv1x3_2.weight', 'encoder.layers.7.conv1x3_2.bias', 'encoder.layers.7.bn2.weight', 'encoder.layers.7.bn2.bias', 'encoder.layers.7.bn2.running_mean', 'encoder.layers.7.bn2.running_var', 'encoder.layers.7.bn2.num_batches_tracked', 'encoder.layers.8.conv3x1_1.weight', 'encoder.layers.8.conv3x1_1.bias', 'encoder.layers.8.conv1x3_1.weight', 'encoder.layers.8.conv1x3_1.bias', 'encoder.layers.8.bn1.weight', 'encoder.layers.8.bn1.bias', 'encoder.layers.8.bn1.running_mean', 'encoder.layers.8.bn1.running_var', 'encoder.layers.8.bn1.num_batches_tracked', 'encoder.layers.8.conv3x1_2.weight', 'encoder.layers.8.conv3x1_2.bias', 'encoder.layers.8.conv1x3_2.weight', 'encoder.layers.8.conv1x3_2.bias', 'encoder.layers.8.bn2.weight', 'encoder.layers.8.bn2.bias', 'encoder.layers.8.bn2.running_mean', 'encoder.layers.8.bn2.running_var', 'encoder.layers.8.bn2.num_batches_tracked', 'encoder.layers.9.conv3x1_1.weight', 'encoder.layers.9.conv3x1_1.bias', 'encoder.layers.9.conv1x3_1.weight', 'encoder.layers.9.conv1x3_1.bias', 'encoder.layers.9.bn1.weight', 'encoder.layers.9.bn1.bias', 'encoder.layers.9.bn1.running_mean', 'encoder.layers.9.bn1.running_var', 'encoder.layers.9.bn1.num_batches_tracked', 'encoder.layers.9.conv3x1_2.weight', 'encoder.layers.9.conv3x1_2.bias', 'encoder.layers.9.conv1x3_2.weight', 'encoder.layers.9.conv1x3_2.bias', 'encoder.layers.9.bn2.weight', 'encoder.layers.9.bn2.bias', 'encoder.layers.9.bn2.running_mean', 'encoder.layers.9.bn2.running_var', 'encoder.layers.9.bn2.num_batches_tracked', 'encoder.layers.10.conv3x1_1.weight', 'encoder.layers.10.conv3x1_1.bias', 'encoder.layers.10.conv1x3_1.weight', 'encoder.layers.10.conv1x3_1.bias', 'encoder.layers.10.bn1.weight', 'encoder.layers.10.bn1.bias', 'encoder.layers.10.bn1.running_mean', 'encoder.layers.10.bn1.running_var', 'encoder.layers.10.bn1.num_batches_tracked', 'encoder.layers.10.conv3x1_2.weight', 'encoder.layers.10.conv3x1_2.bias', 'encoder.layers.10.conv1x3_2.weight', 'encoder.layers.10.conv1x3_2.bias', 'encoder.layers.10.bn2.weight', 'encoder.layers.10.bn2.bias', 'encoder.layers.10.bn2.running_mean', 'encoder.layers.10.bn2.running_var', 'encoder.layers.10.bn2.num_batches_tracked', 'encoder.layers.11.conv3x1_1.weight', 'encoder.layers.11.conv3x1_1.bias', 'encoder.layers.11.conv1x3_1.weight', 'encoder.layers.11.conv1x3_1.bias', 'encoder.layers.11.bn1.weight', 'encoder.layers.11.bn1.bias', 'encoder.layers.11.bn1.running_mean', 'encoder.layers.11.bn1.running_var', 'encoder.layers.11.bn1.num_batches_tracked', 'encoder.layers.11.conv3x1_2.weight', 'encoder.layers.11.conv3x1_2.bias', 'encoder.layers.11.conv1x3_2.weight', 'encoder.layers.11.conv1x3_2.bias', 'encoder.layers.11.bn2.weight', 'encoder.layers.11.bn2.bias', 'encoder.layers.11.bn2.running_mean', 'encoder.layers.11.bn2.running_var', 'encoder.layers.11.bn2.num_batches_tracked', 'encoder.layers.12.conv3x1_1.weight', 'encoder.layers.12.conv3x1_1.bias', 'encoder.layers.12.conv1x3_1.weight', 'encoder.layers.12.conv1x3_1.bias', 'encoder.layers.12.bn1.weight', 'encoder.layers.12.bn1.bias', 'encoder.layers.12.bn1.running_mean', 'encoder.layers.12.bn1.running_var', 'encoder.layers.12.bn1.num_batches_tracked', 'encoder.layers.12.conv3x1_2.weight', 'encoder.layers.12.conv3x1_2.bias', 'encoder.layers.12.conv1x3_2.weight', 'encoder.layers.12.conv1x3_2.bias', 'encoder.layers.12.bn2.weight', 'encoder.layers.12.bn2.bias', 'encoder.layers.12.bn2.running_mean', 'encoder.layers.12.bn2.running_var', 'encoder.layers.12.bn2.num_batches_tracked', 'encoder.layers.13.conv3x1_1.weight', 'encoder.layers.13.conv3x1_1.bias', 'encoder.layers.13.conv1x3_1.weight', 'encoder.layers.13.conv1x3_1.bias', 'encoder.layers.13.bn1.weight', 'encoder.layers.13.bn1.bias', 'encoder.layers.13.bn1.running_mean', 'encoder.layers.13.bn1.running_var', 'encoder.layers.13.bn1.num_batches_tracked', 'encoder.layers.13.conv3x1_2.weight', 'encoder.layers.13.conv3x1_2.bias', 'encoder.layers.13.conv1x3_2.weight', 'encoder.layers.13.conv1x3_2.bias', 'encoder.layers.13.bn2.weight', 'encoder.layers.13.bn2.bias', 'encoder.layers.13.bn2.running_mean', 'encoder.layers.13.bn2.running_var', 'encoder.layers.13.bn2.num_batches_tracked', 'encoder.layers.14.conv3x1_1.weight', 'encoder.layers.14.conv3x1_1.bias', 'encoder.layers.14.conv1x3_1.weight', 'encoder.layers.14.conv1x3_1.bias', 'encoder.layers.14.bn1.weight', 'encoder.layers.14.bn1.bias', 'encoder.layers.14.bn1.running_mean', 'encoder.layers.14.bn1.running_var', 'encoder.layers.14.bn1.num_batches_tracked', 'encoder.layers.14.conv3x1_2.weight', 'encoder.layers.14.conv3x1_2.bias', 'encoder.layers.14.conv1x3_2.weight', 'encoder.layers.14.conv1x3_2.bias', 'encoder.layers.14.bn2.weight', 'encoder.layers.14.bn2.bias', 'encoder.layers.14.bn2.running_mean', 'encoder.layers.14.bn2.running_var', 'encoder.layers.14.bn2.num_batches_tracked', 'encoder.output_conv.weight', 'encoder.output_conv.bias', 'decoder.loss_first_part.prototypes', 'decoder.loss_first_part.distance_scale', 'decoder.layers.0.conv.weight', 'decoder.layers.0.conv.bias', 'decoder.layers.0.bn.weight', 'decoder.layers.0.bn.bias', 'decoder.layers.0.bn.running_mean', 'decoder.layers.0.bn.running_var', 'decoder.layers.0.bn.num_batches_tracked', 'decoder.layers.1.conv3x1_1.weight', 'decoder.layers.1.conv3x1_1.bias', 'decoder.layers.1.conv1x3_1.weight', 'decoder.layers.1.conv1x3_1.bias', 'decoder.layers.1.bn1.weight', 'decoder.layers.1.bn1.bias', 'decoder.layers.1.bn1.running_mean', 'decoder.layers.1.bn1.running_var', 'decoder.layers.1.bn1.num_batches_tracked', 'decoder.layers.1.conv3x1_2.weight', 'decoder.layers.1.conv3x1_2.bias', 'decoder.layers.1.conv1x3_2.weight', 'decoder.layers.1.conv1x3_2.bias', 'decoder.layers.1.bn2.weight', 'decoder.layers.1.bn2.bias', 'decoder.layers.1.bn2.running_mean', 'decoder.layers.1.bn2.running_var', 'decoder.layers.1.bn2.num_batches_tracked', 'decoder.layers.2.conv3x1_1.weight', 'decoder.layers.2.conv3x1_1.bias', 'decoder.layers.2.conv1x3_1.weight', 'decoder.layers.2.conv1x3_1.bias', 'decoder.layers.2.bn1.weight', 'decoder.layers.2.bn1.bias', 'decoder.layers.2.bn1.running_mean', 'decoder.layers.2.bn1.running_var', 'decoder.layers.2.bn1.num_batches_tracked', 'decoder.layers.2.conv3x1_2.weight', 'decoder.layers.2.conv3x1_2.bias', 'decoder.layers.2.conv1x3_2.weight', 'decoder.layers.2.conv1x3_2.bias', 'decoder.layers.2.bn2.weight', 'decoder.layers.2.bn2.bias', 'decoder.layers.2.bn2.running_mean', 'decoder.layers.2.bn2.running_var', 'decoder.layers.2.bn2.num_batches_tracked', 'decoder.layers.3.conv.weight', 'decoder.layers.3.conv.bias', 'decoder.layers.3.bn.weight', 'decoder.layers.3.bn.bias', 'decoder.layers.3.bn.running_mean', 'decoder.layers.3.bn.running_var', 'decoder.layers.3.bn.num_batches_tracked', 'decoder.layers.4.conv3x1_1.weight', 'decoder.layers.4.conv3x1_1.bias', 'decoder.layers.4.conv1x3_1.weight', 'decoder.layers.4.conv1x3_1.bias', 'decoder.layers.4.bn1.weight', 'decoder.layers.4.bn1.bias', 'decoder.layers.4.bn1.running_mean', 'decoder.layers.4.bn1.running_var', 'decoder.layers.4.bn1.num_batches_tracked', 'decoder.layers.4.conv3x1_2.weight', 'decoder.layers.4.conv3x1_2.bias', 'decoder.layers.4.conv1x3_2.weight', 'decoder.layers.4.conv1x3_2.bias', 'decoder.layers.4.bn2.weight', 'decoder.layers.4.bn2.bias', 'decoder.layers.4.bn2.running_mean', 'decoder.layers.4.bn2.running_var', 'decoder.layers.4.bn2.num_batches_tracked', 'decoder.layers.5.conv3x1_1.weight', 'decoder.layers.5.conv3x1_1.bias', 'decoder.layers.5.conv1x3_1.weight', 'decoder.layers.5.conv1x3_1.bias', 'decoder.layers.5.bn1.weight', 'decoder.layers.5.bn1.bias', 'decoder.layers.5.bn1.running_mean', 'decoder.layers.5.bn1.running_var', 'decoder.layers.5.bn1.num_batches_tracked', 'decoder.layers.5.conv3x1_2.weight', 'decoder.layers.5.conv3x1_2.bias', 'decoder.layers.5.conv1x3_2.weight', 'decoder.layers.5.conv1x3_2.bias', 'decoder.layers.5.bn2.weight', 'decoder.layers.5.bn2.bias', 'decoder.layers.5.bn2.running_mean', 'decoder.layers.5.bn2.running_var', 'decoder.layers.5.bn2.num_batches_tracked', 'decoder.output_conv.weight', 'decoder.output_conv.bias'])\n",
            "Import Model erfnet_isomaxplus with weights erfnet_pretrained.pth to FineTune\n",
            "========== TRAINING ===========\n",
            "/content/cityscapes/leftImg8bit/train\n",
            "/content/cityscapes/leftImg8bit/val\n",
            "----- TRAINING - EPOCH 1 -----\n",
            "LEARNING RATE:  5e-05\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/AnomalySegmentation/train/main.py\", line 610, in <module>\n",
            "    main(parser.parse_args())\n",
            "  File \"/content/AnomalySegmentation/train/main.py\", line 574, in main\n",
            "    model = train(args, model, False)   #Train decoder\n",
            "  File \"/content/AnomalySegmentation/train/main.py\", line 242, in train\n",
            "    for step, (images, labels) in enumerate(loader):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 484, in __iter__\n",
            "    return self._get_iterator()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 415, in _get_iterator\n",
            "    return _MultiProcessingDataLoaderIter(self)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1191, in __init__\n",
            "    self._reset(loader, first_iter=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1228, in _reset\n",
            "    self._try_put_index()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1482, in _try_put_index\n",
            "    self._index_queues[worker_queue_idx].put((self._send_idx, index))  # type: ignore[possibly-undefined]\n",
            "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 94, in put\n",
            "    self._start_thread()\n",
            "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 177, in _start_thread\n",
            "    self._thread.start()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 940, in start\n",
            "    self._started.wait()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 607, in wait\n",
            "    signaled = self._cond.wait(timeout)\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 320, in wait\n",
            "    waiter.acquire()\n",
            "KeyboardInterrupt\n",
            "Model saved in /content/AnomalySegmentation/save/erfnet_training_isomaxplus_loss\n",
            "updating: content/AnomalySegmentation/save/erfnet_training_isomaxplus_loss/ (stored 0%)\n",
            "updating: content/AnomalySegmentation/save/erfnet_training_isomaxplus_loss/model.txt (deflated 92%)\n",
            "updating: content/AnomalySegmentation/save/erfnet_training_isomaxplus_loss/opts.txt (deflated 38%)\n",
            "updating: content/AnomalySegmentation/save/erfnet_training_isomaxplus_loss/automated_log.txt (deflated 27%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation:**"
      ],
      "metadata": {
        "id": "3-pAOTAnYE3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "no_execute = False\n",
        "just_once = True\n",
        "\n",
        "losses = [\"CrossEntropy\", \"Focal\", \"LogitNorm\", \"IsoMaxPlus\"]\n",
        "models = [\"erfnet\", \"erfnet\", \"erfnet\", \"erfnet_isomaxplus\"]\n",
        "load_dirs = [\"trained_models\", \"erfnet_training_focal_loss\", \"erfnet_training_logitnorm_loss\", \"erfnet_training_isomaxplus_loss\"]\n",
        "weights = [\"erfnet_pretrained.pth\", \"model_best.pth\", \"model_best.pth\", \"model_best.pth\"]\n",
        "\n",
        "for loss, model, load_dir, weight in zip(losses, models, load_dirs, weights):\n",
        "  print(f\"------ Loss function: {loss} ------\\n\")\n",
        "  for dataset_dir in ['RoadAnomaly21', 'RoadObsticle21', 'FS_LostFound_full', 'fs_static', 'RoadAnomaly']:\n",
        "    for method in [\"MSP\", \"MaxLogit\", \"MaxEntropy\"]:\n",
        "\n",
        "      if no_execute:\n",
        "        break\n",
        "\n",
        "      format_file = os.listdir(f'/content/Validation_Dataset/{dataset_dir}/images')[0].split(\".\")[1]\n",
        "      input =f'/content/Validation_Dataset/{dataset_dir}/images/\\*.{format_file}'\n",
        "\n",
        "      print(f\"\\nDataset: {dataset_dir} method: {method} loss: {loss}\")\n",
        "\n",
        "      if torch.cuda.is_available():\n",
        "        !python -W ignore /content/AnomalySegmentation/eval/evalAnomaly.py --input {input} --method  {method} --model {model} --loadDir {load_dir} --loadWeights {weight}\n",
        "      else:\n",
        "        !python -W ignore /content/AnomalySegmentation/eval/evalAnomaly.py --input {input} --method {method}  --model {model} --loadDir {load_dir} --loadWeights {weight} --cpu\n",
        "\n",
        "      print(\"----------------------------\")\n",
        "      if just_once:\n",
        "        no_execute = True\n",
        "        just_once = False\n",
        "    print(\"----------------------------\\n\\n\")"
      ],
      "metadata": {
        "id": "d1P6xBfcB9UO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "vNdTJZh4IP7G"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}