{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/RonPlusSign/AnomalySegmentation/blob/chris-1/Project6.ipynb)"
      ],
      "metadata": {
        "id": "ypo8OBRZ-1p3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Anomaly Segmentation Project 6**\n",
        "##*Andrea Delli, Christian Dellisanti, Giorgia Modi*"
      ],
      "metadata": {
        "id": "AUjRrYEW8-uz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Dataset Preparation**"
      ],
      "metadata": {
        "id": "4x3MajLNeXhX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip  install -q numpy matplotlib Pillow torchvision visdom ood_metrics icecream cityscapesscripts\n",
        "\n",
        "import sys, os\n",
        "if not os.path.isfile('/content/Validation_Dataset.zip'):\n",
        "  !gdown 12YJq48XkCxQHjN3CmLc-zM5dThSak4Ta\n",
        "if not os.path.isdir('/content/Validation_Dataset'):\n",
        "  !unzip -q Validation_Dataset.zip\n",
        "if not os.path.isdir('/content/AnomalySegmentation'):\n",
        "  #!git clone https://github.com/shyam671/AnomalySegmentation_CourseProjectBaseCode.git\n",
        "  #token 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\n",
        "  !git clone -b chris-1 https://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@github.com/RonPlusSign/AnomalySegmentation.git\n",
        "!cd /content/AnomalySegmentation && git pull"
      ],
      "metadata": {
        "id": "B_tj8W3BeVPo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6360b884-b8b6-44a0-e402-2e7467ac9833"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects:  14% (1/7)\u001b[K\rremote: Counting objects:  28% (2/7)\u001b[K\rremote: Counting objects:  42% (3/7)\u001b[K\rremote: Counting objects:  57% (4/7)\u001b[K\rremote: Counting objects:  71% (5/7)\u001b[K\rremote: Counting objects:  85% (6/7)\u001b[K\rremote: Counting objects: 100% (7/7)\u001b[K\rremote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1)\u001b[K\rremote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 4 (delta 3), reused 4 (delta 3), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects:  25% (1/4)\rUnpacking objects:  50% (2/4)\rUnpacking objects:  75% (3/4)\rUnpacking objects: 100% (4/4)\rUnpacking objects: 100% (4/4), 353 bytes | 176.00 KiB/s, done.\n",
            "From https://github.com/RonPlusSign/AnomalySegmentation\n",
            "   9a7210f..46f5205  chris-1    -> origin/chris-1\n",
            "Updating 9a7210f..46f5205\n",
            "Fast-forward\n",
            " eval/evalAnomaly.py | 2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**mIoU**"
      ],
      "metadata": {
        "id": "JAmA1igJhHhR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import  os\n",
        "# s306027@studenti.polito.it\n",
        "# %mR+g$L\\~5U03O9)IZ-_\n",
        "# Per Eseguire tutto ci mette 23 min sia CPU che GPU\n",
        "createLabel = False\n",
        "if not os.path.isdir('/content/cityscapes'):\n",
        "  !mkdir /content/cityscapes\n",
        "\n",
        "if not os.path.isfile('/content/cityscapes/gtFine_trainvaltest.zip'):\n",
        "  !csDownload gtFine_trainvaltest.zip -d /content/cityscapes/\n",
        "  !rm /content/cityscapes/README\n",
        "  !rm /content/cityscapes/license.txt\n",
        "\n",
        "if not os.path.isfile('/content/cityscapes/leftImg8bit_trainvaltest.zip'):\n",
        "  !csDownload leftImg8bit_trainvaltest.zip -d /content/cityscapes/\n",
        "  !rm /content/cityscapes/README\n",
        "  !rm /content/cityscapes/license.txt\n",
        "\n",
        "if not os.path.isdir('/content/cityscapes/gtFine'):\n",
        "  !unzip -q /content/cityscapes/gtFine_trainvaltest.zip -d /content/cityscapes/\n",
        "  createLabel = True\n",
        "\n",
        "\n",
        "if not os.path.isdir('/content/cityscapes/leftImg8bit'):\n",
        "  !unzip -q /content/cityscapes/leftImg8bit_trainvaltest.zip  -d /content/cityscapes/\n",
        "  createLabel = True\n",
        "\n",
        "if createLabel:\n",
        "  os.environ['CITYSCAPES_DATASET'] = '/content/cityscapes/'\n",
        "  !csCreateTrainIdLabelImgs\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3w0jewGkphY",
        "outputId": "5a48ada7-f571-42a4-e31f-1b3a4142ff94"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cityscapes username or email address: s306027@studenti.polito.it\n",
            "Cityscapes password: \n",
            "Store credentials unencrypted in '/root/.local/share/cityscapesscripts/credentials.json' [y/N]: y\n",
            "Downloading cityscapes package 'gtFine_trainvaltest.zip' to '/content/cityscapes/gtFine_trainvaltest.zip'\n",
            "Download progress: 100% 241M/241M [00:13<00:00, 18.5MB/s]\n",
            "rm: cannot remove '/content/cityscapes/README': No such file or directory\n",
            "rm: cannot remove '/content/cityscapes/license.txt': No such file or directory\n",
            "Downloading cityscapes package 'leftImg8bit_trainvaltest.zip' to '/content/cityscapes/leftImg8bit_trainvaltest.zip'\n",
            "Download progress:  98% 10.8G/11.0G [09:52<00:11, 19.6MB/s]\n",
            "rm: cannot remove '/content/cityscapes/README': No such file or directory\n",
            "rm: cannot remove '/content/cityscapes/license.txt': No such file or directory\n",
            "replace /content/cityscapes/README? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "Processing 5000 annotation files\n",
            "Progress: 100.0 % "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# ci mette 7 min con la GPU\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  !python -W ignore /content/AnomalySegmentation/eval/eval_iou.py --loadDir /content/AnomalySegmentation/trained_models/ --datadir /content/cityscapes/  | tail -n 28\n",
        "else:\n",
        "  !python -W ignore /content/AnomalySegmentation/eval/eval_iou.py  --loadDir  /content/AnomalySegmentation/trained_models/ --datadir /content/cityscapes/  --cpu | tail -n 28\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAeuewkbhM3p",
        "outputId": "91464ffe-a919-48c1-cf3e-c3a79a673dcb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "498 val/munster/munster_000172_000019_leftImg8bit.png\n",
            "499 val/munster/munster_000173_000019_leftImg8bit.png\n",
            "-------------MSP-------------------\n",
            "---------------------------------------\n",
            "Took  80.77754092216492 seconds\n",
            "=======================================\n",
            "Per-Class IoU:\n",
            "\u001b[0m97.62\u001b[0m Road\n",
            "\u001b[0m81.37\u001b[0m sidewalk\n",
            "\u001b[0m90.77\u001b[0m building\n",
            "\u001b[0m49.43\u001b[0m wall\n",
            "\u001b[0m54.93\u001b[0m fence\n",
            "\u001b[0m60.81\u001b[0m pole\n",
            "\u001b[0m62.60\u001b[0m traffic light\n",
            "\u001b[0m72.32\u001b[0m traffic sign\n",
            "\u001b[0m91.35\u001b[0m vegetation\n",
            "\u001b[0m60.97\u001b[0m terrain\n",
            "\u001b[0m93.38\u001b[0m sky\n",
            "\u001b[0m76.11\u001b[0m person\n",
            "\u001b[0m53.45\u001b[0m rider\n",
            "\u001b[0m92.91\u001b[0m car\n",
            "\u001b[0m72.78\u001b[0m truck\n",
            "\u001b[0m78.87\u001b[0m bus\n",
            "\u001b[0m63.86\u001b[0m train\n",
            "\u001b[0m46.41\u001b[0m motorcycle\n",
            "\u001b[0m71.89\u001b[0m bicycle\n",
            "=======================================\n",
            "MEAN IoU:  \u001b[0m72.20\u001b[0m %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Anomaly Inference**"
      ],
      "metadata": {
        "id": "4RZTrDS4Mysu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# se vado alla linea 87 di evalAnomaly.py quello dovrebbe essere l'utilizzo di MSP\n",
        "\n",
        "no_execute = False\n",
        "just_once = False\n",
        "\n",
        "for dataset_dir in ['RoadAnomaly', 'FS_LostFound_full', 'RoadObsticle21', 'RoadAnomaly21', 'fs_static']:\n",
        "    for method in [\"MSP\", \"MaxLogit\", \"MaxEntropy\"]:\n",
        "\n",
        "      if no_execute:\n",
        "        break\n",
        "\n",
        "      format_file = os.listdir(f'/content/Validation_Dataset/{dataset_dir}/images')[0].split(\".\")[1]\n",
        "      input =f'/content/Validation_Dataset/{dataset_dir}/images/*.{format_file}'\n",
        "      print(f\"\\nDataset: {dataset_dir} method : {method}\")\n",
        "      if torch.cuda.is_available():\n",
        "        !python -W ignore /content/AnomalySegmentation/eval/evalAnomaly.py --input {input} --loadDir '/content/AnomalySegmentation/trained_models/' --method  {method}  | tail -n 2\n",
        "      else:\n",
        "        !python -W ignore /content/AnomalySegmentation/eval/evalAnomaly.py --input {input} --loadDir '/content/AnomalySegmentation/trained_models/' --method {method}  --cpu | tail -n 2\n",
        "\n",
        "      if just_once:\n",
        "        no_execute = True\n",
        "        just_once = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9afwM8zdM7_l",
        "outputId": "36f7739a-b376-4d73-85ee-fa74832b2665"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset: RoadAnomaly method : MSP\n",
            "AUPRC score: 6.738430123274028\n",
            "FPR@TPR95: 94.89165173912563\n",
            "\n",
            "Dataset: RoadAnomaly method : MaxLogit\n",
            "AUPRC score: 6.261041778832238\n",
            "FPR@TPR95: 87.40798550331887\n",
            "\n",
            "Dataset: RoadAnomaly method : MaxEntropy\n",
            "AUPRC score: 5.343968114481838\n",
            "FPR@TPR95: 82.28332032617533\n",
            "\n",
            "Dataset: FS_LostFound_full method : MSP\n",
            "AUPRC score: 0.04317115562533831\n",
            "FPR@TPR95: 97.1629737988462\n",
            "\n",
            "Dataset: FS_LostFound_full method : MaxLogit\n",
            "AUPRC score: 0.03342295829977907\n",
            "FPR@TPR95: 97.51261950474581\n",
            "\n",
            "Dataset: FS_LostFound_full method : MaxEntropy\n",
            "AUPRC score: 0.5774409798957532\n",
            "FPR@TPR95: 28.370377553976617\n",
            "\n",
            "Dataset: RoadObsticle21 method : MSP\n",
            "AUPRC score: 0.018794117004305163\n",
            "FPR@TPR95: 95.399020190716\n",
            "\n",
            "Dataset: RoadObsticle21 method : MaxLogit\n",
            "AUPRC score: 0.02092376571398884\n",
            "FPR@TPR95: 65.61880697582242\n",
            "\n",
            "Dataset: RoadObsticle21 method : MaxEntropy\n",
            "AUPRC score: 0.05488599630491162\n",
            "FPR@TPR95: 38.8355074491152\n",
            "\n",
            "Dataset: RoadAnomaly21 method : MSP\n",
            "AUPRC score: 1.6319066971638478\n",
            "FPR@TPR95: 95.25864514332903\n",
            "\n",
            "Dataset: RoadAnomaly21 method : MaxLogit\n",
            "AUPRC score: 1.2451039820863412\n",
            "FPR@TPR95: 89.16379685795232\n",
            "\n",
            "Dataset: RoadAnomaly21 method : MaxEntropy\n",
            "AUPRC score: 2.718516721188082\n",
            "FPR@TPR95: 68.40363055122776\n",
            "\n",
            "Dataset: fs_static method : MSP\n",
            "AUPRC score: 2.644619880941904\n",
            "FPR@TPR95: 96.04300806593338\n",
            "\n",
            "Dataset: fs_static method : MaxLogit\n",
            "AUPRC score: 1.985076286433964\n",
            "FPR@TPR95: 99.33830433781615\n",
            "\n",
            "Dataset: fs_static method : MaxEntropy\n",
            "AUPRC score: 8.020334590893995\n",
            "FPR@TPR95: 59.87101183566757\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Temperature Scaling**"
      ],
      "metadata": {
        "id": "NhQWIx8rklfO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Anomaly Inference with temperature**"
      ],
      "metadata": {
        "id": "q7DsE7oO1n9G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "no_execute = False\n",
        "just_once = True\n",
        "for t in [0.5, 0.75, 1.1]:\n",
        "  for dataset_dir in ['RoadAnomaly', 'FS_LostFound_full', 'RoadObsticle21', 'RoadAnomaly21', 'fs_static']:\n",
        "\n",
        "    if no_execute:\n",
        "        break\n",
        "\n",
        "    format_file = os.listdir(f'/content/Validation_Dataset/{dataset_dir}/images')[0].split(\".\")[1]\n",
        "    input =f'/content/Validation_Dataset/{dataset_dir}/images/*.{format_file}'\n",
        "    print(f\"\\nDataset: {dataset_dir} method : MSP Temperature: {t}\")\n",
        "    if torch.cuda.is_available():\n",
        "      !python -W ignore /content/AnomalySegmentation/eval/evalAnomaly.py --input {input} --loadDir '/content/AnomalySegmentation/trained_models/'  --method 'MSP'   --temperature {t} | tail -n 2\n",
        "    else:\n",
        "      !python -W ignore /content/AnomalySegmentation/eval/evalAnomaly.py --input {input} --loadDir '/content/AnomalySegmentation/trained_models/'  --method 'MSP'  --cpu  --temperature {t} | tail -n 2\n",
        "\n",
        "    if just_once:\n",
        "      no_execute = True\n",
        "      just_once = False\n"
      ],
      "metadata": {
        "id": "uOPe7qbN14Qz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c090fe5e-d3b0-445d-fa8b-ed786883db05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset: RoadAnomaly method : MSP Temperature: 0.5\n",
            "AUPRC score: 6.711347578959494\n",
            "FPR@TPR95: 94.9778651262153\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DATASET MANAGEMENT** **TUTTO INUTILE GIÀ TUTTO SCRITTO**"
      ],
      "metadata": {
        "id": "zXztTueNBgkk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "import os\n",
        "\n",
        "from PIL import Image\n",
        "import sys\n",
        "\n",
        "\n",
        "def pil_loader(path):\n",
        "    # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n",
        "    with open(f\"/content/Validation_Dataset/{path}\", 'rb') as f:\n",
        "        img = Image.open(f)\n",
        "        return img.convert('RGB')\n",
        "\n",
        "\n",
        "# Define the Dataset class\n",
        "class PACSDataset(Dataset):\n",
        "    def __init__(self, root= \"/content/Validation_Dataset\", source_domain=\"FS_LostFound_full\" , dataset_transform=None):\n",
        "      super(PACSDataset, self).__init__( )\n",
        "\n",
        "      self.dataset_transform = dataset_transform\n",
        "\n",
        "      self.root=f\"{root}/{source_domain}\"\n",
        "      self.data   = os.listdir(f\"{root}/{source_domain}/images\")\n",
        "      #self.labels = os.listdir(f\"{root}/{source_domain}/labels_masks\")\n",
        "\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "      image, label = pil_loader(f\"images/{self.data[index]}\"), pil_loader(f\"labels_masks/{self.data[index]}\")\n",
        "\n",
        "      # Applies preprocessing when accessing the image\n",
        "      if self.dataset_transform is not None:\n",
        "          image = self.dataset_transform(image)\n",
        "\n",
        "      return image, label\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mNB5VstJIcYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ARCHITECTURE SETUP**"
      ],
      "metadata": {
        "id": "AWeVJrW2NiFM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# Define AlexNet architecture class\n",
        "class ErfNet(nn.Module):\n",
        "    def __init__(self, num_classes=1000):\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "        )\n",
        "        # Category classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, num_classes)\n",
        "        )\n",
        "        # Domain classifier\n",
        "        self.domain_classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.features(x)\n",
        "        features = features.view(features.size(0), -1)\n",
        "        class_outputs = self.classifier(features)\n",
        "        domain_outputs = self.domain_classifier(features)\n",
        "        return class_outputs, domain_outputs"
      ],
      "metadata": {
        "id": "GB1UGpoSJL4w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}