{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/RonPlusSign/AnomalySegmentation/blob/chris-1/Project6.ipynb)"
      ],
      "metadata": {
        "id": "ypo8OBRZ-1p3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Anomaly Segmentation Project 6**\n",
        "##*Andrea Delli, Christian Dellisanti, Giorgia Modi*"
      ],
      "metadata": {
        "id": "AUjRrYEW8-uz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Dataset Preparation**"
      ],
      "metadata": {
        "id": "4x3MajLNeXhX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip  install -q numpy matplotlib Pillow torchvision visdom ood_metrics\n",
        "\n",
        "import sys, os\n",
        "if not os.path.isfile('/content/Validation_Dataset.zip'):\n",
        "  !gdown 12YJq48XkCxQHjN3CmLc-zM5dThSak4Ta\n",
        "if not os.path.isdir('/content/Validation_Dataset'):\n",
        "  !unzip Validation_Dataset.zip\n",
        "if not os.path.isdir('/content/AnomalySegmentation'):\n",
        "  #!git clone https://github.com/shyam671/AnomalySegmentation_CourseProjectBaseCode.git\n",
        "  #token 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\n",
        "  !git clone -b chris-1 https://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@github.com/RonPlusSign/AnomalySegmentation.git"
      ],
      "metadata": {
        "id": "B_tj8W3BeVPo"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Anomaly Inference**"
      ],
      "metadata": {
        "id": "4RZTrDS4Mysu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# se vado alla linea 87 di evalAnomaly.py quello dovrebbe essere l'utilizzo di MSP\n",
        "\n",
        "for dataset_dir in ['RoadAnomaly', 'FS_LostFound_full', 'RoadObsticle21', 'RoadAnomaly21', 'fs_static']:\n",
        "  if torch.cuda.is_available():\n",
        "\n",
        "    format_file = os.listdir(f'/content/Validation_Dataset/{dataset_dir}/images')[0].split(\".\")[1]\n",
        "    input =f'/content/Validation_Dataset/{dataset_dir}/images/*.{format_file}'\n",
        "\n",
        "    !python /content/AnomalySegmentation/eval/evalAnomaly.py --input {input} --loadDir '/content/AnomalySegmentation/trained_models/' | tail -n 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9afwM8zdM7_l",
        "outputId": "e6176f43-88f2-459e-ed3f-484e31c7c06f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/AnomalySegmentation/eval/evalAnomaly.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model = load_my_state_dict(model, torch.load(weightspath, map_location=lambda storage, loc: storage))\n",
            "AUPRC score: 6.261041897652326\n",
            "FPR@TPR95: 87.40798550331887\n",
            "/content/AnomalySegmentation/eval/evalAnomaly.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model = load_my_state_dict(model, torch.load(weightspath, map_location=lambda storage, loc: storage))\n",
            "AUPRC score: 0.03342295309257113\n",
            "FPR@TPR95: 97.51261950474581\n",
            "/content/AnomalySegmentation/eval/evalAnomaly.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model = load_my_state_dict(model, torch.load(weightspath, map_location=lambda storage, loc: storage))\n",
            "AUPRC score: 0.02092376571398884\n",
            "FPR@TPR95: 65.61880697582242\n",
            "/content/AnomalySegmentation/eval/evalAnomaly.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model = load_my_state_dict(model, torch.load(weightspath, map_location=lambda storage, loc: storage))\n",
            "AUPRC score: 1.2451039661003525\n",
            "FPR@TPR95: 89.16379685795232\n",
            "/content/AnomalySegmentation/eval/evalAnomaly.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model = load_my_state_dict(model, torch.load(weightspath, map_location=lambda storage, loc: storage))\n",
            "AUPRC score: 1.9850763495853345\n",
            "FPR@TPR95: 99.33830433781615\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DATASET MANAGEMENT** **TUTTO INUTILE GIÃ€ TUTTO SCRITTO**"
      ],
      "metadata": {
        "id": "zXztTueNBgkk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "import os\n",
        "\n",
        "from PIL import Image\n",
        "import sys\n",
        "\n",
        "\n",
        "def pil_loader(path):\n",
        "    # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n",
        "    with open(f\"/content/Validation_Dataset/{path}\", 'rb') as f:\n",
        "        img = Image.open(f)\n",
        "        return img.convert('RGB')\n",
        "\n",
        "\n",
        "# Define the Dataset class\n",
        "class PACSDataset(Dataset):\n",
        "    def __init__(self, root= \"/content/Validation_Dataset\", source_domain=\"FS_LostFound_full\" , dataset_transform=None):\n",
        "      super(PACSDataset, self).__init__( )\n",
        "\n",
        "      self.dataset_transform = dataset_transform\n",
        "\n",
        "      self.root=f\"{root}/{source_domain}\"\n",
        "      self.data   = os.listdir(f\"{root}/{source_domain}/images\")\n",
        "      #self.labels = os.listdir(f\"{root}/{source_domain}/labels_masks\")\n",
        "\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "      image, label = pil_loader(f\"images/{self.data[index]}\"), pil_loader(f\"labels_masks/{self.data[index]}\")\n",
        "\n",
        "      # Applies preprocessing when accessing the image\n",
        "      if self.dataset_transform is not None:\n",
        "          image = self.dataset_transform(image)\n",
        "\n",
        "      return image, label\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mNB5VstJIcYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ARCHITECTURE SETUP**"
      ],
      "metadata": {
        "id": "AWeVJrW2NiFM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# Define AlexNet architecture class\n",
        "class ErfNet(nn.Module):\n",
        "    def __init__(self, num_classes=1000):\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "        )\n",
        "        # Category classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, num_classes)\n",
        "        )\n",
        "        # Domain classifier\n",
        "        self.domain_classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.features(x)\n",
        "        features = features.view(features.size(0), -1)\n",
        "        class_outputs = self.classifier(features)\n",
        "        domain_outputs = self.domain_classifier(features)\n",
        "        return class_outputs, domain_outputs"
      ],
      "metadata": {
        "id": "GB1UGpoSJL4w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}