{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/RonPlusSign/AnomalySegmentation/blob/chris-1/Project6.ipynb)"
      ],
      "metadata": {
        "id": "ypo8OBRZ-1p3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Anomaly Segmentation Project 6**\n",
        "##*Andrea Delli, Christian Dellisanti, Giorgia Modi*"
      ],
      "metadata": {
        "id": "AUjRrYEW8-uz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Dataset Preparation**"
      ],
      "metadata": {
        "id": "4x3MajLNeXhX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip  install -q numpy matplotlib Pillow torchvision visdom ood_metrics icecream cityscapesscripts\n",
        "\n",
        "import sys, os\n",
        "if not os.path.isfile('/content/Validation_Dataset.zip'):\n",
        "  !gdown 12YJq48XkCxQHjN3CmLc-zM5dThSak4Ta\n",
        "if not os.path.isdir('/content/Validation_Dataset'):\n",
        "  !unzip -q Validation_Dataset.zip\n",
        "if not os.path.isdir('/content/AnomalySegmentation'):\n",
        "  #!git clone https://github.com/shyam671/AnomalySegmentation_CourseProjectBaseCode.git\n",
        "  #token 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\n",
        "  !git clone -b chris-1 https://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@github.com/RonPlusSign/AnomalySegmentation.git\n",
        "!cd /content/AnomalySegmentation && git pull"
      ],
      "metadata": {
        "id": "B_tj8W3BeVPo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "977e5c29-c7a0-43c2-ede2-7e9400188a8f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.4 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=12YJq48XkCxQHjN3CmLc-zM5dThSak4Ta\n",
            "From (redirected): https://drive.google.com/uc?id=12YJq48XkCxQHjN3CmLc-zM5dThSak4Ta&confirm=t&uuid=b2e0983f-5190-4834-9810-a66655615928\n",
            "To: /content/Validation_Dataset.zip\n",
            "100% 329M/329M [00:05<00:00, 55.1MB/s]\n",
            "Cloning into 'AnomalySegmentation'...\n",
            "remote: Enumerating objects: 293, done.\u001b[K\n",
            "remote: Counting objects: 100% (82/82), done.\u001b[K\n",
            "remote: Compressing objects: 100% (59/59), done.\u001b[K\n",
            "remote: Total 293 (delta 53), reused 46 (delta 23), pack-reused 211 (from 1)\u001b[K\n",
            "Receiving objects: 100% (293/293), 21.53 MiB | 18.25 MiB/s, done.\n",
            "Resolving deltas: 100% (179/179), done.\n",
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**mIoU**"
      ],
      "metadata": {
        "id": "JAmA1igJhHhR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!csDownload --help\n",
        "!mkdir /content/data1/\n",
        "!csDownload gtFine_trainvaltest.zip -d /content/data1/"
      ],
      "metadata": {
        "id": "-BU29f_ntEWV",
        "outputId": "b780b3c7-4ca7-4c20-d4a9-549d3361b045",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: csDownload [-h] [-l] [-d DESTINATION_PATH] [-r] [package_name ...]\n",
            "\n",
            "Download packages of the Cityscapes Dataset.\n",
            "\n",
            "positional arguments:\n",
            "  package_name          name of the packages to download\n",
            "\n",
            "options:\n",
            "  -h, --help            show this help message and exit\n",
            "  -l, --list_available  list available packages and exit\n",
            "  -d DESTINATION_PATH, --destination_path DESTINATION_PATH\n",
            "                        destination path for downloads\n",
            "  -r, --resume          resume previous download\n",
            "\n",
            "Requires an account that can be created via https://www.cityscapes-dataset.com/register/\n",
            "Downloading cityscapes package 'gtFine_trainvaltest.zip' to '/content/data1/gtFine_trainvaltest.zip'\n",
            "Download progress: 100% 241M/241M [00:12<00:00, 19.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import  os\n",
        "\n",
        "if not os.path.isdir('/content/Validation_Dataset'):\n",
        "  !mkdir /content/cityscapes\n",
        "#!csDownload --help\n",
        "if not os.path.isfile('/content/cityscapes/gtFine_trainvaltest.zip'):\n",
        "  !csDownload gtFine_trainvaltest.zip -d /content/data/\n",
        "if not os.path.isfile('/content/cityscapes/leftImg8bit_trainvaltest.zip'):\n",
        "  !csDownload leftImg8bit_trainvaltest.zip -d /content/data/\n",
        "#!csDownload leftImg8bit_trainvaltest.zip -d /content/data/\n",
        "!unzip -q /content/data/gtFine_trainvaltest.zip -d /content/data/\n",
        "!unzip -q /content/data/leftImg8bit_trainvaltest.zip  -d /content/data/\n",
        "#gtFine_trainvaltest.zip\n",
        "#leftImg8bit_trainvaltest.zip"
      ],
      "metadata": {
        "id": "A3w0jewGkphY",
        "outputId": "e730ff4e-51cc-45d2-a1d9-50efb7aafd3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "replace README? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "replace README? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# se vado alla linea 87 di evalAnomaly.py quello dovrebbe essere l'utilizzo di MSP\n",
        "\n",
        "no_execute = False\n",
        "just_once = True\n",
        "\n",
        "\n",
        "for method in [\"MSP\", \"MaxLogit\", \"MaxEntropy\"]:\n",
        "\n",
        "  if no_execute:\n",
        "    break\n",
        "\n",
        "\n",
        "  if torch.cuda.is_available():\n",
        "    !python -W ignore /content/AnomalySegmentation/eval/eval_iou.py --loadDir /content/AnomalySegmentation/trained_models/ --datadir /content/data/\n",
        "  else:\n",
        "    !python -W ignore /content/AnomalySegmentation/eval/eval_iou.py  --loadDir  /content/AnomalySegmentation/trained_models/ --datadir /content/data/ --cpu\n",
        "\n",
        "  if just_once:\n",
        "    no_execute = True\n",
        "    just_once = False"
      ],
      "metadata": {
        "id": "pAeuewkbhM3p",
        "outputId": "e9166838-6222-47d0-a88a-9870256e2120",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model: /content/AnomalySegmentation/trained_models/erfnet.py\n",
            "Loading weights: /content/AnomalySegmentation/trained_models/erfnet_pretrained.pth\n",
            "Model and weights LOADED successfully\n",
            "/content/data/leftImg8bit/val /content/data/gtFine/val\n",
            "---------------------------------------\n",
            "Took  0.12188911437988281 seconds\n",
            "=======================================\n",
            "Per-Class IoU:\n",
            "\u001b[0m0.00\u001b[0m Road\n",
            "\u001b[0m0.00\u001b[0m sidewalk\n",
            "\u001b[0m0.00\u001b[0m building\n",
            "\u001b[0m0.00\u001b[0m wall\n",
            "\u001b[0m0.00\u001b[0m fence\n",
            "\u001b[0m0.00\u001b[0m pole\n",
            "\u001b[0m0.00\u001b[0m traffic light\n",
            "\u001b[0m0.00\u001b[0m traffic sign\n",
            "\u001b[0m0.00\u001b[0m vegetation\n",
            "\u001b[0m0.00\u001b[0m terrain\n",
            "\u001b[0m0.00\u001b[0m sky\n",
            "\u001b[0m0.00\u001b[0m person\n",
            "\u001b[0m0.00\u001b[0m rider\n",
            "\u001b[0m0.00\u001b[0m car\n",
            "\u001b[0m0.00\u001b[0m truck\n",
            "\u001b[0m0.00\u001b[0m bus\n",
            "\u001b[0m0.00\u001b[0m train\n",
            "\u001b[0m0.00\u001b[0m motorcycle\n",
            "\u001b[0m0.00\u001b[0m bicycle\n",
            "=======================================\n",
            "MEAN IoU:  \u001b[0m0.00\u001b[0m %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Anomaly Inference**"
      ],
      "metadata": {
        "id": "4RZTrDS4Mysu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# se vado alla linea 87 di evalAnomaly.py quello dovrebbe essere l'utilizzo di MSP\n",
        "\n",
        "no_execute = False\n",
        "just_once = True\n",
        "\n",
        "for dataset_dir in ['RoadAnomaly', 'FS_LostFound_full', 'RoadObsticle21', 'RoadAnomaly21', 'fs_static']:\n",
        "    for method in [\"MSP\", \"MaxLogit\", \"MaxEntropy\"]:\n",
        "\n",
        "      if no_execute:\n",
        "        break\n",
        "\n",
        "      format_file = os.listdir(f'/content/Validation_Dataset/{dataset_dir}/images')[0].split(\".\")[1]\n",
        "      input =f'/content/Validation_Dataset/{dataset_dir}/images/*.{format_file}'\n",
        "      print(f\"\\nDataset: {dataset_dir} method : {method}\")\n",
        "      if torch.cuda.is_available():\n",
        "        !python -W ignore /content/AnomalySegmentation/eval/evalAnomaly.py --input {input} --loadDir '/content/AnomalySegmentation/trained_models/' --method {method} | tail -n 2\n",
        "      else:\n",
        "        !python -W ignore /content/AnomalySegmentation/eval/evalAnomaly.py --input {input} --loadDir '/content/AnomalySegmentation/trained_models/' --method {method}  --cpu | tail -n 2\n",
        "\n",
        "      if just_once:\n",
        "        no_execute = True\n",
        "        just_once = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9afwM8zdM7_l",
        "outputId": "5b16d27f-fcfe-45f3-9147-b5a8df671119"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset: RoadAnomaly method : MSP\n",
            "AUPRC score: 11.621902667890218\n",
            "FPR@TPR95: 61.66823489182735\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Temperature Scaling**"
      ],
      "metadata": {
        "id": "NhQWIx8rklfO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Anomaly Inference with temperature**"
      ],
      "metadata": {
        "id": "q7DsE7oO1n9G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "no_execute = False\n",
        "just_once = True\n",
        "for t in [0.5, 0.75, 1.1]:\n",
        "  for dataset_dir in ['RoadAnomaly', 'FS_LostFound_full', 'RoadObsticle21', 'RoadAnomaly21', 'fs_static']:\n",
        "\n",
        "    if no_execute:\n",
        "        break\n",
        "\n",
        "    format_file = os.listdir(f'/content/Validation_Dataset/{dataset_dir}/images')[0].split(\".\")[1]\n",
        "    input =f'/content/Validation_Dataset/{dataset_dir}/images/*.{format_file}'\n",
        "    print(f\"\\nDataset: {dataset_dir} method : MSP Temperature: {t}\")\n",
        "    if torch.cuda.is_available():\n",
        "      !python -W ignore /content/AnomalySegmentation/eval/evalAnomaly.py --input {input} --loadDir '/content/AnomalySegmentation/trained_models/'  --method 'MSP'   --temperature {t} | tail -n 2\n",
        "    else:\n",
        "      !python -W ignore /content/AnomalySegmentation/eval/evalAnomaly.py --input {input} --loadDir '/content/AnomalySegmentation/trained_models/'  --method 'MSP'  --cpu  --temperature {t} | tail -n 2\n",
        "\n",
        "    if just_once:\n",
        "      no_execute = True\n",
        "      just_once = False\n"
      ],
      "metadata": {
        "id": "uOPe7qbN14Qz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c090fe5e-d3b0-445d-fa8b-ed786883db05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset: RoadAnomaly method : MSP Temperature: 0.5\n",
            "AUPRC score: 6.711347578959494\n",
            "FPR@TPR95: 94.9778651262153\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DATASET MANAGEMENT** **TUTTO INUTILE GIÀ TUTTO SCRITTO**"
      ],
      "metadata": {
        "id": "zXztTueNBgkk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "import os\n",
        "\n",
        "from PIL import Image\n",
        "import sys\n",
        "\n",
        "\n",
        "def pil_loader(path):\n",
        "    # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n",
        "    with open(f\"/content/Validation_Dataset/{path}\", 'rb') as f:\n",
        "        img = Image.open(f)\n",
        "        return img.convert('RGB')\n",
        "\n",
        "\n",
        "# Define the Dataset class\n",
        "class PACSDataset(Dataset):\n",
        "    def __init__(self, root= \"/content/Validation_Dataset\", source_domain=\"FS_LostFound_full\" , dataset_transform=None):\n",
        "      super(PACSDataset, self).__init__( )\n",
        "\n",
        "      self.dataset_transform = dataset_transform\n",
        "\n",
        "      self.root=f\"{root}/{source_domain}\"\n",
        "      self.data   = os.listdir(f\"{root}/{source_domain}/images\")\n",
        "      #self.labels = os.listdir(f\"{root}/{source_domain}/labels_masks\")\n",
        "\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "      image, label = pil_loader(f\"images/{self.data[index]}\"), pil_loader(f\"labels_masks/{self.data[index]}\")\n",
        "\n",
        "      # Applies preprocessing when accessing the image\n",
        "      if self.dataset_transform is not None:\n",
        "          image = self.dataset_transform(image)\n",
        "\n",
        "      return image, label\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mNB5VstJIcYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ARCHITECTURE SETUP**"
      ],
      "metadata": {
        "id": "AWeVJrW2NiFM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# Define AlexNet architecture class\n",
        "class ErfNet(nn.Module):\n",
        "    def __init__(self, num_classes=1000):\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "        )\n",
        "        # Category classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, num_classes)\n",
        "        )\n",
        "        # Domain classifier\n",
        "        self.domain_classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.features(x)\n",
        "        features = features.view(features.size(0), -1)\n",
        "        class_outputs = self.classifier(features)\n",
        "        domain_outputs = self.domain_classifier(features)\n",
        "        return class_outputs, domain_outputs"
      ],
      "metadata": {
        "id": "GB1UGpoSJL4w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}