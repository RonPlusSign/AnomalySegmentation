{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/RonPlusSign/AnomalySegmentation/blob/chris-1/Project6.ipynb)"
      ],
      "metadata": {
        "id": "ypo8OBRZ-1p3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Anomaly Segmentation Project 6**\n",
        "##*Andrea Delli, Christian Dellisanti, Giorgia Modi*"
      ],
      "metadata": {
        "id": "AUjRrYEW8-uz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Dataset Preparation**"
      ],
      "metadata": {
        "id": "4x3MajLNeXhX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip  install -q numpy matplotlib Pillow torchvision visdom ood_metrics\n",
        "\n",
        "import sys, os\n",
        "if not os.path.isfile('/content/Validation_Dataset.zip'):\n",
        "  !gdown 12YJq48XkCxQHjN3CmLc-zM5dThSak4Ta\n",
        "if not os.path.isdir('/content/Validation_Dataset'):\n",
        "  !unzip Validation_Dataset.zip\n",
        "if not os.path.isdir('/content/AnomalySegmentation'):\n",
        "  #!git clone https://github.com/shyam671/AnomalySegmentation_CourseProjectBaseCode.git\n",
        "  #token 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\n",
        "  !git clone -b chris-1 https://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@github.com/RonPlusSign/AnomalySegmentation.git\n",
        "!cd /content/AnomalySegmentation && git pull"
      ],
      "metadata": {
        "id": "B_tj8W3BeVPo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab3b899d-8102-46c3-be30-0c162411e7ac",
        "collapsed": true
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects:  14% (1/7)\u001b[K\rremote: Counting objects:  28% (2/7)\u001b[K\rremote: Counting objects:  42% (3/7)\u001b[K\rremote: Counting objects:  57% (4/7)\u001b[K\rremote: Counting objects:  71% (5/7)\u001b[K\rremote: Counting objects:  85% (6/7)\u001b[K\rremote: Counting objects: 100% (7/7)\u001b[K\rremote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1)\u001b[K\rremote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 4 (delta 3), reused 4 (delta 3), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects:  25% (1/4)\rUnpacking objects:  50% (2/4)\rUnpacking objects:  75% (3/4)\rUnpacking objects: 100% (4/4)\rUnpacking objects: 100% (4/4), 345 bytes | 172.00 KiB/s, done.\n",
            "From https://github.com/RonPlusSign/AnomalySegmentation\n",
            "   0caa8c0..8e13659  chris-1    -> origin/chris-1\n",
            "Updating 0caa8c0..8e13659\n",
            "Fast-forward\n",
            " eval/evalAnomaly.py | 2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Anomaly Inference**"
      ],
      "metadata": {
        "id": "4RZTrDS4Mysu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# se vado alla linea 87 di evalAnomaly.py quello dovrebbe essere l'utilizzo di MSP\n",
        "\n",
        "for dataset_dir in ['RoadAnomaly', 'FS_LostFound_full', 'RoadObsticle21', 'RoadAnomaly21', 'fs_static']:\n",
        "  if not torch.cuda.is_available():\n",
        "    for method in [\"MSP\", \"MaxLogit\", \"MaxEntropy\"]: #MaxEntropy in the future\n",
        "\n",
        "      format_file = os.listdir(f'/content/Validation_Dataset/{dataset_dir}/images')[0].split(\".\")[1]\n",
        "      input =f'/content/Validation_Dataset/{dataset_dir}/images/*.{format_file}'\n",
        "      print(f\"\\nDataset: {dataset_dir} method : {method}\")\n",
        "      !python -W ignore /content/AnomalySegmentation/eval/evalAnomaly.py --input {input} --loadDir '/content/AnomalySegmentation/trained_models/' --method {method} --cpu\n",
        "      break\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9afwM8zdM7_l",
        "outputId": "ae7fc2de-d476-4e13-81bf-4802592039da"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset: RoadAnomaly method : MSP\n",
            "Loading model: /content/AnomalySegmentation/trained_models/erfnet.py\n",
            "Loading weights: /content/AnomalySegmentation/trained_models/erfnet_pretrained.pth\n",
            "Model and weights LOADED successfully\n",
            "/content/Validation_Dataset/RoadAnomaly/images/0.jpg\n",
            "result.shpe torch.Size([1, 20, 720, 1280])\n",
            "result.squeeze(0).data.cpu().numpy() : 921599.8125\n",
            "ood_gts appena caricato : [[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "val_out : [2.3841858e-07 4.7683716e-07 1.2464023e-01 ... 2.9829204e-02 2.3841858e-06\n",
            " 1.1920929e-07] \n",
            " val_label : [0. 0. 0. ... 1. 1. 1.]\n",
            "AUPRC score: 6.73843136602053\n",
            "FPR@TPR95: 94.89165173912563\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Temperature Scaling**"
      ],
      "metadata": {
        "id": "NhQWIx8rklfO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Anomaly Inference with temperature**"
      ],
      "metadata": {
        "id": "q7DsE7oO1n9G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "\n",
        "for t in [0.5, 0.75, 1.1]:\n",
        "  for dataset_dir in ['RoadAnomaly', 'FS_LostFound_full', 'RoadObsticle21', 'RoadAnomaly21', 'fs_static']:\n",
        "\n",
        "    format_file = os.listdir(f'/content/Validation_Dataset/{dataset_dir}/images')[0].split(\".\")[1]\n",
        "    input =f'/content/Validation_Dataset/{dataset_dir}/images/*.{format_file}'\n",
        "    print(f\"\\nDataset: {dataset_dir} method : MSP Temperature: {t}\")\n",
        "\n",
        "    !python -W ignore /content/AnomalySegmentation/eval/evalAnomaly.py --input {input} --loadDir '/content/AnomalySegmentation/trained_models/'  --method 'MSP'  --cpu  --temperature {t} | tail -n 2\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "uOPe7qbN14Qz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43bb64bf-8d56-4ddc-9e60-20c39d13dfa4"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset: RoadAnomaly method : MSP Temperature: 0.5\n",
            "AUPRC score: 6.711344253191805\n",
            "FPR@TPR95: 94.9778651262153\n",
            "\n",
            "Dataset: FS_LostFound_full method : MSP Temperature: 0.5\n",
            "AUPRC score: 0.046513549713061375\n",
            "FPR@TPR95: 96.1368579659756\n",
            "\n",
            "Dataset: RoadObsticle21 method : MSP Temperature: 0.5\n",
            "AUPRC score: 0.018794117004305163\n",
            "FPR@TPR95: 95.20898177939428\n",
            "\n",
            "Dataset: RoadAnomaly21 method : MSP Temperature: 0.5\n",
            "AUPRC score: 1.662199319412507\n",
            "FPR@TPR95: 95.1301177602757\n",
            "\n",
            "Dataset: fs_static method : MSP Temperature: 0.5\n",
            "AUPRC score: 2.779911842973269\n",
            "FPR@TPR95: 95.46371734399979\n",
            "\n",
            "Dataset: RoadAnomaly method : MSP Temperature: 0.75\n",
            "AUPRC score: 6.723575093120552\n",
            "FPR@TPR95: 94.93579185596369\n",
            "\n",
            "Dataset: FS_LostFound_full method : MSP Temperature: 0.75\n",
            "AUPRC score: 0.044913449681561586\n",
            "FPR@TPR95: 96.6792729040551\n",
            "\n",
            "Dataset: RoadObsticle21 method : MSP Temperature: 0.75\n",
            "AUPRC score: 0.018794117004305163\n",
            "FPR@TPR95: 95.305352521508\n",
            "\n",
            "Dataset: RoadAnomaly21 method : MSP Temperature: 0.75\n",
            "AUPRC score: 1.6463917807525665\n",
            "FPR@TPR95: 95.18942252454362\n",
            "\n",
            "Dataset: fs_static method : MSP Temperature: 0.75\n",
            "AUPRC score: 2.7078169777305696\n",
            "FPR@TPR95: 95.71846852338554\n",
            "\n",
            "Dataset: RoadAnomaly method : MSP Temperature: 1.1\n",
            "AUPRC score: 6.744795309567523\n",
            "FPR@TPR95: 94.86656357972738\n",
            "\n",
            "Dataset: FS_LostFound_full method : MSP Temperature: 1.1\n",
            "AUPRC score: 0.042753992868055035\n",
            "FPR@TPR95: 97.37868230509771\n",
            "\n",
            "Dataset: RoadObsticle21 method : MSP Temperature: 1.1\n",
            "AUPRC score: 0.018794117004305163\n",
            "FPR@TPR95: 95.43576303886596\n",
            "\n",
            "Dataset: RoadAnomaly21 method : MSP Temperature: 1.1\n",
            "AUPRC score: 1.6262456814288289\n",
            "FPR@TPR95: 95.29052916319398\n",
            "\n",
            "Dataset: fs_static method : MSP Temperature: 1.1\n",
            "AUPRC score: 2.620158789928175\n",
            "FPR@TPR95: 96.18376332678639\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DATASET MANAGEMENT** **TUTTO INUTILE GIÃ€ TUTTO SCRITTO**"
      ],
      "metadata": {
        "id": "zXztTueNBgkk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "import os\n",
        "\n",
        "from PIL import Image\n",
        "import sys\n",
        "\n",
        "\n",
        "def pil_loader(path):\n",
        "    # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n",
        "    with open(f\"/content/Validation_Dataset/{path}\", 'rb') as f:\n",
        "        img = Image.open(f)\n",
        "        return img.convert('RGB')\n",
        "\n",
        "\n",
        "# Define the Dataset class\n",
        "class PACSDataset(Dataset):\n",
        "    def __init__(self, root= \"/content/Validation_Dataset\", source_domain=\"FS_LostFound_full\" , dataset_transform=None):\n",
        "      super(PACSDataset, self).__init__( )\n",
        "\n",
        "      self.dataset_transform = dataset_transform\n",
        "\n",
        "      self.root=f\"{root}/{source_domain}\"\n",
        "      self.data   = os.listdir(f\"{root}/{source_domain}/images\")\n",
        "      #self.labels = os.listdir(f\"{root}/{source_domain}/labels_masks\")\n",
        "\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "      image, label = pil_loader(f\"images/{self.data[index]}\"), pil_loader(f\"labels_masks/{self.data[index]}\")\n",
        "\n",
        "      # Applies preprocessing when accessing the image\n",
        "      if self.dataset_transform is not None:\n",
        "          image = self.dataset_transform(image)\n",
        "\n",
        "      return image, label\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mNB5VstJIcYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ARCHITECTURE SETUP**"
      ],
      "metadata": {
        "id": "AWeVJrW2NiFM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# Define AlexNet architecture class\n",
        "class ErfNet(nn.Module):\n",
        "    def __init__(self, num_classes=1000):\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "        )\n",
        "        # Category classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, num_classes)\n",
        "        )\n",
        "        # Domain classifier\n",
        "        self.domain_classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.features(x)\n",
        "        features = features.view(features.size(0), -1)\n",
        "        class_outputs = self.classifier(features)\n",
        "        domain_outputs = self.domain_classifier(features)\n",
        "        return class_outputs, domain_outputs"
      ],
      "metadata": {
        "id": "GB1UGpoSJL4w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}